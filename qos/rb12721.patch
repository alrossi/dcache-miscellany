diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/local/clients/LocalQoSVerificationClient.java b/modules/dcache-qos/src/main/java/org/dcache/qos/local/clients/LocalQoSVerificationClient.java
new file mode 100644
index 0000000000000000000000000000000000000000..aff1ef4ceb3689d60eec3dd3068430c9e68d59bc
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/local/clients/LocalQoSVerificationClient.java
@@ -0,0 +1,108 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.local.clients;
+
+import diskCacheV111.util.PnfsId;
+import org.dcache.qos.QoSException;
+import org.dcache.qos.listeners.QoSVerificationListener;
+import org.dcache.qos.services.verifier.handlers.FileQoSOperationHandler;
+import org.dcache.qos.vehicles.QoSAdjustmentResponse;
+import org.dcache.qos.vehicles.QoSBatchedVerificationRequest;
+import org.dcache.qos.vehicles.QoSVerificationRequest;
+
+/**
+ *  A pass-through to the file operation handler. Use this listener when plugging
+ *  in directly to the verification service.
+ */
+public final class LocalQoSVerificationClient implements QoSVerificationListener {
+  private FileQoSOperationHandler fileOpHandler;
+
+  @Override
+  public void fileQoSVerificationRequested(QoSVerificationRequest request) {
+    fileOpHandler.handleUpdate(request.getUpdate(), request.getRequirements());
+  }
+
+  @Override
+  public void fileQoSVerificationRequested(QoSBatchedVerificationRequest request) {
+    fileOpHandler.handleVerificationRequest(request);
+  }
+
+  @Override
+  public void fileQoSAdjustmentCompleted(QoSAdjustmentResponse response) {
+    fileOpHandler.handleAdjustmentResponse(response);
+  }
+
+  @Override
+  public void fileQoSVerificationCancelled(PnfsId pnfsId) throws QoSException {
+    fileOpHandler.handleFileOperationCancelled(pnfsId);
+  }
+
+  public void fileQoSBatchedVerificationCancelled(String pool) {
+    fileOpHandler.handleFileOperationsCancelledForPool(pool);
+  }
+
+  public void notifyLocationExclusion(String location, boolean excluded) {
+    fileOpHandler.handleExcludedStatusChange(location, excluded);
+  }
+
+  public void setFileOpHandler(FileQoSOperationHandler fileOpHandler) {
+    this.fileOpHandler = fileOpHandler;
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/remote/receivers/QoSVerificationReceiver.java b/modules/dcache-qos/src/main/java/org/dcache/qos/remote/receivers/QoSVerificationReceiver.java
new file mode 100644
index 0000000000000000000000000000000000000000..fadb373b61dbfe1512d1948050cdf14550733dfe
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/remote/receivers/QoSVerificationReceiver.java
@@ -0,0 +1,162 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.remote.receivers;
+
+import dmg.cells.nucleus.CellMessageReceiver;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.services.verifier.handlers.FileQoSOperationHandler;
+import org.dcache.qos.util.MessageGuard;
+import org.dcache.qos.util.MessageGuard.Status;
+import org.dcache.qos.vehicles.QoSAdjustmentResponse;
+import org.dcache.qos.vehicles.QoSAdjustmentResponseMessage;
+import org.dcache.qos.vehicles.QoSBatchVerificationCancelledMessage;
+import org.dcache.qos.vehicles.QoSBatchedVerificationRequest;
+import org.dcache.qos.vehicles.QoSBatchedVerificationRequestMessage;
+import org.dcache.qos.vehicles.QoSLocationExcludedMessage;
+import org.dcache.qos.vehicles.QoSVerificationCancelledMessage;
+import org.dcache.qos.vehicles.QoSVerificationRequest;
+import org.dcache.qos.vehicles.QoSVerificationRequestMessage;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ *  Implements message reception for remote verification service.
+ *  </p>
+ *  If disabled manually, messages will be dropped.
+ */
+public final class QoSVerificationReceiver implements CellMessageReceiver {
+    private static final Logger ACTIVITY_LOGGER = LoggerFactory.getLogger("org.dcache.qos-log");
+
+    private MessageGuard messageGuard;
+    private FileQoSOperationHandler fileOpHandler;
+
+    public void messageArrived(QoSAdjustmentResponseMessage message) {
+        QoSAdjustmentResponse response = message.getResponse();
+        ACTIVITY_LOGGER.info("Received notice that qos adjustment for file {} has completed.",
+            response.getPnfsId());
+        if (messageGuard.getStatus("QoSAdjustmentResponseMessage", message)
+            == Status.DISABLED) {
+            return;
+        }
+        fileOpHandler.handleAdjustmentResponse(response);
+    }
+
+    public void messageArrived(QoSLocationExcludedMessage message) {
+        ACTIVITY_LOGGER.info("Received notice of location exclusion = {} for pool {} from scanner.",
+           message.isExcluded(), message.getLocation());
+        if (messageGuard.getStatus("QoSLocationExcludedMessage", message)
+            == Status.DISABLED) {
+            return;
+        }
+        fileOpHandler.handleExcludedStatusChange(message.getLocation(), message.isExcluded());
+    }
+
+    public void messageArrived(QoSVerificationRequestMessage message) {
+        QoSVerificationRequest request = message.getRequest();
+        FileQoSUpdate update = request.getUpdate();
+        ACTIVITY_LOGGER.info("Received notice of request for verification for {}, pool {}, type {}.",
+            update.getPnfsId(), update.getPool(), update.getMessageType());
+        if (messageGuard.getStatus("QoSVerificationRequestMessage", message)
+            == Status.DISABLED) {
+            return;
+        }
+        fileOpHandler.handleVerificationRequest(request);
+    }
+
+    public void messageArrived(QoSBatchedVerificationRequestMessage message) {
+        QoSBatchedVerificationRequest request = message.getRequest();
+        ACTIVITY_LOGGER.info("Received notice of batched request for verification on "
+                + "{}, type {}, unit {}, forced {}.",
+            request.getPool(), request.getType(), request.getStorageUnit(), request.isForced());
+        if (messageGuard.getStatus("QoSBatchedVerificationRequestMessage", message)
+            == Status.DISABLED) {
+            return;
+        }
+        fileOpHandler.handleVerificationRequest(request);
+    }
+
+    public void messageArrived(QoSBatchVerificationCancelledMessage message) {
+        ACTIVITY_LOGGER.info("Received notice to cancel batched request for verification on "
+                + "{}.", message.getPool());
+        if (messageGuard.getStatus("QoSBatchVerificationCancelledMessage", message)
+            == Status.DISABLED) {
+            return;
+        }
+        fileOpHandler.handleFileOperationsCancelledForPool(message.getPool());
+    }
+
+    public void messageArrived(QoSVerificationCancelledMessage message) {
+        ACTIVITY_LOGGER.info("Received notice to cancel request for verification of "
+                + "{}.",  message.getPnfsId());
+        if (messageGuard.getStatus("QoSVerificationCancelledMessage", message)
+            == Status.DISABLED) {
+            return;
+        }
+        fileOpHandler.handleFileOperationCancelled(message.getPnfsId());
+    }
+
+    public void setFileOpHandler(FileQoSOperationHandler fileOpHandler) {
+        this.fileOpHandler = fileOpHandler;
+    }
+
+    public void setMessageGuard(MessageGuard messageGuard) {
+        this.messageGuard = messageGuard;
+    }
+}
\ No newline at end of file
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/admin/QoSVerifierAdmin.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/admin/QoSVerifierAdmin.java
new file mode 100644
index 0000000000000000000000000000000000000000..a91dea30df25803c7b07ff23e8030be847416f2f
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/admin/QoSVerifierAdmin.java
@@ -0,0 +1,645 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.admin;
+
+import com.google.common.collect.ImmutableSet;
+import diskCacheV111.util.CacheException;
+import diskCacheV111.util.PnfsHandler;
+import diskCacheV111.util.PnfsId;
+import dmg.cells.nucleus.CellCommandListener;
+import dmg.util.command.Argument;
+import dmg.util.command.Command;
+import dmg.util.command.Option;
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import java.util.NoSuchElementException;
+import java.util.concurrent.TimeUnit;
+import org.dcache.auth.Subjects;
+import org.dcache.auth.attributes.Restrictions;
+import org.dcache.cells.CellStub;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.data.QoSAction;
+import org.dcache.qos.data.QoSMessageType;
+import org.dcache.qos.services.scanner.namespace.NamespaceAccess;
+import org.dcache.qos.services.verifier.data.FileQoSFilter;
+import org.dcache.qos.services.verifier.data.FileQoSOperation;
+import org.dcache.qos.services.verifier.data.FileQoSOperationMap;
+import org.dcache.qos.services.verifier.data.PoolInfoFilter;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.dcache.qos.services.verifier.handlers.FileQoSOperationHandler;
+import org.dcache.qos.services.verifier.util.QoSVerifierCounters;
+import org.dcache.qos.util.InitializerAwareCommand;
+import org.dcache.qos.util.MapInitializer;
+import org.dcache.qos.util.MessageGuard;
+import org.dcache.qos.util.QoSHistory;
+import org.dcache.vehicles.FileAttributes;
+
+public final class QoSVerifierAdmin implements CellCommandListener {
+
+  abstract class FilteredVerifyOpCommand extends InitializerAwareCommand {
+    @Option(name = "action",
+        valueSpec = "COPY_REPLICA|CACHE_REPLICA|PERSIST_REPLICA|WAIT_FOR_STAGE|FLUSH",
+        usage = "Match only operations for files with this action type.")
+    protected QoSAction action;
+
+    @Option(name = "state",
+        valueSpec = "READY|RUNNING|DONE|CANCELED|FAILED|ABORTED",
+        separator = ",",
+        usage = "Match only operations for files matching this comma-delimited set of states; "
+            + "default is all.")
+    protected String[] state = {"RUNNING", "READY"};
+
+    @Option(name = "storageUnit",
+        usage = "Match only operations for files with this storage unit.")
+    protected String storageUnit;
+
+    @Option(name = "group",
+        usage = "Match only operations with this preferred pool group; use the option with no "
+            + "value to match only operations without a specified group.")
+    protected String poolGroup;
+
+    @Option(name = "parent",
+        usage = "Match only operations with this parent pool name; use the option with no value "
+            + "to match only operations without a parent pool.")
+    String parent;
+
+    @Option(name = "source",
+        usage = "Match only operations with this source pool name; use the option with no value "
+            + "to match only operations without a source pool.")
+    protected String source;
+
+    @Option(name = "target",
+        usage = "Match only operations with this target pool name; use the option with no value "
+            + "to match only operations without a target pool.")
+    protected String target;
+
+    @Option(name = "retried",
+        usage = "Match only the operation with this number of retries.")
+    protected Integer retried;
+
+    @Option(name = "lastUpdateBefore", valueSpec = FORMAT_STRING,
+        usage = "Match only operations whose start time is before this date-time.")
+    protected String lastUpdateBefore;
+
+    @Option(name = "lastUpdateAfter", valueSpec = FORMAT_STRING,
+        usage = "Match only operations whose start time is after this date-time.")
+    protected String lastUpdateAfter;
+
+    @Argument(required = false,
+              usage = "Match only activities for this comma-delimited list of pnfsids. "
+            + "Leaving the argument unspecified or using '*' matches all pnfsids.")
+    protected String pnfsids;
+
+    protected FilteredVerifyOpCommand() {
+      super(initializer);
+    }
+
+    protected FileQoSFilter getFilter() {
+      FileQoSFilter filter = new FileQoSFilter();
+
+      if (pnfsids != null && !pnfsids.equals("*")) {
+        filter.setPnfsIds(pnfsids);
+      }
+
+      filter.setLastUpdateBefore(getTimestamp(lastUpdateBefore));
+      filter.setLastUpdateAfter(getTimestamp(lastUpdateAfter));
+      filter.setState(ImmutableSet.copyOf(state));
+      filter.setAction(action);
+      filter.setStorageUnit(storageUnit);
+      filter.setPoolGroup(poolGroup);
+      filter.setParent(parent);
+      filter.setSource(source);
+      filter.setTarget(target);
+      filter.setRetried(retried);
+
+      return filter;
+    }
+  }
+
+  @Command(name = "pool info",
+           hint = "list tags and mode for a pool or pools",
+           description = "Lists pool key, name, mode, status, tags and last update time.")
+  class PoolInfoCommand extends InitializerAwareCommand {
+    @Option(name = "status",
+            valueSpec = "DOWN|READ_ONLY|ENABLED|UNINITIALIZED",
+            separator = ",",
+            usage = "List only information for pools matching this  comma-delimited set of states.")
+    String[] status = {"DOWN", "READ_ONLY", "ENABLED", "UNINITIALIZED"};
+
+    @Option(name = "keys",
+            separator = ",",
+            usage = "List only information for pools matching this comma-delimited set of keys.")
+    Integer[] keys;
+
+    @Option(name = "lastUpdateBefore", valueSpec = FORMAT_STRING,
+            usage = "List only operations whose last update was before this date-time.")
+    String lastUpdateBefore;
+
+    @Option(name = "lastUpdateAfter", valueSpec = FORMAT_STRING,
+            usage = "List only operations whose last update was after this date-time.")
+    String lastUpdateAfter;
+
+    @Argument(required = false,
+        usage = "Regular expression to match pool names; no argument matches all pools.")
+    String pools;
+
+    PoolInfoCommand() { super(initializer); }
+
+    @Override
+    protected String doCall() throws Exception {
+      PoolInfoFilter filter = new PoolInfoFilter();
+      filter.setPools(pools);
+      filter.setKeys(keys);
+      filter.setStatus(status);
+      filter.setLastUpdateAfter(getTimestamp(lastUpdateAfter));
+      filter.setLastUpdateBefore(getTimestamp(lastUpdateBefore));
+
+      try {
+        return poolInfoMap.listPoolInfo(filter);
+      } catch (IndexOutOfBoundsException | NoSuchElementException e) {
+        return "No such pools: " + pools;
+      }
+    }
+  }
+
+  @Command(name = "verify",
+      hint = "launch an operation to verify one or more pnfsids",
+      description = "For each pnfsid, runs a check to see that the number of replicas is properly "
+          + "constrained, creating new copies or removing redundant ones as necessary.")
+  class VerifyCommand extends InitializerAwareCommand {
+    @Argument(usage = "Comma-delimited list of pnfsids for which to run the adjustment.")
+    String pnfsids;
+
+    VerifyCommand() { super(initializer); }
+
+    @Override
+    protected String doCall() throws Exception {
+      try {
+        return runFileChecks(Arrays.asList(pnfsids.split("[,]")));
+      } catch (Throwable t) {
+        return t.getMessage();
+      }
+    }
+  }
+
+  @Command(name = "verify cancel",
+          hint = "cancel file operations",
+          description = "Scans the file table and cancels operations matching the filter parameters.")
+  class VerifyCancelCommand extends FilteredVerifyOpCommand {
+    @Option(name = "forceRemoval",
+            usage = "Remove all waiting operations for this match after cancellation of the running "
+            + "tasks. (Default is false; this option is redundant if the state includes WAITING.)")
+    boolean forceRemoval = false;
+
+    @Override
+    protected String doCall() throws Exception {
+      if (pnfsids == null) {
+        return "To cancel you must specify one or more pnfsids, or '*' for all matching pnfsids.";
+      }
+
+      FileQoSFilter filter = getFilter();
+
+      if (filter.isSimplePnfsMatch()) {
+        fileOpMap.cancel(new PnfsId(pnfsids), forceRemoval);
+        return String.format("Issued cancel command for %s.", pnfsids);
+      }
+
+      forceRemoval |= ImmutableSet.copyOf(state).contains("WAITING");
+      filter.setForceRemoval(forceRemoval);
+
+      fileOpMap.cancel(filter);
+
+      return "Issued cancel command to cancel file operations.";
+    }
+  }
+
+  @Command(name = "verify ctrl",
+           hint = "control checkpointing or handling of operations",
+      description = "Runs checkpointing, resets checkpoint properties, resets operation properties, "
+                    + "turn processing of operations on or off (start/shutdown), or displays info "
+                    + "relevant to operation processing and checkpointing.")
+  class VerifyControlCommand extends InitializerAwareCommand {
+    @Argument(valueSpec = "ON|OFF|START|SHUTDOWN|RESET|RUN|INFO",
+        required = false,
+        usage = "off = turn checkpointing off; on = turn checkpointing on; info = information (default); "
+                + "reset = reset properties; start = (re)start processing of operations; "
+                + "shutdown = stop all processing of operations; "
+                + "run = checkpoint to disk immediately." )
+    String arg = "INFO";
+
+    @Option(name = "checkpoint",
+            usage = "With reset mode (one of checkpoint|sweep|delay). Interval length between "
+                + "checkpointing of the file operation data.")
+    Long checkpoint;
+
+    @Option(name = "sweep",
+            usage = "With reset mode (one of checkpoint|sweep|delay). Minimal interval between "
+                + "sweeps of the file operations.")
+    Long sweep;
+
+    @Option(name = "delay",
+            usage = "With reset mode (one of checkpoint|sweep|delay). Delay before actual "
+                + "execution of a task which has been set to the running state.")
+    Long delay;
+
+    @Option(name = "unit", valueSpec = "SECONDS|MINUTES|HOURS",
+            usage = "Checkpoint, sweep or delay interval unit.")
+    TimeUnit unit;
+
+    @Option(name = "retries", usage = "Maximum number of retries on a failed operation.")
+    Integer retries;
+
+    @Option(name = "file", usage = "Alternate (full) path for checkpoint file.")
+    String file;
+
+    private ControlMode mode;
+
+    VerifyControlCommand() { super(initializer); }
+
+    @Override
+    public String call() {
+      mode = ControlMode.valueOf(arg.toUpperCase());
+      if (mode == ControlMode.START) {
+        new Thread(() -> startAll()).start();
+        return "Consumer initialization and reload of checkpoint file started.";
+      }
+      return super.call();
+    }
+
+    @Override
+    protected String doCall() throws Exception {
+      switch (mode) {
+        case SHUTDOWN:
+          shutdownAll();
+          return "Consumer has been shutdown.";
+        case OFF:
+          if (fileOpMap.isCheckpointingOn()) {
+            fileOpMap.stopCheckpointer();
+            return "Shut down checkpointing.";
+          }
+          return "Checkpointing already off.";
+        case ON:
+          if (!fileOpMap.isCheckpointingOn()) {
+            fileOpMap.startCheckpointer();
+            return fileOpMap.infoMessage();
+          }
+          return "Checkpointing already on.";
+        case RUN:
+          if (!fileOpMap.isCheckpointingOn()) {
+            return "Checkpointing is off; please turn it on first.";
+          }
+          fileOpMap.runCheckpointNow();
+          return "Forced checkpoint.";
+        case RESET:
+          if (!fileOpMap.isCheckpointingOn()) {
+            return "Checkpointing is off; please turn it on first.";
+          }
+
+          if (checkpoint != null) {
+            fileOpMap.setCheckpointExpiry(checkpoint);
+            if (unit != null) {
+              fileOpMap.setCheckpointExpiryUnit(unit);
+            }
+          } else if (sweep != null) {
+            fileOpMap.setTimeout(sweep);
+            if (unit != null) {
+              fileOpMap.setTimeoutUnit(unit);
+            }
+          } else if (delay != null) {
+            fileOpHandler.setLaunchDelay(delay);
+            if (unit != null) {
+              fileOpHandler.setLaunchDelayUnit(unit);
+            }
+          }
+
+          if (retries != null) {
+            fileOpMap.setMaxRetries(retries);
+          }
+
+          if (file != null) {
+            fileOpMap.setCheckpointFilePath(file);
+          }
+
+          fileOpMap.reset();
+          // fall through here
+        case INFO:
+        default:
+          return fileOpMap.infoMessage();
+      }
+    }
+  }
+
+  @Command(name = "verify failed",
+      hint = "launch operations to rerun verify for all pnfsids currently appearing in "
+          + "the history errors list",
+      description = "For each pnfsid, runs a check to see that "
+          + "the requirements are satisfied, and submitting the appropriate adjustment"
+          + "requests if not. NOTE: running this command also clears the current errors list.")
+  class VerifyFailedCommand extends InitializerAwareCommand {
+
+    VerifyFailedCommand() { super(initializer); }
+
+    @Override
+    protected String doCall() throws Exception {
+      return runFileChecks(history.getErrorPnfsids());
+    }
+  }
+
+  @Command(name = "verify details",
+      hint = "list diagnostic information concerning verification by pool",
+      description = "Gives statistics for verification completed or failed by pool.")
+  class VerifyDetailsCommand extends InitializerAwareCommand {
+    VerifyDetailsCommand() { super(initializer); }
+
+    @Override
+    protected String doCall() throws Exception {
+      StringBuilder builder = new StringBuilder();
+      counters.appendDetails(builder);
+      return builder.toString();
+    }
+  }
+
+  @Command(name = "verify history",
+           hint = "display a history of the most recent terminated operations",
+           description = "When operations complete or are aborted, their string representations "
+               + "are added to a circular buffer whose capacity is set by the property "
+               + "'qos.limits.file.operation-history'.")
+  class VerifyHistoryCommand extends InitializerAwareCommand {
+    @Argument(required = false, valueSpec = "errors", usage = "Display just the failures.")
+    String errors;
+
+    @Option(name = "limit", usage = "Display up to this number of entries.")
+    Integer limit;
+
+    @Option(name = "order", valueSpec = "ASC|DESC",
+            usage = "Display entries in ascending (default) or descending order of arrival.")
+    String order = "ASC";
+
+    VerifyHistoryCommand() { super(initializer); }
+
+    @Override
+    protected String doCall() throws Exception {
+      boolean failed = false;
+      if (errors != null) {
+        if (!"errors".equals(errors)) {
+          return  "Optional argument must be 'errors'";
+        }
+        failed = true;
+      }
+
+      SortOrder order = SortOrder.valueOf(this.order.toUpperCase());
+
+      switch (order) {
+        case DESC:
+          if (limit != null) {
+            return history.descending(failed, limit);
+          }
+          return history.descending(failed);
+        default:
+          if (limit != null) {
+            return history.ascending(failed, limit);
+          }
+          return history.ascending(failed);
+      }
+    }
+  }
+
+  @Command(name = "verify ls",
+           hint = "list entries in the operation table",
+           description = "Scans the table and returns operations matching the filter parameters.")
+  class VerifyLsCommand extends FilteredVerifyOpCommand {
+    @Option(name = "count", usage="Do not list, but return only the number of matches.")
+    boolean count = false;
+
+    @Option(name = "byPool",
+            usage="Return counts detailed pool-by-pool (only valid if 'count' is true).")
+    boolean byPool = false;
+
+    @Option(name = "limit",
+        usage = "Maximum number of rows to list.  This option becomes required when "
+            + "the operation queues reach " + LS_THRESHOLD + "; be aware that "
+            + "listing more than this number of rows may provoke an out of memory "
+            + "error for the domain.")
+    Integer limit;
+
+    @Override
+    protected String doCall() throws Exception {
+      FileQoSFilter filter = getFilter();
+
+      if (filter.isSimplePnfsMatch()) {
+        FileQoSOperation op = fileOpMap.getOperation(new PnfsId(pnfsids));
+        if (op == null) {
+          return String.format("No operation currently registered for %s.",
+              pnfsids);
+        }
+        return op.toString() + "\n";
+      }
+
+      if (count) {
+        StringBuilder builder = byPool ? new StringBuilder() : null;
+        long total = fileOpMap.count(filter, builder);
+
+        if (builder == null) {
+          return total + " matching pnfsids";
+        }
+
+        return String.format("%s matching operations."
+                + "\n\nOperation counts per pool:\n%s",
+            total, builder.toString());
+      }
+
+      long size = fileOpMap.size();
+      int limitValue = (int)size;
+
+      if (limit == null) {
+        ImmutableSet<String> stateSet = ImmutableSet.copyOf(state);
+        if ((stateSet.contains("READY") || stateSet.contains("WAITING")) && size >= LS_THRESHOLD) {
+          return String.format(REQUIRE_LIMIT, size, size);
+        }
+      } else {
+        limitValue = limit;
+      }
+
+      return fileOpMap.list(filter, limitValue);
+    }
+  }
+
+  @Command(name = "verify stats", hint = "print diagnostic statistics",
+      description = "Reads in the contents of the file recording periodic statistics "
+          + "(see diag command).")
+  class VerifyStatsCommand extends InitializerAwareCommand {
+    @Option(name = "limit", usage = "Display up to this number of lines (default is 24 * 60).")
+    Integer limit = 24 * 60;
+
+    @Option(name = "order", valueSpec = "asc|desc",
+        usage = "Display lines in ascending (default) or descending order by timestamp.")
+    String order = "asc";
+
+    @Option(name = "enable",
+        usage = "Turn the recording of statistics to file on or off. Recording to file is "
+            + "off by default.")
+    Boolean enable = null;
+
+    VerifyStatsCommand() { super(initializer); }
+
+    protected String doCall() throws Exception {
+      if (enable != null) {
+        counters.setToFile(enable);
+        return "Recording to file is now " + (enable ? "on." : "off.");
+      }
+
+      SortOrder order = SortOrder.valueOf(this.order.toUpperCase());
+      StringBuilder builder = new StringBuilder();
+      counters.readStatistics(builder, 0, limit, order == SortOrder.DESC);
+      return builder.toString();
+    }
+  }
+
+  private CellStub pnfsManager;
+  private MessageGuard messageGuard;
+  private MapInitializer initializer;
+  private PoolInfoMap poolInfoMap;
+  private FileQoSOperationMap fileOpMap;
+  private FileQoSOperationHandler fileOpHandler;
+  private QoSVerifierCounters counters;
+  private QoSHistory history;
+
+  public void setCounters(QoSVerifierCounters counters) {
+    this.counters = counters;
+  }
+
+  public void setFileOpMap(FileQoSOperationMap fileOpMap) {
+    this.fileOpMap = fileOpMap;
+  }
+
+  public void setFileOpHandler(
+      FileQoSOperationHandler fileOpHandler) {
+    this.fileOpHandler = fileOpHandler;
+  }
+
+  public void setHistory(QoSHistory history) {
+    this.history = history;
+  }
+
+  public void setInitializer(MapInitializer initializer) {
+    this.initializer = initializer;
+  }
+
+  public void setMessageGuard(MessageGuard messageGuard) {
+    this.messageGuard = messageGuard;
+  }
+
+  public void setPnfsManager(CellStub pnfsManager) {
+    this.pnfsManager = pnfsManager;
+  }
+
+  public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+    this.poolInfoMap = poolInfoMap;
+  }
+
+  private String runFileChecks(List<String> list) {
+    StringBuilder reply = new StringBuilder();
+    int successful = 0;
+    for (String pnfsid: list) {
+      try {
+        PnfsId pnfsId = new PnfsId(pnfsid);
+        FileAttributes attr
+            = getPnfsHandler().getFileAttributes(pnfsId, NamespaceAccess.LOCATION_ATTRIBUTES);
+        Iterator<String> it = attr.getLocations().iterator();
+        FileQoSUpdate update = new FileQoSUpdate(pnfsId, it.hasNext() ? it.next() : null,
+                                                 QoSMessageType.VALIDATE_ONLY);
+        fileOpMap.register(update);
+        ++successful;
+      } catch (NoSuchElementException | CacheException e) {
+        reply.append(pnfsid).append(" ").append(e.getMessage()).append("\n");
+      }
+    }
+
+    reply.append("verification started for ").append(successful).append(" files.\n");
+
+    return reply.toString();
+  }
+
+  private PnfsHandler getPnfsHandler() {
+    PnfsHandler handler = new PnfsHandler(pnfsManager);
+    handler.setSubject(Subjects.ROOT);
+    handler.setRestriction(Restrictions.none());
+    return handler;
+  }
+
+  private void startAll() {
+    initializer.initialize();
+    if (fileOpMap.isRunning()) {
+      fileOpMap.shutdown();
+    }
+    fileOpMap.initialize();
+    fileOpMap.reload();
+    messageGuard.enable();
+  }
+
+  private void shutdownAll() {
+    if (fileOpMap.isRunning()) {
+      fileOpMap.shutdown();
+    }
+    messageGuard.disable(true);
+    initializer.shutDown();
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSCancelFilter.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSCancelFilter.java
new file mode 100644
index 0000000000000000000000000000000000000000..10d9159d218f3709681f5a48ab852ff78af30e9c
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSCancelFilter.java
@@ -0,0 +1,79 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+/**
+ *  Filter used specifically with cancel operations.
+ */
+public final class FileQoSCancelFilter extends FileQoSFilter {
+    /*
+     *  Overrides the normal matching of a pool. Since this is a cancel operation,
+     *  if the pool does not exist, we should cancel it no matter what the toMatch value is.
+     */
+    protected boolean matchesPool(String toMatch,
+                                  Integer operationValue,
+                                  PoolInfoMap map) {
+        if (operationValue != null && !map.isValidPoolIndex(operationValue)) {
+            return true;
+        }
+
+        return super.matchesPool(toMatch, operationValue, map);
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSFilter.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSFilter.java
new file mode 100644
index 0000000000000000000000000000000000000000..4ed5a68316f3214879dc6c4a33a3f6babe72b1dc
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSFilter.java
@@ -0,0 +1,211 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.base.Splitter;
+import java.util.HashSet;
+import java.util.Set;
+import org.dcache.qos.data.QoSAction;
+
+/**
+ *  Simple implementation of matcher.
+ */
+public class FileQoSFilter implements FileQoSMatcher {
+    private Set<String> state;
+    private Set<String> pnfsids;
+    private QoSAction   action;
+    private String      storageUnit;
+    private String      poolGroup;
+    private String      parent;
+    private String      source;
+    private String      target;
+    private Long        lastUpdateBefore;
+    private Long        lastUpdateAfter;
+    private Integer     retried;
+    private boolean     forceRemoval = false;
+
+    protected boolean matchesPool(String toMatch,
+                                  Integer operationValue,
+                                  PoolInfoMap map) {
+        if (toMatch == null) {
+            return true;
+        }
+
+        if (toMatch.isEmpty()) {
+            return operationValue == null;
+        }
+
+        if (!map.hasPool(toMatch)) {
+            return false;
+        }
+
+        return map.getPoolIndex(toMatch).equals(operationValue);
+    }
+
+    @Override
+    public boolean isForceRemoval() {
+        return forceRemoval;
+    }
+
+    @Override
+    public boolean isSimplePnfsMatch() {
+        return pnfsids == null ? false : pnfsids.size() == 1;
+    }
+
+    /**
+     *  Filter components are treated as parts of an AND statement.
+     */
+    @Override
+    public boolean matches(FileQoSOperation operation, PoolInfoMap map) {
+        if (action != null && action != operation.getAction()) {
+            return false;
+        }
+
+        if (state != null && !state.contains(operation.getStateName())) {
+            return false;
+        }
+
+        if (pnfsids != null && !pnfsids.contains(operation.getPnfsId().toString())) {
+            return false;
+        }
+
+        if (retried != null && operation.getRetried() < retried) {
+            return false;
+        }
+
+        if (storageUnit != null &&
+                        !storageUnit.equals(map.getUnit(operation.getStorageUnit()))) {
+            return false;
+        }
+
+        if (poolGroup != null &&
+            !poolGroup.equals(map.getGroup(operation.getPoolGroup()))) {
+            return false;
+        }
+
+        Long lastUpdate = operation.getLastUpdate();
+
+        if (lastUpdateBefore != null && lastUpdateBefore <= lastUpdate) {
+            return false;
+        }
+
+        if (lastUpdateAfter != null && lastUpdateAfter >= lastUpdate) {
+            return false;
+        }
+
+        if (!matchesPool(parent, operation.getParent(), map)) {
+            return false;
+        }
+
+        if (!matchesPool(source, operation.getSource(), map)) {
+            return false;
+        }
+
+        return matchesPool(target, operation.getTarget(), map);
+    }
+
+    public void setAction(QoSAction action) { this.action = action; }
+
+    public void setForceRemoval(boolean forceRemoval) {
+        this.forceRemoval = forceRemoval;
+    }
+
+    public void setLastUpdateAfter(Long lastUpdateAfter) {
+        this.lastUpdateAfter = lastUpdateAfter;
+    }
+
+    public void setLastUpdateBefore(Long lastUpdateBefore) {
+        this.lastUpdateBefore = lastUpdateBefore;
+    }
+
+    public void setParent(String parent) {
+        this.parent = parent;
+    }
+
+    public void setPoolGroup(String poolGroup) {
+        this.poolGroup = poolGroup;
+    }
+
+    public void setPnfsIds(String pnfsIds) {
+        if (pnfsIds != null) {
+            this.pnfsids = new HashSet<>(Splitter.on(",").splitToList(pnfsIds));
+        }
+    }
+
+    public void setRetried(Integer retried) {
+        this.retried = retried;
+    }
+
+    public void setSource(String source) {
+        this.source = source;
+    }
+
+    public void setState(Set<String> states) {
+            this.state = states;
+    }
+
+    public void setStorageUnit(String storageUnit) {
+        this.storageUnit = storageUnit;
+    }
+
+    public void setTarget(String target) {
+        this.target = target;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSLocations.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSLocations.java
new file mode 100644
index 0000000000000000000000000000000000000000..d7c2767e3c606ecc915308ffb0bcdf7ebdee1401
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSLocations.java
@@ -0,0 +1,361 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import diskCacheV111.util.PnfsId;
+import java.io.Serializable;
+import java.util.Collection;
+import java.util.Set;
+import org.dcache.vehicles.qos.ReplicaStatusMessage;
+
+/**
+ *  The following table illustrates the classification of a file with each type of replica location.
+ *  <p/>
+ *  <table>
+ *   <thead>
+ *     <th>
+ *         <td style="text-align: center;">Cached+Sticky</td>
+ *         <td style="text-align: center;">Precious+Sticky</td>
+ *         <td style="text-align: center;">Precious</td>
+ *         <td style="text-align: center;">Cached</td>
+ *         <td style="text-align: center;">Broken</td>
+ *         <td style="text-align: center;">Removed</td>
+ *         <td style="text-align: center;">OFFLINE</td>
+ *         <td style="text-align: center;">EXCLUDED</td>
+ *     </th>
+ *   </thead>
+ *   <tbody>
+ *     <tr>
+ *             <td style="text-align: left;">CURRENT DISK LOCATIONS</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;">B2</td>
+ *             <td style="text-align: center;">C</td>
+ *             <td style="text-align: center;">D</td>
+ *             <td style="text-align: center;">[E]</td>
+ *             <td style="text-align: center;">F</td>
+ *             <td style="text-align: center;">G</td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">VERIFIED</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;">B2</td>
+ *             <td style="text-align: center;">C</td>
+ *             <td style="text-align: center;">D</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">G</td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">BROKEN</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">D</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">OCCUPIED</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;">B2</td>
+ *             <td style="text-align: center;">C</td>
+ *             <td style="text-align: center;">D</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">F</td>
+ *             <td style="text-align: center;">G</td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">READABLE</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;">B2</td>
+ *             <td style="text-align: center;">C</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">[E]</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">G</td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">VIABLE</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;">B2</td>
+ *             <td style="text-align: center;">C</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">G</td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">PERSISTENT</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">G</td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">PERSISTENT W/O EXCLUDED</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;">B1</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">CACHED</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;">C</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *     </tr>
+ *     <tr>
+ *             <td style="text-align: left;">REMOVABLE</td>
+ *             <td style="text-align: center;">A</td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *             <td style="text-align: center;"></td>
+ *     </tr>
+ *   </tbody>
+ *  </table>
+ *  <p/>
+ *  Note that "REMOVABLE" here means from the standpoint of being able to reduce the number of
+ *  persistent replicas, not in the sense of the file not having a sticky flag; i.e., it tells
+ *  the engine whether the replica can be cached or not.  In effect, only cached+sticky files
+ *  belong to this class.
+ */
+public final class FileQoSLocations implements Serializable {
+  private static final long serialVersionUID = -987104125231438126L;
+
+  private final PnfsId pnfsId;
+
+  private String requiredPoolGroup;
+
+  /*
+   *  Locations as reported in the namespace.
+   */
+  private Collection<String> currentDiskLocations;
+  private Collection<String> currentTapeLocations;
+
+  /*
+   *  Disk locations verified from the pool repository.
+   */
+  private Set<String> broken;
+  private Set<String> readable;
+  private Set<String> exist;
+  private Set<String> viable;
+  private Set<String> persistent;
+  private Set<String> members;
+  private Set<String> occupied;
+  private Set<String> cached;
+  private Set<String> excluded;
+  private Set<String> precious;
+
+  /*
+   *  Set by verifier from the pool information.
+   */
+  private Set<String> hsm;
+
+  /*
+   *  For each location, a verification message is provided by the verifier.
+   */
+  private Collection<ReplicaStatusMessage> replicaStatus;
+
+  public FileQoSLocations(PnfsId pnfsId) {
+    this.pnfsId = pnfsId;
+  }
+
+  public PnfsId getPnfsId() {
+    return pnfsId;
+  }
+
+  public Collection<String> getCurrentDiskLocations() {
+    return currentDiskLocations;
+  }
+
+  public void setCurrentDiskLocations(Collection<String> currentDiskLocations) {
+    this.currentDiskLocations = currentDiskLocations;
+  }
+
+  public Collection<String> getCurrentTapeLocations() {
+    return currentTapeLocations;
+  }
+
+  public void setCurrentTapeLocations(Collection<String> currentTapeLocations) {
+    this.currentTapeLocations = currentTapeLocations;
+  }
+
+  public Set<String> getBroken() {
+    return broken;
+  }
+
+  public void setBroken(Set<String> broken) {
+    this.broken = broken;
+  }
+
+  public Set<String> getReadable() {
+    return readable;
+  }
+
+  public void setReadable(Set<String> readable) {
+    this.readable = readable;
+  }
+
+  public Set<String> getExist() {
+    return exist;
+  }
+
+  public void setExist(Set<String> exist) {
+    this.exist = exist;
+  }
+
+  public Set<String> getViable() {
+    return viable;
+  }
+
+  public void setViable(Set<String> viable) {
+    this.viable = viable;
+  }
+
+  public Set<String> getPersistent() {
+    return persistent;
+  }
+
+  public void setPersistent(Set<String> persistent) {
+    this.persistent = persistent;
+  }
+
+  public Set<String> getPrecious() { return precious; }
+
+  public void setPrecious(Set<String> precious) { this.precious = precious; }
+
+  public Set<String> getMembers() {
+    return members;
+  }
+
+  public void setMembers(Set<String> members) {
+    this.members = members;
+  }
+
+  public Set<String> getOccupied() {
+    return occupied;
+  }
+
+  public void setOccupied(Set<String> occupied) {
+    this.occupied = occupied;
+  }
+
+  public Set<String> getCached() {
+    return cached;
+  }
+
+  public void setCached(Set<String> cached) {
+    this.cached = cached;
+  }
+
+  public Set<String> getExcluded() {
+    return excluded;
+  }
+
+  public void setExcluded(Set<String> excluded) {
+    this.excluded = excluded;
+  }
+
+  public Set<String> getHsm() { return hsm; }
+
+  public void setHsm(Set<String> hsm) {
+    this.hsm = hsm;
+  }
+
+  public Collection<ReplicaStatusMessage> getReplicaStatus() {
+    return replicaStatus;
+  }
+
+  public void setReplicaStatus(Collection<ReplicaStatusMessage> replicaStatus) {
+    this.replicaStatus = replicaStatus;
+  }
+
+  public String getRequiredPoolGroup() {
+    return requiredPoolGroup;
+  }
+
+  public void setRequiredPoolGroup(String requiredPoolGroup) {
+    this.requiredPoolGroup = requiredPoolGroup;
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSMatcher.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSMatcher.java
new file mode 100644
index 0000000000000000000000000000000000000000..f34c132d6e52e6f8006ea1000bbe3b5535fe74ff
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSMatcher.java
@@ -0,0 +1,86 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import java.io.Serializable;
+
+/**
+ *  Used by admin commands to select operations for cancellation or listing.
+ */
+public interface FileQoSMatcher extends Serializable {
+    /**
+     *  Used on cancellation to indicate the entry should be cancelled in its entirety
+     *  (as opposed to just the running adjustment associated with it).
+     */
+    boolean isForceRemoval();
+
+    /**
+     *  For short-circuiting the fuller match operation when the filter is looking to
+     *  match only a single pnfsId.
+     */
+    boolean isSimplePnfsMatch();
+
+    /**
+     *  @param operation to be matched by the filter,
+     *  @param map to translate references to names.
+     *  @return whether the operation matches or not.
+     */
+    boolean matches(FileQoSOperation operation, PoolInfoMap map);
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOpCheckpointRecord.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOpCheckpointRecord.java
new file mode 100644
index 0000000000000000000000000000000000000000..4843fdde6873501dcd94976b591282bb8b5428d8
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOpCheckpointRecord.java
@@ -0,0 +1,124 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import diskCacheV111.util.PnfsId;
+import org.dcache.qos.QoSException;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.data.QoSMessageType;
+
+/**
+ *  Wrapper for preparing {@link FileQoSOperation}s to be written to a simple text file and for
+ *  reading back the file entries into a new {@link FileQoSUpdate}.
+ */
+public final class FileQoSOpCheckpointRecord {
+  private static final String UNDEF = "null";
+
+  private PnfsId pnfsId;
+  private long size;
+  private String poolGroup;
+  private String storageUnit;
+  private String parent;
+
+  public FileQoSOpCheckpointRecord(FileQoSOperation operation, PoolInfoMap map) {
+    pnfsId = operation.getPnfsId();
+    size = operation.getSize();
+
+    Integer gindex = operation.getPoolGroup();
+    if (gindex != null) {
+      poolGroup = map.getGroup(gindex);
+    }
+
+    Integer sindex = operation.getStorageUnit();
+    if (sindex != null) {
+      storageUnit = map.getUnit(sindex);
+    }
+
+    Integer pindex = operation.getParent();
+    if (pindex != null) {
+      parent = map.getPool(sindex);
+    }
+  }
+
+  public FileQoSOpCheckpointRecord(String data) throws QoSException {
+    String[] parts = data.split("[|]");
+    if (parts.length != 5) {
+      throw new QoSException("FileQoSOpRecord " + data + " is corrupt.");
+    }
+    pnfsId = parts[0] == UNDEF ? null : new PnfsId(parts[0]);
+    size = Integer.valueOf(parts[1]);
+    poolGroup = parts[2] == UNDEF ? null : parts[2];
+    storageUnit = parts[3] == UNDEF ? null : parts[3];
+    parent = parts[4] == UNDEF ? null : parts[4];
+  }
+
+  public FileQoSUpdate toUpdate() {
+    QoSMessageType type = parent != null ?
+        QoSMessageType.POOL_STATUS_UP : QoSMessageType.QOS_MODIFIED;
+    FileQoSUpdate update = new FileQoSUpdate(pnfsId, parent, type, poolGroup,
+                                             storageUnit, false);
+    update.setSize(size);
+    return update;
+  }
+
+  public String toString() {
+    return pnfsId + "|" + size + "|" + poolGroup + "|" + storageUnit + "|" + parent;
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOperation.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOperation.java
new file mode 100644
index 0000000000000000000000000000000000000000..8b18e6c80fa268e4b2656751ca3aff9d1c71b176
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOperation.java
@@ -0,0 +1,500 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.collect.ImmutableSet;
+import diskCacheV111.util.CacheException;
+import diskCacheV111.util.PnfsId;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+import org.dcache.qos.QoSException;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.data.QoSAction;
+import org.dcache.qos.data.QoSMessageType;
+import org.dcache.qos.listeners.QoSAdjustmentListener;
+import org.dcache.qos.util.ExceptionMessage;
+import org.dcache.qos.vehicles.QoSAdjustmentRequest;
+import org.dcache.util.NonReindexableList;
+
+import static org.dcache.qos.data.QoSAction.VOID;
+
+/**
+ *  Object stored in the operation map.
+ *  <p/>
+ *  Since this table may grow very large, two strategies have been adopted to try to reduce
+ *  the memory footprint of each instance:
+ *  <p/>
+ *  <ol>
+ *    <li>The state enum is replaced by int values and a conversion method.</li>
+ *    <li>Apart from the PnfsId and the exception thrown by adjustment failure,
+ *        only int indices referencing the {@link PoolInfoMap} are stored.</li>
+ *  </ol>
+ *  <p/>
+ *  The latter choice is to minimize variable allocation to 4-byte primitives
+ *  rather than 8-byte object references. This will have some impact on
+ *  performance, but the trade-off is suggested by a decision to use only
+ *  a simple persistence model for rollback/recovery purposes and otherwise
+ *  rely on values stored in memory.
+ *  <p/>
+ *  Only those methods which are utilized by both the consumer thread in the operation
+ *  map and by the handler threads have been synchronized.
+ *  <p/>
+ *  For the purposes of efficiency, we allow purely read-only access (such as through the admin
+ *  interface or the checkpointing operation) to be unsynchronized.
+ */
+public final class FileQoSOperation {
+    /*
+     *  Stored state. Instead of using enum, to leave less of a memory footprint.
+     *  The map storing operation markers is expected to be very large.
+     *  Order is significant.
+     */
+    public static final int READY           = 0; // READY TO RUN VERIFICATION AGAIN
+    public static final int RUNNING         = 1; // VERIFICATION SUBMITTED TO THE EXECUTOR
+    public static final int DONE            = 2; // CURRENT ADJUSTMENT COMPLETED WITHOUT ERROR
+    public static final int CANCELED        = 3; // CURRENT ADJUSTMENT WAS TERMINATED BY USER
+    public static final int FAILED          = 4; // CURRENT ADJUSTMENT FAILED WITH EXCEPTION
+    public static final int ABORTED         = 5; // CANNOT DO ANYTHING FURTHER
+    public static final int UNINITIALIZED   = 6; // CONSTRUCTED BUT NOT YET CONFIGURED
+    public static final int SUSPENDED       = 7; // TEMPORARILY UNABLE TO RUN, WILL BE RESET TO READY
+
+    private static final String TO_STRING = "%s (%s)(%s %s)(parent %s, retried %s)";
+    private static final String TO_HISTORY_STRING = "%s (%s)(%s %s)(parent %s, retried %s) %s";
+
+    /*
+     *  Hidden marker for null, used with int->Integer autoboxing.
+     */
+    private static final int NIL = -19;
+
+    private final PnfsId      pnfsId;
+    private final long        size;
+
+    private long              lastUpdate;
+    private int               messageType;
+    private int               poolGroup;
+    private int               storageUnit;
+    private int               parent;
+    private int               source;
+    private int               target;
+    private int               state;
+    private int               retried;
+    private int               previousAction;
+    private int               action;
+
+    /**
+     *  Estimated number of adjustments left
+     */
+    private int               needed;
+
+    private Collection<Integer> tried;
+    private CacheException      exception;
+
+    public FileQoSOperation(PnfsId pnfsId,
+                            QoSMessageType type,
+                            Integer pgroup,
+                            Integer sunit,
+                            long size) {
+        this.pnfsId = pnfsId;
+        messageType = type.ordinal();
+        poolGroup = setNilForNull(pgroup);
+        storageUnit = setNilForNull(sunit);
+        this.size = size;
+        state = UNINITIALIZED;
+        needed = 0;
+        retried = 0;
+        parent = NIL;
+        source = NIL;
+        target = NIL;
+        previousAction = VOID.ordinal();
+        action = VOID.ordinal();
+        lastUpdate = System.currentTimeMillis();
+    }
+
+    public CacheException getException() {
+        return exception;
+    }
+
+    public long getLastUpdate() {
+        return lastUpdate;
+    }
+
+    public int getMessageType() {
+        return messageType;
+    }
+
+    public Integer getParent() {
+        return getNullForNil(parent);
+    }
+
+    public String getPrincipalPool(PoolInfoMap map) {
+        if (parent != NIL) {
+            return map.getPool(parent);
+        }
+
+        if (source != NIL) {
+            return map.getPool(source);
+        }
+
+        if (target != NIL) {
+            return map.getPool(target);
+        }
+
+        return "UNDEFINED";
+    }
+
+    public PnfsId getPnfsId() {
+        return pnfsId;
+    }
+
+    public Integer getPoolGroup() {
+        return getNullForNil(poolGroup);
+    }
+
+    public long getSize() { return size; }
+
+    public Integer getSource() {
+        return getNullForNil(source);
+    }
+
+    public synchronized int getState() {
+        return state;
+    }
+
+    public synchronized String getStateName() {
+        switch (state) {
+            case READY:
+                return "READY";
+            case RUNNING:
+                return "RUNNING";
+            case DONE:
+                return "DONE";
+            case CANCELED:
+                return "CANCELED";
+            case FAILED:
+                return "FAILED";
+            case ABORTED:
+                return "ABORTED";
+            case UNINITIALIZED:
+                return "UNINITIALIZED";
+            case SUSPENDED:
+                return "SUSPENDED";
+        }
+
+        throw new IllegalArgumentException("No such state: " + state);
+    }
+
+    public Integer getStorageUnit() {
+        return getNullForNil(storageUnit);
+    }
+
+    public Integer getTarget() {
+        return getNullForNil(target);
+    }
+
+    public Set<Integer> getTried() {
+        if (tried == null) {
+            return Collections.EMPTY_SET;
+        }
+        return ImmutableSet.copyOf(tried);
+    }
+
+    public boolean isBackground() {
+        return parent != NIL;
+    }
+
+    @VisibleForTesting
+    public void setLastUpdate(Long lastUpdate) {
+        this.lastUpdate = lastUpdate;
+    }
+
+    public void setSource(Integer source) {
+        this.source = setNilForNull(source);
+    }
+
+    public void setTarget(Integer target) {
+        this.target = setNilForNull(target);
+    }
+
+    public String toString() {
+        return String.format(TO_STRING,
+                             FileQoSUpdate.getFormattedDateFromMillis(lastUpdate),
+                             pnfsId, actionName(previousAction),
+                             getStateName(), parent == NIL ? "none" : parent, retried);
+    }
+
+    public String toHistoryString() {
+        return String.format(TO_HISTORY_STRING,
+                             FileQoSUpdate.getFormattedDateFromMillis(lastUpdate),
+                             pnfsId, actionName(previousAction),
+                             getStateName(), parent == NIL ? "none" : parent,
+                             retried, exception == null ? "" : new ExceptionMessage(exception));
+    }
+
+    public synchronized void abortOperation() {
+        state = ABORTED;
+        lastUpdate = System.currentTimeMillis();
+        source = NIL;
+        target = NIL;
+    }
+
+    public void addSourceToTriedLocations() {
+        if (source == NIL) {
+            return;
+        }
+
+        if (tried == null) {
+            tried = new HashSet<>();
+        }
+
+        tried.add(source);
+    }
+
+    public void addTargetToTriedLocations() {
+        if (target == NIL) {
+            return;
+        }
+
+        if (tried == null) {
+            tried = new HashSet<>();
+        }
+
+        tried.add(target);
+    }
+
+    public synchronized boolean cancel(boolean forceRemoval) {
+        if (isTerminal()) {
+            return false;
+        }
+
+        state = CANCELED;
+
+        if (forceRemoval) {
+            action = VOID.ordinal();
+        }
+
+        lastUpdate = System.currentTimeMillis();
+        retried = 0;
+
+        return true;
+    }
+
+    public synchronized QoSAction getAction() {
+        return QoSAction.values()[action];
+    }
+
+    public int getRetried() {
+        return retried;
+    }
+
+    public int getNeededAdjustments() { return needed; }
+
+    public void incrementRetried() {
+        ++retried;
+    }
+
+    public synchronized boolean isInTerminalState() {
+        return isTerminal();
+    }
+
+    /**
+     *  Synchronized on the operation instance, so it can return without
+     *  submitting request if the operation has in the interim been cancelled.
+     *  Also sets the action under lock.
+     */
+    public synchronized void requestAdjustment(QoSAdjustmentRequest request,
+                                               QoSAdjustmentListener adjustmentListener)
+            throws QoSException {
+        if (isTerminal()) {
+            return;
+        }
+
+        setAction(request.getAction());
+        adjustmentListener.fileQoSAdjustmentRequested(request);
+    }
+
+    public synchronized void resetOperation() {
+        state = READY;
+        exception = null;
+        lastUpdate = System.currentTimeMillis();
+    }
+
+    public void resetSourceAndTarget() {
+        retried = 0;
+        source = NIL;
+        target = NIL;
+    }
+
+    public void setNeeded(int needed) {
+        /*
+         *  Once needed has been determined to be greater than 1,
+         *  each successive verification will decrement this count.
+         *  The original count needs to be preserved, however,
+         *  so that the task does not inappropriately get moved
+         *  to the head of the queue.
+         */
+        this.needed = Math.max(this.needed, needed);
+    }
+
+    public void setParentOrSource(Integer pool, boolean isParent) {
+        if (isParent) {
+            parent = setNilForNull(pool);
+        } else {
+            source = setNilForNull(pool);
+        }
+    }
+
+    public synchronized void setState(int state) {
+        this.state = state;
+    }
+
+    public synchronized void setState(String state) {
+        switch (state) {
+            case "READY":       this.state = READY;     break;
+            case "RUNNING":     this.state = RUNNING;   break;
+            case "SUSPENDED":   this.state = SUSPENDED; break;
+            case "DONE":        this.state = DONE;      break;
+            case "CANCELED":    this.state = CANCELED;  break;
+            case "FAILED":      this.state = FAILED;    break;
+            case "ABORTED":     this.state = ABORTED;   break;
+            case "UNINITIALIZED":
+                throw new IllegalArgumentException("Cannot set "
+                                + "operation to UNINITIALIZED.");
+            default:
+                throw new IllegalArgumentException("No such state: " + state);
+        }
+    }
+
+    /**
+     *  When another operation for this file/pnfsid is to be
+     *  queued, we overwrite the storage unit field on this one, in case
+     *  there is a storage unit scan being requested.
+     */
+    public synchronized void updateOperation(FileQoSOperation operation) {
+        if (operation.storageUnit != NIL) {
+            storageUnit = operation.storageUnit;
+        }
+    }
+
+    public synchronized boolean updateOperation(CacheException error) {
+        if (isTerminal()) {
+            return false;
+        }
+
+        if (error != null) {
+            exception = error;
+            state = FAILED;
+        } else {
+            state = DONE;
+            retried = 0;
+        }
+
+        lastUpdate = System.currentTimeMillis();
+        previousAction = action;
+        return true;
+    }
+
+    public synchronized void voidOperation() {
+        if (!isTerminal()) {
+            state = DONE;
+        }
+        retried = 0;
+        source = NIL;
+        target = NIL;
+        tried = null;
+        lastUpdate = System.currentTimeMillis();
+        previousAction = action;
+        action = VOID.ordinal();
+    }
+
+    /*
+     * Called under synchronization except during testing.
+     */
+    @VisibleForTesting
+    void setAction(QoSAction action) {
+        previousAction = this.action;
+        this.action = action.ordinal();
+    }
+
+    private Integer getNullForNil(int value) {
+        return value == NIL ? null : value;
+    }
+
+    private boolean isTerminal() {
+        switch (state) {
+            case DONE:
+            case CANCELED:
+            case FAILED:
+            case ABORTED:
+                return true;
+            default:
+                return false;
+        }
+    }
+
+    private synchronized String actionName(int action) {
+        return action == NIL ? "NOOP" : QoSAction.values()[action].toString();
+    }
+
+    private int setNilForNull(Integer value) {
+        return value == null ? NIL : value == NonReindexableList.MISSING_INDEX ? NIL : value;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOperationMap.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOperationMap.java
new file mode 100644
index 0000000000000000000000000000000000000000..901b351893718023bd114bd55c7f2ffb47878767
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/FileQoSOperationMap.java
@@ -0,0 +1,1094 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.annotations.VisibleForTesting;
+import diskCacheV111.util.CacheException;
+import diskCacheV111.util.PnfsId;
+import dmg.cells.nucleus.CellInfoProvider;
+import java.io.PrintWriter;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.Map;
+import java.util.NoSuchElementException;
+import java.util.Queue;
+import java.util.Set;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.stream.Collectors;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.data.QoSMessageType;
+import org.dcache.qos.services.verifier.handlers.CheckpointHandler;
+import org.dcache.qos.services.verifier.handlers.FileQoSOperationHandler;
+import org.dcache.qos.services.verifier.util.QoSVerificationTask;
+import org.dcache.qos.services.verifier.util.QoSVerifierCounters;
+import org.dcache.qos.util.CacheExceptionUtils;
+import org.dcache.qos.util.CacheExceptionUtils.FailureType;
+import org.dcache.qos.util.QoSHistory;
+import org.dcache.util.RunnableModule;
+
+import static org.dcache.qos.data.QoSAction.VOID;
+import static org.dcache.qos.data.QoSMessageType.CHECK_CUSTODIAL_ONLINE;
+import static org.dcache.qos.data.QoSMessageType.POOL_STATUS_DOWN;
+import static org.dcache.qos.data.QoSMessageType.POOL_STATUS_UP;
+import static org.dcache.qos.services.verifier.data.FileQoSOperation.ABORTED;
+import static org.dcache.qos.services.verifier.data.FileQoSOperation.CANCELED;
+import static org.dcache.qos.services.verifier.data.FileQoSOperation.DONE;
+import static org.dcache.qos.services.verifier.data.FileQoSOperation.FAILED;
+import static org.dcache.qos.services.verifier.data.FileQoSOperation.RUNNING;
+import static org.dcache.qos.services.verifier.data.FileQoSOperation.SUSPENDED;
+import static org.dcache.qos.services.verifier.data.PoolInfoMap.ONLINE_CUSTODIAL_SCAN_INDEX;
+
+/**
+ *  The main locus of operations for verification.</p>
+ *  <p/>
+ *  Tracks all operations on individual files via an instance of {@link FileQoSOperation},
+ *  whose lifecycle is initiated by the the arrival of a message, and which terminates when
+ *  all work on the associated pnfsid has completed or has been aborted/cancelled.
+ *  <p/>
+ *  When more than one event references a pnfsid which has a current entry in the map,
+ *  only the current entry's storage unit is updated. This is because when the current
+ *  adjustment finishes, another verification is always done.  When the file's requirements
+ *  have been satisfied, the operation is voided to enable removal from the map.
+ *  <p/>
+ *  The runnable logic entails scanning the queues in order to post-process terminated
+ *  adjustments, and to launch new adjustment requests for eligible operations if there are
+ *  slots available.  The number of slots for running adjustments should not exceed the
+ *  number of maxRunning tasks chosen for the adjustment service.
+ *  <p/>
+ *  Fairness is defined here as the availability of a second replica for a given file.
+ *  This means that operations are processed FIFO, but those requiring more than one
+ *  adjustment are requeued after each adjustment.
+ *  <p/>
+ *  The map distinguishes between three classes of requests, to which it dedicates three
+ *  separate queues:  new cache locations and cancellations, pool scan verifications,
+ *  and qos modifications. A simple clock algorithm is used to select operations from
+ *  them to run.
+ *  <p/>
+ *  Because of the potential for long-running staging operations to starve out the running
+ *  queue, an allocation quota (configurable) is used to determine if more staging requests
+ *  can be sent; in the case where the quota has been reached, the running operation is
+ *  suspended. The operation then gets placed on a fourth queue and is reset to ready
+ *  for retry.  The fourth queue is included in the clock selection algorithm, so that there
+ *  is a fair chance that the suspended operations will be reattempted reasonably early when
+ *  running slots have been freed.
+ *  <p/>
+ *  A periodic checkpointer, if on, writes out selected data from each operation entry.
+ *  In the case of crash and restart of this domain, the checkpoint file is reloaded into memory.
+ *  <p/>
+ *  Access to the index map is not synchronized, because it is implemented using a
+ *  ConcurrentHashMap.  This is the most efficient solution for allowing multiple inserts
+ *  and reads to take place concurrently with any consumer thread removes.  All updating
+ *  of operation state or settings in fact is done through an index read, since the necessary
+ *  synchronization of those values is handled inside the operation object.  Only the initial
+ *  queueing and cancellation requests require additional synchronization.
+ *  <p/>
+ *  However, since index reads are not blocked, the list and count methods, which filter
+ *  against the index (and not the queues), along with the checkpointer, which attempts
+ *  to persist live operations, will return or write out a dirty snapshot which is only
+ *  an approximation of state, so as not to block consumer processing.
+ *  <p/>
+ *  Class is not marked final for stubbing/mocking purposes.
+ */
+public class FileQoSOperationMap extends RunnableModule implements CellInfoProvider {
+    private static final String MISSING_ENTRY = "Entry for %s + was removed from map before "
+                                    + "completion of outstanding operation.";
+
+    private static final String COUNTS_FORMAT = "    %-24s %15s\n";
+
+    /*
+     *  The indices of the READY queues.
+     */
+    private static final int LOC = 0; // from location or cancellation request
+    private static final int SCN = 1; // from pool scan request
+    private static final int MOD = 2; // from qos modification request
+    private static final int STG = 3; // staging request temporarily rejected because of quota
+
+    final class Checkpointer implements Runnable {
+        long     last;
+        long     expiry;
+        TimeUnit expiryUnit;
+        String   path;
+        Thread   thread;
+
+        volatile boolean running        = false;
+        volatile boolean resetInterrupt = false;
+        volatile boolean runInterrupt   = false;
+
+        public void run() {
+            running = true;
+
+            while (running) {
+                try {
+                    synchronized (this) {
+                        wait(expiryUnit.toMillis(expiry));
+                    }
+                } catch (InterruptedException e) {
+                    if (resetInterrupt) {
+                        LOGGER.trace("Checkpoint reset: expiry {} {}.",
+                                     expiry, expiryUnit);
+                        resetInterrupt = false;
+                        continue;
+                    }
+
+                    if (!runInterrupt) {
+                        LOGGER.info("Checkpointer wait was interrupted; exiting.");
+                        break;
+                    }
+                    runInterrupt = false;
+                }
+
+                if (running) {
+                    save();
+                }
+            }
+        }
+
+        /**
+         * Writes out data from the operation map to the checkpoint file.
+         */
+        @VisibleForTesting
+        void save() {
+            long start = System.currentTimeMillis();
+            long count = checkpointHandler.save(path, index.values().iterator());
+            last = System.currentTimeMillis();
+            counters.recordCheckpoint(last, last - start, count);
+        }
+    }
+
+    /**
+     *  Handles canceled operations.
+     *  <p/>
+     *  First, it appends the incoming operations to the appropriate queue.
+     *  Next, it handles cancellations, and then searches the running queue to see
+     *  which adjustments have completed. All terminated operations are passed
+     *  to post-processing, which determines whether the operation can be
+     *  permanently removed or if needs to be re-queued.
+     */
+    class TerminalOperationProcessor {
+        private Collection<FileQoSOperation> toProcess = new ArrayList<>();
+
+        void processTerminated() {
+            appendIncoming();
+            gatherCanceled();
+            gatherTerminated();
+
+            LOGGER.trace("Found {} terminated operations.", toProcess.size());
+
+            /*
+             *  Only non-voided operations will remain in the map after this call.
+             *  If the operation is re-queued because of a retriable failure,
+             *  it goes to the head of the queue; else it is appended.
+             */
+            toProcess.stream().forEach(this::postProcess);
+            toProcess.clear();
+        }
+
+        private void appendIncoming() {
+            synchronized (incoming) {
+                while (true) {
+                    try {
+                        enqueue(incoming.remove(), false);
+                    } catch (NoSuchElementException e) {
+                        break;
+                    }
+                }
+            }
+        }
+
+        /**
+         *  This is a potentially expensive operation (O[n] in the queue size),
+         *  but should be called relatively infrequently.
+         */
+        private void cancel(Queue<FileQoSOperation> queue,
+                            Collection<FileQoSMatcher> filters) {
+            for (Iterator<FileQoSOperation> i = queue.iterator(); i.hasNext();) {
+                FileQoSOperation operation = i.next();
+                for (FileQoSMatcher filter : filters) {
+                    if (filter.matches(operation, poolInfoMap)) {
+                        i.remove();
+                        removeIfStaging(operation.getPnfsId());
+                        if (operation.cancel(filter.isForceRemoval())) {
+                            toProcess.add(operation);
+                        }
+                        break;
+                    }
+                }
+            }
+        }
+
+        private void gatherCanceled() {
+            Collection<FileQoSMatcher> filters = new ArrayList<>();
+
+            synchronized (cancelFilters) {
+                filters.addAll(cancelFilters);
+                cancelFilters.clear();
+            }
+
+            cancel(running, filters);
+            for (Deque<FileQoSOperation> queue : queues) {
+                cancel(queue, filters);
+            }
+        }
+
+        private void gatherTerminated() {
+            for (Iterator<FileQoSOperation> i = running.iterator(); i.hasNext();) {
+                FileQoSOperation operation = i.next();
+                switch (operation.getState()) {
+                    case SUSPENDED:
+                        operation.resetSourceAndTarget();
+                        operation.resetOperation();
+                        queues[STG].addLast(operation);
+                        i.remove();
+                        break;
+                    case RUNNING:
+                        break;
+                    default:
+                        removeIfStaging(operation.getPnfsId());
+                        i.remove();
+                        toProcess.add(operation);
+                        break;
+                }
+            }
+        }
+
+        /**
+         *  Exceptions are analyzed to determine if any more work can be done.
+         *  In the case of fatal errors, an alarm is sent.  Operations that have
+         *  not failed fatally (aborted) and are not VOID are reset to ready;
+         *  otherwise, the operation record will have been removed when this method returns.
+         */
+        private void postProcess(FileQoSOperation operation) {
+            String pool = operation.getPrincipalPool(poolInfoMap);
+            Integer sindex = operation.getSource();
+            Integer tindex = operation.getTarget();
+            String source = sindex == null ? null : poolInfoMap.getPool(sindex);
+            String target = tindex == null ? null : poolInfoMap.getPool(tindex);
+
+            boolean retry = false;
+            int opState = operation.getState();
+
+            switch (opState) {
+                case FAILED:
+                    FailureType type =
+                        CacheExceptionUtils.getFailureType(operation.getException(),
+                            operation.getAction());
+                    switch (type) {
+                        case NEWSOURCE:
+                            operation.addSourceToTriedLocations();
+                            operation.resetSourceAndTarget();
+                            retry = true;
+                            break;
+                        case NEWTARGET:
+                            operation.addTargetToTriedLocations();
+                            operation.resetSourceAndTarget();
+                            retry = true;
+                            break;
+                        case RETRIABLE:
+                            operation.incrementRetried();
+                            if (operation.getRetried() < maxRetries) {
+                                retry = true;
+                                break;
+                            }
+
+                            /*
+                             *  We don't really know here whether the source
+                             *  or the target is bad.  The best we can do is
+                             *  retry until we have exhausted all the possible
+                             *  pool group members.
+                             */
+                            operation.addTargetToTriedLocations();
+                            if (source != null) {
+                                operation.addSourceToTriedLocations();
+                            }
+
+                            /*
+                             *  All readable pools in the pool group.
+                             */
+                            int groupMembers = poolInfoMap.getMemberPools (operation.getPoolGroup(),
+                                false).size();
+
+                            if (groupMembers > operation.getTried().size()) {
+                                operation.resetSourceAndTarget();
+                                retry = true;
+                                break;
+                            }
+
+                            /**
+                             * fall through; no more possibilities left
+                             */
+                        case FATAL:
+                            operation.addTargetToTriedLocations();
+                            if (source != null) {
+                                operation.addSourceToTriedLocations();
+                            }
+
+                            Set<String> tried = operation.getTried().stream()
+                                                                    .map(poolInfoMap::getPool)
+                                                                    .collect(Collectors.toSet());
+                            operationHandler.operationAborted(operation, pool, tried, maxRetries);
+                            operationHandler.handleQoSActionCompleted(operation.getPnfsId(),
+                                                                      opState,
+                                                                      operation.getAction(),
+                                                                      operation.getException());
+                            operation.abortOperation();
+
+                            /*
+                             * Only fatal errors count as operation failures.
+                             */
+                            counters.incrementFailed(pool);
+                            break;
+                        default:
+                            operation.abortOperation();
+                            LOGGER.error("{}: No such failure type: {}.", operation.getPnfsId(), type);
+                    }
+                    break;
+                case DONE:
+                    /*
+                     *  Only count DONE, not CANCELED
+                     */
+                    counters.increment(source, target, operation.getAction());
+
+                    /*
+                     *  fall through to notify and reset
+                     */
+                case CANCELED:
+                    operationHandler.handleQoSActionCompleted(operation.getPnfsId(),
+                                                              opState,
+                                                              operation.getAction(),
+                                                              operation.getException());
+                    operation.setSource(null);
+                    operation.setTarget(null);
+                    break;
+            }
+
+            /*
+             *  The synchronization protects against the situation where an incoming file
+             *  update with this id sees the operation is in the index but does not realize
+             *  it is about to be removed, thus skipping the creation of a fresh instance
+             *  of the operation.
+             *
+             *  If the operation has been aborted here, or marked VOID during verification,
+             *  it is removed.
+             */
+            boolean abort = operation.getState() == ABORTED;
+            synchronized (incoming) {
+                if (abort || (!retry && operation.getAction() == VOID)) {
+                    remove(operation.getPnfsId(), abort);
+                } else {
+                    operation.resetOperation();
+                    enqueue(operation, retry);
+                }
+            }
+        }
+    }
+
+    /**
+     *  Selects from waiting operations and submits them for task execution.
+     */
+    class ReadyOperationProcessor {
+        int current = 0;
+
+        void processReady() {
+            int available = maxRunning - running.size();
+            int empty = 0;
+
+            LOGGER.trace("Available to run: {}", available);
+
+            /*
+             *  Simple clock algorithm
+             */
+            while (available > 0 && empty < queues.length) {
+                FileQoSOperation operation = queues[current].poll();
+                current = (current + 1) % queues.length;
+                if (operation == null) {
+                    ++empty;
+                    continue;
+                }
+                submit(operation);
+                --available;
+            }
+        }
+    }
+
+    /**
+     *  Accessed mostly for retrieval of the operation.  Writes occur on the handler threads
+     *  adding operations and removes occur on the consumer thread.
+     *  <p/>
+     *  Default sharding is probably OK for the present purposes, even with a large maximum
+     *  running operations value, so we have not specified the constructor parameters.
+     */
+    final Map<PnfsId, FileQoSOperation> index = new ConcurrentHashMap<>();
+
+    /**
+     *  These queues are entirely used by the consumer thread. Hence
+     *      there is no need for synchronization on any of them.
+     *  <p/>
+     *  The order for election to run is FIFO.  The operation is removed from these
+     *  waiting queues and added to running; an attempt at fairness is made by
+     *  appending it back to these queues when it successfully terminates, if more work
+     *  is to be done, but to restoring it to the head of the queue if there is
+     *  a retriable failure.
+     */
+    final Deque<FileQoSOperation>[] queues = new Deque[] {
+        new LinkedList<FileQoSOperation>(), // LOC
+        new LinkedList<FileQoSOperation>(), // SCN
+        new LinkedList<FileQoSOperation>(), // MOD
+        new LinkedList<FileQoSOperation>()  // STG
+    };
+
+    /**
+     *  Also used exclusively by the consumer thread.
+     */
+    final Queue<FileQoSOperation> running = new LinkedList<>();
+
+    /**
+     *  Queue of incoming/ready operations.  This buffer is shared between the handler
+     *  threads and consumer thread, to avoid synchronizing the internal queues.
+     *  The incoming operations are appended to the latter during the consumer scan.
+     */
+    final Queue<FileQoSOperation> incoming = new LinkedList<>();
+
+    /**
+     *  For tracking the current number of running operations that are staging.
+     *  Used by consumer thread and verifier threads.
+     */
+    final Set<PnfsId> staging = new HashSet<>();
+
+    /**
+     *  List of filters for cancelling operations.  This buffer is shared between
+     *  the caller and the consumer thread.
+     *  <p/>
+     *  Processing of cancellation is done during the consumer scan, as it would have
+     *  to be atomic anyway.  This avoids once again any extra locking on the internal queues.
+     */
+    final Collection<FileQoSMatcher> cancelFilters = new ArrayList<>();
+
+    /**
+     *  For recovery.
+     */
+    @VisibleForTesting
+    final Checkpointer checkpointer = new Checkpointer();
+
+    /**
+     *  The consumer thread logic is encapsulated in these two processors.
+     */
+    final TerminalOperationProcessor terminalProcessor = new TerminalOperationProcessor();
+    final ReadyOperationProcessor readyProcessor = new ReadyOperationProcessor();
+
+    /**
+     *  For reporting operations terminated or canceled while the consumer thread
+     *  is doing work outside the wait monitor.
+     */
+    final AtomicInteger  signalled = new AtomicInteger(0);
+
+    private PoolInfoMap poolInfoMap;
+    private CheckpointHandler checkpointHandler;
+
+    /*
+     *  A callback to the handler.  Note, this creates a cyclical dependency in the spring context.
+     *  The rationale here is that the map controls the terminal logic for verification
+     *  operations on a single consumer thread, and thus needs to notify other components (such
+     *  as the engine or scanner) of termination.  It makes sense that only the handler
+     *  would communicate with the "outside", and that the map should be internal to this service.
+     */
+    private FileQoSOperationHandler operationHandler;
+
+    /**
+     *  This should be set to something <= the maxRunning value for the adjuster map in order
+     *  to keep the memory footprint bounded in the latter. Otherwise we risk doubling
+     *  the index held here.
+     */
+    private int maxRunning = 200;
+
+    /**
+     *  Max number of running operations whose action can be WAIT_FOR_STAGE.
+     *  This is so we do not block throughput of other types of adjustments.
+     */
+    private double maxStaging = 0.5;
+
+    /**
+     *  Meaning for a given source-target pair. When a source or target is changed,
+     *  the retry count is reset to 0.
+     */
+    private int maxRetries  = 1;
+
+    /**
+     *  Statistics collection.
+     */
+    private QoSVerifierCounters counters;
+    private QoSHistory history;
+
+    /**
+     *  Degenerate call to {@link #cancel(FileQoSMatcher)}.  Used by admin command.
+     *
+     *  @param pnfsId single operation to cancel.
+     *  @param remove true if the entire entry is to be removed from the
+     *                map at the next scan.  Otherwise, cancellation pertains
+     *                only to the current (running) verification.
+     */
+    public void cancel(PnfsId pnfsId, boolean remove) {
+        FileQoSFilter filter = new FileQoSCancelFilter();
+        filter.setPnfsIds(pnfsId.toString());
+        filter.setForceRemoval(remove);
+        cancel(filter);
+    }
+
+    /**
+     *  Batch version of cancel.  In this case, the filter will indicate whether
+     *  the operation should be cancelled <i>in toto</i> or only the current verification.
+     *  The actual scan is done on the consumer thread.
+     */
+    public void cancel(FileQoSMatcher filter) {
+        synchronized (cancelFilters) {
+            cancelFilters.add(filter);
+        }
+        signalAll();
+    }
+
+    /**
+     *  Cancel operations with this pool as parent, source or target.
+     */
+    public void cancelFileOpForPool(String pool, boolean onlyParent) {
+        FileQoSFilter fileFilter = new FileQoSCancelFilter();
+        fileFilter.setParent(pool);
+        fileFilter.setForceRemoval(true);
+        cancel(fileFilter);
+        if (!onlyParent) {
+            fileFilter = new FileQoSCancelFilter();
+            fileFilter.setSource(pool);
+            fileFilter.setForceRemoval(true);
+            cancel(fileFilter);
+            fileFilter = new FileQoSCancelFilter();
+            fileFilter.setTarget(pool);
+            fileFilter.setForceRemoval(true);
+            cancel(fileFilter);
+        }
+    }
+
+    /**
+     *  Checks to see if the number of staging operations exceeds the quota.
+     *  If so, sets the operation state to suspended; else it adds the id to
+     *  the stage list.
+     *
+     *  @return true if added to the staging list, false if suspended.
+     */
+    public boolean canStage(FileQoSOperation operation) {
+        boolean accepted;
+
+        synchronized (staging) {
+            if ((double)staging.size() < (maxStaging * (double)maxRunning)) {
+                staging.add(operation.getPnfsId());
+                accepted = true;
+            } else {
+                operation.setState(SUSPENDED);
+                accepted = false;
+            }
+        }
+
+        if (!accepted) {
+            signalAll();
+        }
+
+        return accepted;
+    }
+
+    /**
+     *  Used by admin command.
+     *
+     *  @return number of operations matching the filter.
+     */
+    public long count(FileQoSMatcher filter, StringBuilder builder) {
+        long total = 0;
+        Iterator<FileQoSOperation> iterator = index.values().iterator();
+
+        Map<String, AtomicLong> summary = builder == null ? null : new HashMap<>();
+
+        while (iterator.hasNext()) {
+            FileQoSOperation operation = iterator.next();
+            if (filter.matches(operation, poolInfoMap)) {
+                ++total;
+
+                if (summary == null) {
+                    continue;
+                }
+
+                String pool = operation.getPrincipalPool(poolInfoMap);
+                AtomicLong count = summary.get(pool);
+                if (count == null) {
+                    count = new AtomicLong(0);
+                    summary.put(pool, count);
+                }
+                count.incrementAndGet();
+            }
+        }
+
+        if (summary != null) {
+            summary.entrySet()
+                   .stream()
+                   .forEach((e) -> builder.append(String.format(COUNTS_FORMAT,
+                                   e.getKey(), e.getValue())));
+        }
+
+        return total;
+    }
+
+    public FileQoSOperation getOperation(PnfsId pnfsId) {
+        return index.get(pnfsId);
+    }
+
+    public void getInfo(PrintWriter pw) {
+        pw.println(infoMessage());
+    }
+
+    public String infoMessage() {
+        StringBuilder info = new StringBuilder();
+        info.append(String.format("maximum concurrent operations %s\n"
+                + "maximum staging allocation %s\n"
+                + "maximum retries on failure %s\n\n",
+            maxRunning,
+            maxStaging,
+            maxRetries));
+        info.append(String.format("sweep interval %s %s\n",
+            timeout,
+            timeoutUnit));
+        info.append(String.format("checkpoint interval %s %s\n"
+                + "checkpoint file path %s\n",
+            checkpointer.expiry,
+            checkpointer.expiryUnit,
+            checkpointer.path));
+        info.append(String.format("task launch delay %s \n\n",
+            operationHandler.getLaunchDelay()));
+
+        counters.appendCounts(info);
+
+        info.append(String.format("\nQUEUES\n%-30s %15s\n%-30s %15s\n"
+                + "%-30s %15s\n%-30s %15s\n%-30s %15s\n\n",
+            "RUNNING", running.size(),
+            "READY (LOCATION)", queues[LOC].size(),
+            "READY (POOL SCAN)", queues[SCN].size(),
+            "READY (MODIFY QOS)", queues[MOD].size(),
+            "READY (STAGE)", queues[STG].size()));
+
+        return info.toString();
+    }
+
+    @Override
+    public void initialize() {
+        super.initialize();
+        startCheckpointer();
+    }
+
+    public boolean isCheckpointingOn() {
+        return checkpointer.running;
+    }
+
+    /**
+     *  Used by admin command.
+     */
+    public String list(FileQoSMatcher filter, int limit) {
+        StringBuilder builder = new StringBuilder();
+        Iterator<FileQoSOperation> iterator = index.values().iterator();
+
+        int total = 0;
+
+        while (iterator.hasNext()) {
+            FileQoSOperation operation = iterator.next();
+            if (filter.matches(operation, poolInfoMap)) {
+                ++total;
+                builder.append(operation).append("\n");
+            }
+
+            if (total >= limit) {
+                break;
+            }
+        }
+
+        if (total == 0) {
+            builder.append("NO (MATCHING) OPERATIONS.\n");
+        } else {
+            builder.append("TOTAL OPERATIONS:\t\t").append(total).append("\n");
+        }
+        return builder.toString();
+    }
+
+    /**
+     *  @return true if add returns true.
+     */
+    public boolean register(FileQoSUpdate data) {
+        PnfsId pnfsId = data.getPnfsId();
+        Integer gunit = poolInfoMap.getGroupIndex(data.getEffectivePoolGroup());
+        Integer sunit = poolInfoMap.getUnitIndex(data.getStorageUnit());
+        QoSMessageType type = data.getMessageType();
+        FileQoSOperation operation
+            = new FileQoSOperation(pnfsId, type, gunit, sunit, data.getSize());
+        boolean isParent = type == POOL_STATUS_DOWN ||
+                           type == POOL_STATUS_UP ||
+                           type == CHECK_CUSTODIAL_ONLINE;
+        int poolIndex = type == CHECK_CUSTODIAL_ONLINE ? ONLINE_CUSTODIAL_SCAN_INDEX :
+            poolInfoMap.getPoolIndex(data.getPool());
+        operation.setParentOrSource(poolIndex, isParent);
+        operation.resetOperation();
+        LOGGER.debug("register, before add:  operation group is {}.", operation.getPoolGroup());
+        return add(pnfsId, operation);
+    }
+
+    /**
+     *  Reads in the checkpoint file.  Creates one if it does not exist.
+     */
+    public void reload() {
+        checkpointHandler.load(checkpointer.path);
+    }
+
+    /**
+     *  Used by admin command.
+     *
+     *  Called after a change to the checkpoint path and/or interval.
+     *  Interrupts the thread so that it resumes with the new settings.
+     */
+    public void reset() {
+        if (isCheckpointingOn()) {
+            checkpointer.resetInterrupt = true;
+            checkpointer.thread.interrupt();
+        }
+    }
+
+    /**
+     *  The consumer thread. When notified or times out, iterates over the queues to
+     *  check the state of running operations and to submit waiting operations if there
+     *  are open slots.  Removes completed operations.
+     *  <p/>
+     *  Note that since the scan takes place outside of the monitor, the signals sent
+     *  by various update methods will not be caught before the current thread is inside
+     *  {@link #await}; for this reason, a counter is used and reset to 0 before each scan.
+     *  No wait occurs if the counter is non-zero after the scan.
+     */
+    public void run() {
+        try {
+            while (!Thread.interrupted()) {
+                LOGGER.trace("Calling scan.");
+
+                signalled.set(0);
+
+                scan();
+
+                if (signalled.get() > 0) {
+                    /*
+                     *  Give the operations completed during the scan a chance
+                     *  to free slots immediately, if possible, by rescanning now.
+                     */
+                    LOGGER.trace("Scan complete, received {} signals; "
+                                    + "rechecking for requeued operations ...",
+                                    signalled.get());
+                    continue;
+                }
+
+                if (Thread.interrupted()) {
+                    break;
+                }
+
+                LOGGER.trace("Scan complete, waiting ...");
+                await();
+            }
+        } catch (InterruptedException e) {
+            LOGGER.trace("Consumer was interrupted.");
+        }
+
+        LOGGER.info("Exiting file operation consumer.");
+        clear();
+
+        LOGGER.info("File operation queues and index cleared.");
+    }
+
+    /**
+     *  Used by admin command.
+     *  <p/>
+     *  If the checkpointing thread is running, interrupts the wait so that it calls
+     *  save immediately.  If it is off, it just calls save. (Note:  the latter is
+     *  done on the caller thread; this is used mainly for testing.  For the admin
+     *  command, this method is disallowed if checkpointing is off.)
+     */
+    public void runCheckpointNow() {
+        if (isCheckpointingOn()) {
+            checkpointer.runInterrupt = true;
+            checkpointer.thread.interrupt();
+        } else {
+            checkpointer.save();
+        }
+    }
+
+    /**
+     *   Operation sweep: the main queue update sequence (run by the consumer).
+     */
+    @VisibleForTesting
+    public void scan() {
+        long start = System.currentTimeMillis();
+        terminalProcessor.processTerminated();
+        readyProcessor.processReady();
+        long end = System.currentTimeMillis();
+        counters.recordSweep(end, end - start);
+    }
+
+    public void setCheckpointExpiry(long checkpointExpiry) {
+        checkpointer.expiry = checkpointExpiry;
+    }
+
+    public void setCheckpointExpiryUnit(TimeUnit checkpointExpiryUnit) {
+        checkpointer.expiryUnit = checkpointExpiryUnit;
+    }
+
+    public void setCheckpointFilePath(String checkpointFilePath) {
+        checkpointer.path = checkpointFilePath;
+    }
+
+    public void setCheckpointHandler(CheckpointHandler checkpointHandler) {
+        this.checkpointHandler = checkpointHandler;
+    }
+
+    public void setCounters(QoSVerifierCounters counters) {
+        this.counters = counters;
+    }
+
+    public void setHistory(QoSHistory history) {
+        this.history = history;
+    }
+
+    public void setMaxRetries(int maxRetries) {
+        this.maxRetries = maxRetries;
+    }
+
+    public void setMaxRunning(int maxRunning) {
+        this.maxRunning = maxRunning;
+    }
+
+    public void setMaxStaging(double maxStaging) {
+        this.maxStaging = maxStaging;
+    }
+
+    public void setOperationHandler(FileQoSOperationHandler operationHandler) {
+        this.operationHandler = operationHandler;
+    }
+
+    public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+        this.poolInfoMap = poolInfoMap;
+    }
+
+    @Override
+    public void shutdown() {
+        stopCheckpointer();
+        super.shutdown();
+    }
+
+    public long size() {
+        return index.size();
+    }
+
+    public void startCheckpointer() {
+        checkpointer.thread = new Thread(checkpointer, "Checkpointing");
+        checkpointer.thread.start();
+    }
+
+    public void stopCheckpointer() {
+        checkpointer.running = false;
+        if (checkpointer.thread != null) {
+            checkpointer.thread.interrupt();
+        }
+    }
+
+    /**
+     *  Terminal update.
+     */
+    public void updateOperation(PnfsId pnfsId, CacheException error) {
+        FileQoSOperation operation = index.get(pnfsId);
+
+        if (operation == null) {
+            throw new IllegalStateException(String.format(MISSING_ENTRY, pnfsId));
+        }
+
+        if (operation.updateOperation(error)) {
+            signalAll();
+        }
+    }
+
+    /**
+     *  Terminal update.
+     */
+    public void voidOperation(PnfsId pnfsId) {
+        FileQoSOperation operation = index.get(pnfsId);
+
+        if (operation == null) {
+            return;
+        }
+
+        operation.voidOperation();
+        signalAll();
+    }
+
+    @VisibleForTesting
+    void submit(FileQoSOperation operation) {
+        operation.setState(RUNNING);
+        running.add(operation);
+        new QoSVerificationTask(operation.getPnfsId(),
+                                operation.getRetried(),
+                                operationHandler).submit();
+    }
+
+    private boolean add(PnfsId pnfsId, FileQoSOperation operation) {
+        synchronized (incoming) {
+            FileQoSOperation present = index.get(pnfsId);
+
+            if (present != null) {
+                present.updateOperation(operation);
+                return false;
+            }
+
+            index.put(pnfsId, operation);
+            incoming.add(operation);
+        }
+
+        signalAll();
+
+        return true;
+    }
+
+    private synchronized void await() throws InterruptedException {
+        wait(timeoutUnit.toMillis(timeout));
+    }
+
+    private void clear() {
+        running.clear();
+        for (Deque d: queues) {
+            d.clear();
+        }
+        cancelFilters.clear();
+        synchronized (staging) {
+            staging.clear();
+        }
+        synchronized (incoming) {
+            incoming.clear();
+        }
+        index.clear();
+    }
+
+    private void enqueue(FileQoSOperation operation, boolean retry) {
+        QoSMessageType type = QoSMessageType.values()[operation.getMessageType()];
+        int index = LOC;
+        switch (type) {
+            case QOS_MODIFIED:
+                index = MOD;
+                break;
+            case POOL_STATUS_DOWN:
+            case POOL_STATUS_UP:
+            case CHECK_CUSTODIAL_ONLINE:
+                index = SCN;
+                break;
+            default:
+                break;
+        }
+
+        if (retry || operation.getNeededAdjustments() < 2) { /** fairness algorithm **/
+            queues[index].addFirst(operation);
+        } else {
+            queues[index].addLast(operation);
+        }
+    }
+
+    private void remove(PnfsId pnfsId, boolean failed) {
+        FileQoSOperation operation = index.remove(pnfsId);
+
+        if (operation == null) {
+            return;
+        }
+
+        /*
+         *  If this is a pool-bound operation (scan, viz. the 'parent' of the
+         *  operation is defined), we notify the handler, which will
+         *  relay to the scanning service when appropriate.
+         */
+        Integer pIndex = operation.getParent();
+        if (pIndex != null) {
+            if (pIndex == ONLINE_CUSTODIAL_SCAN_INDEX) {
+                operationHandler.updateScanRecord(CHECK_CUSTODIAL_ONLINE.name(), failed);
+            } else {
+                operationHandler.updateScanRecord(poolInfoMap.getPool(operation.getParent()), failed);
+            }
+        }
+
+        history.add(operation.toHistoryString(), failed);
+    }
+
+    private void removeIfStaging(PnfsId pnfsId) {
+        synchronized (staging) {
+            staging.remove(pnfsId);
+        }
+    }
+
+    private synchronized void signalAll() {
+        signalled.incrementAndGet();
+        notifyAll();
+    }
+}
\ No newline at end of file
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoDiff.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoDiff.java
new file mode 100644
index 0000000000000000000000000000000000000000..9d355b484ef74a6762f7477ee32ff7913f0a662c
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoDiff.java
@@ -0,0 +1,249 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.collect.HashMultimap;
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Multimap;
+import diskCacheV111.poolManager.PoolSelectionUnit.SelectionPool;
+import diskCacheV111.poolManager.PoolSelectionUnit.SelectionPoolGroup;
+import diskCacheV111.poolManager.StorageUnit;
+import diskCacheV111.pools.PoolCostInfo;
+import diskCacheV111.pools.PoolV2Mode;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ *  Container for recording changes to the internal map based on a PoolMonitor update.
+ *  Records pools, pool groups and storage units that have been added or removed, and
+ *  modifications to the pool set of a pool group, to storage unit constraints, and
+ *  to the tags, mode and cost for new or current pools.
+ *  <p/>
+ *  A note on the handling of pool cost:  cost is always updated, but  this is done
+ *  during the compare phase (under read lock) for pools that are already present.
+ *  Hence the cost map does not figure into the 'empty' diff condition.
+ */
+public final class PoolInfoDiff {
+    final Collection<SelectionPool> newPools = new ArrayList<>();
+    final Collection<String> oldPools = new ArrayList<>();
+    final Collection<String> uninitPools = new ArrayList<>();
+    final Collection<SelectionPoolGroup> newGroups = new ArrayList<>();
+    final Collection<String> oldGroups = new ArrayList<>();
+    final Collection<StorageUnit> newUnits = new ArrayList<>();
+    final Collection<String> oldUnits = new ArrayList<>();
+    final Collection<String> markerChanged = new ArrayList<>();
+
+    /*
+     *  (pool, poolGroup)
+     */
+    final Multimap<String, String> poolsAdded = HashMultimap.create();
+
+    /*
+     *  (pool, poolGroup)
+     */
+    final Multimap<String, String> poolsRmved = HashMultimap.create();
+
+    /*
+     *  (pgroup, unit)
+     */
+    final Multimap<String, String> unitsAdded = HashMultimap.create();
+
+    /*
+     *  (pgroup, unit)
+     */
+    final Multimap<String, String> unitsRmved = HashMultimap.create();
+
+    /*
+     *  (unit, constraints)
+     */
+    final Map<String, StorageUnitConstraints> constraints = new HashMap<>();
+
+    /*
+     *  (pool, mode)
+     */
+    private final Map<String, PoolV2Mode> modeChanged = new HashMap<>();
+
+    /*
+     *  (pool, tags)
+     */
+    private final Map<String, ImmutableMap<String, String>> tagsChanged = new HashMap<>();
+
+    /*
+     *  (pool, hsms>
+     */
+    private final Map<String, Set<String>> hsmsChanged = new HashMap<>();
+
+    /*
+     *  (pool)
+     */
+    private final Set<String> readPref0 = new HashSet<>();
+
+    /*
+     *  (pool, cost)
+     */
+    final Map<String, PoolCostInfo> poolCost = new HashMap<>();
+
+    public Map<String, StorageUnitConstraints> getConstraints() {
+        return constraints;
+    }
+
+    public Map<String, Set<String>> getHsmsChanged() { return hsmsChanged; }
+
+    public Collection<String> getMarkerChanged() { return markerChanged; }
+
+    public Map<String, PoolV2Mode> getModeChanged() {
+        return modeChanged;
+    }
+
+    public Collection<SelectionPoolGroup> getNewGroups() {
+        return newGroups;
+    }
+
+    public Collection<SelectionPool> getNewPools() {
+        return newPools;
+    }
+
+    public Collection<StorageUnit> getNewUnits() {
+        return newUnits;
+    }
+
+    public Collection<String> getOldGroups() {
+        return oldGroups;
+    }
+
+    public Collection<String> getOldPools() {
+        return oldPools;
+    }
+
+    public Collection<String> getOldUnits() {
+        return oldUnits;
+    }
+
+    public Map<String, PoolCostInfo> getPoolCost() {
+        return poolCost;
+    }
+
+    public Multimap<String, String> getPoolsAddedToPoolGroup() {
+        return poolsAdded;
+    }
+
+    public Multimap<String, String> getPoolsRemovedFromPoolGroup() {
+        return poolsRmved;
+    }
+
+    public Set<String> getReadPref0() { return readPref0; }
+
+    public Map<String, ImmutableMap<String, String>> getTagsChanged() {
+        return tagsChanged;
+    }
+
+    public Collection<String> getUninitializedPools() {
+        return uninitPools;
+    }
+
+    public Multimap<String, String> getUnitsAddedToPoolGroup() {
+        return unitsAdded;
+    }
+
+    public Multimap<String, String> getUnitsRemovedFromPoolGroup() {
+        return unitsRmved;
+    }
+
+    public boolean isEmpty() {
+        return newPools.isEmpty() && oldPools.isEmpty() && uninitPools.isEmpty()
+                        && newGroups.isEmpty() && oldGroups.isEmpty()
+                        && newUnits.isEmpty() && oldUnits.isEmpty()
+                        && poolsAdded.isEmpty() && poolsRmved.isEmpty()
+                        && unitsAdded.isEmpty() && unitsRmved.isEmpty()
+                        && constraints.isEmpty() && tagsChanged.isEmpty()
+                        && modeChanged.isEmpty() && hsmsChanged.isEmpty()
+                        && readPref0.isEmpty();
+    }
+
+    public String toString() {
+        return String.format("New Pools:            %s\n" +
+                                        "Old Pools:            %s\n" +
+                                        "Uninitialized Pools:  %s\n" +
+                                        "New Groups:           %s\n" +
+                                        "Old Groups:           %s\n" +
+                                        "New Units:            %s\n" +
+                                        "Old Units:            %s\n" +
+                                        "Pools Added:          %s\n" +
+                                        "Pools Removed:        %s\n" +
+                                        "Units Added:          %s\n" +
+                                        "Units Removed:        %s\n" +
+                                        "Constraints changed:  %s\n" +
+                                        "Mode changed:         %s\n" +
+                                        "Tags changed:         %s\n" +
+                                        "HSMS changed:         %s\n" +
+                                        "Read pref 0:          %s\n",
+                        newPools, oldPools, uninitPools,
+                        newGroups, oldGroups,
+                        newUnits, oldUnits,
+                        poolsAdded, poolsRmved,
+                        unitsAdded, unitsRmved,
+                        constraints, modeChanged,
+                        tagsChanged, hsmsChanged, readPref0);
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoFilter.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoFilter.java
new file mode 100644
index 0000000000000000000000000000000000000000..fe7aa35f702e5b32009aa7269a47797b796cb517
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoFilter.java
@@ -0,0 +1,140 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.collect.ImmutableSet;
+import java.util.Set;
+import java.util.regex.Pattern;
+import org.dcache.qos.data.PoolQoSStatus;
+
+/**
+ *  Used for matching pool information entries.
+ */
+public final class PoolInfoFilter {
+    private Set<String>                  status;
+    private Pattern                      pools;
+    private Set<Integer>                 keys;
+    private Long                         lastUpdateBefore;
+    private Long                         lastUpdateAfter;
+
+    public boolean matches(PoolInformation poolInfo) {
+        if (pools != null && !pools.matcher(poolInfo.getName()).find()) {
+            return false;
+        }
+
+        if (keys != null && !keys.contains(poolInfo.getKey())) {
+            return false;
+        }
+
+        if (lastUpdateBefore != null
+                        && lastUpdateBefore <= poolInfo.getLastUpdate()) {
+            return false;
+        }
+
+        if (lastUpdateAfter != null
+                        && lastUpdateAfter >= poolInfo.getLastUpdate()) {
+            return false;
+        }
+
+        if (this.status != null) {
+            if (!poolInfo.isInitialized()
+                            && this.status.contains(PoolInformation.UNINITIALIZED)) {
+                return true;
+            }
+
+            PoolQoSStatus status = poolInfo.getStatus();
+            if (status == null) {
+                if (this.status.contains(PoolInformation.UNINITIALIZED)) {
+                    return true;
+                }
+            } else if (!this.status.contains(status.name())) {
+                return false;
+            }
+        }
+
+        return true;
+    }
+
+    public void setKeys(Integer[] keys) {
+        if (keys != null) {
+            this.keys = ImmutableSet.copyOf(keys);
+        }
+    }
+
+    public void setLastUpdateAfter(Long lastUpdateAfter) {
+        this.lastUpdateAfter = lastUpdateAfter;
+    }
+
+    public void setLastUpdateBefore(Long lastUpdateBefore) {
+        this.lastUpdateBefore = lastUpdateBefore;
+    }
+
+    public void setPools(String expression) {
+        if (expression != null) {
+            pools = Pattern.compile(expression);
+        }
+    }
+
+    public void setStatus(String[] status) {
+        if (status != null) {
+            this.status = ImmutableSet.copyOf(status);
+        }
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoMap.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoMap.java
new file mode 100644
index 0000000000000000000000000000000000000000..fb14f1de4e0b351c16548a098d26dc180c9e4768
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInfoMap.java
@@ -0,0 +1,1242 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.collect.HashMultimap;
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Multimap;
+import com.google.common.collect.Sets;
+import diskCacheV111.poolManager.CostModule;
+import diskCacheV111.poolManager.PoolSelectionUnit;
+import diskCacheV111.poolManager.PoolSelectionUnit.SelectionLink;
+import diskCacheV111.poolManager.PoolSelectionUnit.SelectionPool;
+import diskCacheV111.poolManager.PoolSelectionUnit.SelectionPoolGroup;
+import diskCacheV111.poolManager.PoolSelectionUnit.SelectionUnit;
+import diskCacheV111.poolManager.StorageUnit;
+import diskCacheV111.poolManager.StorageUnitInfoExtractor;
+import diskCacheV111.pools.PoolCostInfo;
+import diskCacheV111.pools.PoolV2Mode;
+import diskCacheV111.vehicles.PoolManagerPoolInformation;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.Set;
+import java.util.UUID;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.function.Predicate;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+import org.dcache.poolmanager.PoolInfo;
+import org.dcache.poolmanager.PoolMonitor;
+import org.dcache.qos.services.verifier.handlers.PoolInfoChangeHandler;
+import org.dcache.qos.services.verifier.util.AbstractLocationExtractor;
+import org.dcache.qos.services.verifier.util.RandomSelectionStrategy;
+import org.dcache.util.NonReindexableList;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.dcache.util.NonReindexableList.MISSING_INDEX;
+import static org.dcache.util.NonReindexableList.safeGet;
+import static org.dcache.util.NonReindexableList.safeIndexOf;
+
+/**
+ *  Serves as an index of PoolSelectionUnit-related information.
+ *  <p/>
+ *  The internal data structures hold a list of pool names and pool groups
+ *  which will always assign a new index number to a new member even if some
+ *  of the current members happen to be deleted via a PoolSelectionUnit operation.
+ *  <p/>
+ *  The reason for doing this is to be able to store most of the pool info
+ *  associated with a given operation in progress as index references
+ *  (see {@link FileQoSOperation}).
+ *  <p/>
+ *  The relational tables represented by multimaps of indices capture pool, pool group,
+ *  storage unit and hsm membership. There are also maps which define the constraints
+ *  for a given storage unit, the tags for a pool, and the live mode and cost
+ *  information for a pool.
+ *  <p/>
+ *  This class also provides methods for determining the primary group of a given pool,
+ *  the storage groups connected to a given pool group, and whether a pool group can
+ *  satisfy the constraints defined by the storage units bound to it.
+ *  <p/>
+ *  {@link #apply(PoolInfoDiff)} empties and rebuilds pool-related information based
+ *  on a diff obtained from {@link #compare(PoolMonitor)}.  An empty diff is equivalent
+ *  to a load operation (at initialization). These methods are called by the map
+ *  initializer at startup, and thereafter by {@link PoolInfoChangeHandler}.
+ *  <p/>
+ *  This class benefits from read-write synchronization, since there will be many
+ *  more reads of what is for the most part stable information (note that the periodically
+ *  refreshed information is synchronized within the PoolInformation object itself;
+ *  hence changes to those values do not require a write lock; e.g., #updatePoolStatus.)
+ *  <p/>
+ *  Class is not marked final for stubbing/mocking purposes.
+ */
+public class PoolInfoMap {
+    /*
+     *  When there are no preferential groups to which a pool belongs, qos will
+     *  use the entire set of pools to choose from.  In this case, the group index
+     *  returned is this magic number.
+     */
+    public static final int SYSTEM_PGROUP = -1729;
+
+    /*
+     *  Custodial online scan placeholders;
+     */
+    public static final int ONLINE_CUSTODIAL_SCAN_INDEX = -9999;
+
+    /*
+     *  Caller does not need to know this name.  Randomized to make sure it does not
+     *  clash with a real pool group name.
+     */
+    private static final String SYSTEM_PGROUP_NAME = UUID.randomUUID().toString();
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(PoolInfoMap.class);
+
+    /*
+     *  Uses pool tags as discriminator keys.
+     */
+    class LocationExtractor extends AbstractLocationExtractor {
+        LocationExtractor(Collection<String> onlyOneCopyPer) {
+            super(onlyOneCopyPer);
+        }
+
+        @Override
+        protected Map<String, String> getKeyValuesFor(String location) {
+            return getTags(getPoolIndex(location));
+        }
+    }
+
+    /*
+     *  The NonReindexableList semantics is different on get() and indexOf() in that the former
+     *  will throw a NoSuchElementException if the list is set not to reference any nulls
+     *  it may have as placeholders for invalidated indices, and to throw a NoSuchElementException
+     *  when the element is not in the list.
+     *
+     *  Referencing this map under lock does not, unfortunately, guarantee consistency in this
+     *  regard, as the operation map could carry stale references (e.g., after operation cancel).
+     *  Not catching the NoSuchElementException then becomes problematic.
+     *
+     *  In the interest of safety, all references to the three NonReindexableLists use the static
+     *  safe methods of the list so that these failures will not provoke uncaught exceptions.
+     */
+    private final NonReindexableList<String>            pools               = new NonReindexableList<>();
+    private final NonReindexableList<String>            groups              = new NonReindexableList<>();
+    private final NonReindexableList<String>            sunits              = new NonReindexableList<>();
+    private final Map<Integer, PrimaryGroupMarker>      markers             = new HashMap<>();
+    private final Map<Integer, StorageUnitConstraints>  constraints         = new HashMap<>();
+    private final Map<Integer, PoolInformation>         poolInfo            = new HashMap<>();
+    private final Multimap<Integer, Integer>            poolGroupToPool     = HashMultimap.create();
+    private final Multimap<Integer, Integer>            poolToPoolGroup     = HashMultimap.create();
+    private final Multimap<Integer, Integer>            storageToPoolGroup  = HashMultimap.create();
+    private final Multimap<Integer, Integer>            poolGroupToStorage  = HashMultimap.create();
+    private final Multimap<Integer, String>             poolToHsm           = HashMultimap.create();
+    private final Set<Integer>                          readPref0Pools      = new HashSet<>();
+
+    private final ReadWriteLock lock  = new ReentrantReadWriteLock(true);
+    private final Lock          write = lock.writeLock();
+    private final Lock          read  = lock.readLock();
+
+    /**
+     *  Called on a dedicated thread.
+     *  <p/>
+     *  Applies a diff under write lock.
+     *  <p/>
+     *  Will not clear the NonReindexable lists (pools, groups). This is to maintain
+     *  the same indices for the duration of the lifetime of the JVM, since the other
+     *  maps may contain live references to pools or groups.
+     */
+    public void apply(PoolInfoDiff diff) {
+        write.lock();
+        try {
+            /*
+             *  -- Remove stale pools, pool groups and storage units.
+             *
+             *     Pool removal assumes that the pool has been properly drained
+             *     of files first; this is not taken care of here.  Similarly
+             *     for the removal of pool groups.
+             *
+             *     If an old pool group has a changed marker, it is also removed.
+             */
+            LOGGER.trace("removing stale pools, pool groups and storage units");
+            diff.getOldPools().stream().forEach(this::removePool);
+            diff.getOldGroups().stream().forEach(this::removeGroup);
+            diff.getOldUnits().stream().forEach(this::removeUnit);
+
+            /*
+             *  -- Remove pools from current groups.
+             *
+             *     If an old group has a changed marker, it is readded as new.
+             */
+            LOGGER.trace("removing pools from pool groups");
+            diff.getPoolsRemovedFromPoolGroup().entries()
+                .forEach(this::removeFromPoolGroup);
+
+            /*
+             *  -- Remove units from current groups.
+             */
+            LOGGER.trace("removing units from pool groups");
+            diff.getUnitsRemovedFromPoolGroup().entries()
+                .forEach(this::removeStorageUnit);
+
+            /*
+             *  -- Add new storage units, pool groups and pools.
+             */
+            LOGGER.trace("adding new storage units, pool groups and pools");
+            diff.getNewUnits().stream().forEach(this::addStorageUnit);
+            diff.getNewGroups().stream().forEach(this::addPoolGroup);
+            diff.getNewPools().stream().forEach(this::addPool);
+
+            /*
+             *  -- Add units to pool groups.
+             */
+            LOGGER.trace("adding storage units to pool groups");
+            diff.getUnitsAddedToPoolGroup().entries().stream()
+                .forEach(this::addUnitToPoolGroup);
+
+            /*
+             *  -- Add pools to pool groups.
+             */
+            LOGGER.trace("adding pools to pool groups");
+            diff.getPoolsAddedToPoolGroup().entries().stream()
+                .forEach(this::addPoolToPoolGroups);
+
+            /*
+             *  -- Modify constraints.
+             */
+            LOGGER.trace("modifying storage unit constraints");
+            diff.getConstraints().entrySet().stream()
+                .forEach(this::updateConstraints);
+
+            /*
+             *  -- Add pool information for the new pools.
+             *
+             *     The new pools are the only ones to have
+             *     entries in the cost info map.
+             */
+            LOGGER.trace("adding live pool information");
+            diff.getPoolCost().keySet().stream()
+                              .forEach(p -> setPoolInfo(p, diff.getModeChanged().get(p),
+                                                           diff.getTagsChanged().get(p),
+                                                           diff.poolCost.get(p)));
+
+            /*
+             *  -- Add HSMs.
+             */
+            LOGGER.trace("adding hsm pool information");
+            diff.getHsmsChanged().entrySet().stream()
+                                 .forEach(e->updateHsms(e.getKey(), e.getValue()));
+
+            /*
+             *  -- Update the readPref0 pools.
+             */
+            LOGGER.trace("updating set of pools for which there are no links with read pref = 0");
+            readPref0Pools.clear();
+            diff.getReadPref0().stream().forEach(p->readPref0Pools.add(pools.indexOf(p)));
+        } finally {
+            write.unlock();
+        }
+    }
+
+    /**
+     *  Called on dedicated thread.
+     *  <p/>
+     *  Does a diff under read lock.
+     *  <p/>
+     *  Gathers new pools, removed pools, new pool groups, removed pool groups,
+     *  new storage units, removed storage units, modified groups and storage units,
+     *  and pool information changes.
+     *
+     *  @param poolMonitor received from pool manager message.
+     *  @return the diff (parsed out into relevant maps and collections).
+     */
+    public PoolInfoDiff compare(PoolMonitor poolMonitor) {
+        read.lock();
+        PoolSelectionUnit psu = poolMonitor.getPoolSelectionUnit();
+        PoolInfoDiff diff = new PoolInfoDiff();
+        try {
+            LOGGER.trace("Searching for currently uninitialized pools.");
+            getUninitializedPools(diff);
+
+            LOGGER.trace("comparing pools");
+            Set<String> commonPools = comparePools(diff, psu);
+
+            LOGGER.trace("comparing pool groups");
+            Set<String> commonGroups = comparePoolGroups(diff, psu);
+
+            LOGGER.trace("adding pools and units to new pool groups");
+            addPoolsAndUnitsToNewPoolGroups(diff, psu);
+
+            LOGGER.trace("comparing pools in pool groups");
+            comparePoolsInPoolGroups(diff, commonGroups, psu);
+
+            LOGGER.trace("find pool group marker changes");
+            comparePoolGroupMarkers(diff, commonGroups, psu);
+
+            LOGGER.trace("comparing storage units");
+            commonGroups = compareStorageUnits(diff, psu);
+
+            LOGGER.trace("adding pool groups for new storage units");
+            addPoolGroupsForNewUnits(diff, psu);
+
+            LOGGER.trace("comparing storage unit links and constraints");
+            compareStorageUnitLinksAndConstraints(diff, commonGroups, psu);
+
+            LOGGER.trace("comparing pool info");
+            comparePoolInfo(diff, commonPools, poolMonitor);
+        } finally {
+            read.unlock();
+        }
+
+        LOGGER.trace("Diff:\n{}", diff.toString());
+        return diff;
+    }
+
+    /**
+     *  Only for testing.
+     */
+    @VisibleForTesting
+    public StorageUnitConstraints getConstraints(String unit) {
+        read.lock();
+        try {
+            return constraints.get(safeIndexOf(unit, sunits));
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<String> getExcludedLocationNames(Collection<String> members) {
+        read.lock();
+        try {
+            return members.stream()
+                          .map(l -> poolInfo.get(safeIndexOf(l, pools)))
+                          .filter(Objects::nonNull)
+                          .filter(PoolInformation::isInitialized)
+                          .filter(PoolInformation::isExcluded)
+                          .map(PoolInformation::getName)
+                          .collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public String getGroup(Integer group) {
+        read.lock();
+        try {
+            if (group != null && group == SYSTEM_PGROUP) {
+                return SYSTEM_PGROUP_NAME;
+            }
+            return safeGet(group, groups);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Integer getGroupIndex(String name) {
+        read.lock();
+        try {
+            if (name == null || SYSTEM_PGROUP_NAME.equals(name)) {
+                return SYSTEM_PGROUP;
+            }
+            return safeIndexOf(name, groups);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<String> getHsmPoolsForStorageUnit(Integer sunit, Set<String> hsms) {
+        read.lock();
+        try {
+            Predicate<Integer> hasHsm = p -> poolToHsm.get(p)
+                                                      .stream()
+                                                      .filter(hsms::contains)
+                                                      .count() != 0;
+
+            Stream<Integer> hsmPools;
+
+            if (sunit == null) {
+                hsmPools = pools.stream().map(pools::indexOf).filter(hasHsm);
+            } else {
+                hsmPools = storageToPoolGroup.get(sunit)
+                                             .stream()
+                                             .map(poolGroupToPool::get)
+                                             .flatMap(pools -> pools.stream())
+                                             .filter(hasHsm);
+            }
+
+            return hsmPools.filter(pool -> isPoolViable(pool, true))
+                            .map(i->safeGet(i, pools))
+                            .collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    /**
+     *  Uses pool tags as discriminator keys.
+     */
+    public AbstractLocationExtractor getLocationExtractor(Collection<String> oneCopyPer) {
+        return new LocationExtractor(oneCopyPer);
+    }
+
+    public Set<String> getMemberLocations(Integer gindex, Collection<String> locations) {
+        if (gindex == null || gindex == SYSTEM_PGROUP) {
+            return ImmutableSet.copyOf(locations);
+        }
+
+        read.lock();
+        try {
+            Set<String> ofGroup = poolGroupToPool.get(gindex)
+                                                 .stream()
+                                                 .map(i -> safeGet(i, pools))
+                                                 .collect(Collectors.toSet());
+            return locations.stream().filter(ofGroup::contains).collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    /**
+     *  @param writable location is writable and readable if true, only readable if false.
+     *  @return all pool group pools which qualify.
+     */
+    public Set<String> getMemberPools(Integer gindex, boolean writable) {
+        read.lock();
+        try {
+            Stream<Integer> members;
+            if (gindex == null || gindex == SYSTEM_PGROUP) {
+                members = pools.stream().map(pools::indexOf);
+            } else {
+                members = poolGroupToPool.get(gindex).stream();
+            }
+            return ImmutableSet.copyOf(members.filter(p->viable(p, writable))
+                                              .map(p->safeGet(p, pools))
+                                              .collect(Collectors.toSet()));
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public String getPool(Integer pool) {
+        read.lock();
+        try {
+            return safeGet(pool, pools);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Integer getPoolIndex(String name) {
+        read.lock();
+        try {
+            return safeIndexOf(name, pools);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<Integer> getPoolIndices(Collection<String> locations) {
+        read.lock();
+        try {
+            return locations.stream()
+                            .map(p -> safeIndexOf(p, pools))
+                            .collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public PoolManagerPoolInformation getPoolManagerInfo(Integer pool) {
+        read.lock();
+        try {
+            return new PoolManagerPoolInformation(safeGet(pool, pools),
+                                                  poolInfo.get(pool).getCostInfo());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<String> getPools(Collection<Integer> indices) {
+        read.lock();
+        try {
+            return indices.stream().map(i -> safeGet(i, pools)).collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Collection<Integer> getPoolsOfGroup(Integer group) {
+        read.lock();
+        try {
+            if (group == null || group == SYSTEM_PGROUP) {
+                return pools.stream().map(pools::indexOf).collect(Collectors.toList());
+            }
+            return poolGroupToPool.get(group);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<String> getReadableLocations(Collection<String> locations) {
+        read.lock();
+        try {
+            return locations.stream()
+                            .filter(location -> viable(safeIndexOf(location, pools), false))
+                            .collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    /**
+     *  The effective pool group for an operation has to do with whether its source
+     *  or the parent pool belongs to a primary group or not.
+     *  <p/>
+     *  If the pool belongs to a set of pool groups, but among them there is a single
+     *  primary group, then that primary group must be used.  Otherwise, we always select
+     *  from among all available pools, designated SYSTEM_GROUP. This
+     *  is true even if the location belongs to a single pool group.
+     *  <p/>
+     *  More simply, selection of targets for copying replicas ignores pool groups except
+     *  in the case when the file is linked to one and only one primary group.
+     *
+     *  @param pool either source of the operation or the pool being scanned.
+     *  @return the effective pool group for that operation.
+     */
+    public Integer getEffectivePoolGroup(Integer pool) throws IllegalStateException {
+        read.lock();
+        try {
+            Collection<Integer> groups = poolToPoolGroup.get(pool);
+            Optional<Integer> primary = getPrimaryGroup(pool, groups);
+            if (primary.isPresent()) {
+                return primary.get();
+            }
+            return SYSTEM_PGROUP;
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<String> getStorageUnitsForGroup(String group) {
+        read.lock();
+        try {
+            return poolGroupToStorage.get(safeIndexOf(group, groups))
+                                     .stream().map(u->safeGet(u, sunits))
+                                     .collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Map<String, String> getTags(Integer pool) {
+        PoolInformation info;
+
+        read.lock();
+        try {
+            info = poolInfo.get(pool);
+        } finally {
+            read.unlock();
+        }
+
+        if (info == null) {
+            return ImmutableMap.of();
+        }
+
+        Map<String, String> tags = info.getTags();
+        if (tags == null) {
+            return ImmutableMap.of();
+        }
+
+        return tags;
+    }
+
+    public String getUnit(Integer index) {
+        read.lock();
+        try {
+            return safeGet(index, sunits);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Integer getUnitIndex(String name) {
+        read.lock();
+        try {
+            return safeIndexOf(name, sunits);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public Set<Integer> getValidLocations(Collection<Integer> locations, boolean writable) {
+        read.lock();
+        try {
+            return locations.stream()
+                            .filter((i) -> viable(i, writable))
+                            .collect(Collectors.toSet());
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public boolean hasPool(String pool) {
+        read.lock();
+        try {
+            return pools.contains(pool);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public boolean isReadPref0(String pool) {
+        read.lock();
+        try {
+            return readPref0Pools.contains(safeIndexOf(pool, pools));
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public boolean isValidPoolIndex(Integer index) {
+        read.lock();
+        try {
+            return pools.get(index) != null;
+        } catch (NoSuchElementException e) {
+            return false;
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public boolean isPoolViable(Integer pool, boolean writable) {
+        read.lock();
+        try {
+            return viable(pool, writable);
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public boolean isInitialized(String pool) {
+        read.lock();
+        try {
+            PoolInformation info = poolInfo.get(safeIndexOf(pool, pools));
+            return info != null && info.isInitialized();
+        } catch (NoSuchElementException e) {
+            return false;
+        } finally {
+            read.unlock();
+        }
+    }
+
+    public boolean isEnabled(String pool) {
+        read.lock();
+        try {
+            PoolInformation info = poolInfo.get(safeIndexOf(pool, pools));
+            return info != null && info.getMode().isEnabled();
+        } catch (NoSuchElementException e) {
+            return false;
+        } finally {
+            read.unlock();
+        }
+    }
+
+    /**
+     * @Admin
+     */
+    public String listPoolInfo(PoolInfoFilter poolInfoFilter) {
+        final StringBuilder builder = new StringBuilder();
+        read.lock();
+        try {
+            pools.stream()
+                .map(i->safeIndexOf(i, pools))
+                .map(poolInfo::get)
+                .filter(poolInfoFilter::matches)
+                .forEach((i) -> builder.append(i).append("\n"));
+        } finally {
+            read.unlock();
+        }
+        return builder.toString();
+    }
+
+    /**
+     *  All unit tests are synchronous, so there is no need to lock the map here.
+     */
+    @VisibleForTesting
+    public void setUnitConstraints(String group, Integer required,
+                                   Collection<String> oneCopyPer) {
+        constraints.put(sunits.indexOf(group),
+                        new StorageUnitConstraints(required, oneCopyPer));
+    }
+
+    public void updatePoolInfo(String pool, boolean excluded) {
+        write.lock();
+        try {
+            PoolInformation info = poolInfo.get(safeIndexOf(pool, pools));
+            if (info != null) {
+                info.setExcluded(excluded);
+            }
+        } finally {
+            write.unlock();
+        }
+    }
+
+    /*
+     *  Used in testing only.
+     */
+    @VisibleForTesting
+    public void updatePoolMode(String pool, PoolV2Mode mode) {
+        write.lock();
+        try {
+            Integer key = safeIndexOf(pool, pools);
+            PoolInformation info = poolInfo.get(key);
+            if (info == null) {
+                info = new PoolInformation(pool, key);
+                poolInfo.put(key, info);
+            }
+            info.update(mode, null, null);
+        } finally {
+            write.unlock();
+        }
+    }
+
+    /**
+     *  A coarse-grained verification that the required and tag constraints of the pool group
+     *  and its associated storage groups can be met. For the default and each storage unit,
+     *  it attempts to fulfill the  max independent location requirement via the LocationExtractor.
+     *
+     *  @throws IllegalStateException upon encountering the first set of
+     *                               constraints which cannot be met.
+     */
+    public void verifyConstraints(Integer pgindex) throws IllegalStateException {
+        Collection<Integer> storageGroups;
+        AbstractLocationExtractor extractor;
+
+        read.lock();
+        try {
+            storageGroups = poolGroupToStorage.get(pgindex);
+            for (Integer index : storageGroups) {
+                StorageUnitConstraints unitConstraints = constraints.get(index);
+                int required = unitConstraints.getRequired();
+                extractor = getLocationExtractor(unitConstraints.getOneCopyPer());
+                verify(pgindex, extractor, required);
+            }
+        } finally {
+            read.unlock();
+        }
+    }
+
+    @VisibleForTesting
+    /** Called under write lock **/
+    void removeGroup(String group) {
+        int index = safeIndexOf(group, groups);
+        groups.remove(index);
+        markers.remove(index);
+        poolGroupToPool.removeAll(index)
+            .stream()
+            .forEach((pindex) -> poolToPoolGroup.remove(pindex,
+                index));
+        poolGroupToStorage.removeAll(index)
+            .stream()
+            .forEach((gindex) -> storageToPoolGroup.remove(
+                gindex, index));
+    }
+
+    @VisibleForTesting
+    /** Called under write lock except during unit test**/
+    void removePool(String pool) {
+        int pindex = safeIndexOf(pool, pools);
+        pools.remove(pindex);
+        poolToPoolGroup.removeAll(pindex).stream().forEach((g) ->poolGroupToPool.remove(g, pindex));
+        poolInfo.remove(pindex);
+        poolToHsm.removeAll(pindex);
+    }
+
+    @VisibleForTesting
+    /** Called under write lock except during unit test **/
+    void removeUnit(String unit) {
+        int index = safeIndexOf(unit, sunits);
+        sunits.remove(index);
+        constraints.remove(index);
+        storageToPoolGroup.removeAll(index).stream()
+            .forEach((gindex) -> poolGroupToStorage.remove(gindex, index));
+    }
+
+    /** Called under write lock **/
+    private void addPool(SelectionPool pool) {
+        String name = pool.getName();
+        pools.add(name);
+    }
+
+    /** Called under write lock **/
+    private void addPoolGroup(SelectionPoolGroup group) {
+        String name = group.getName();
+        groups.add(name);
+        markers.put(groups.indexOf(name), new PrimaryGroupMarker(group.isPrimary()));
+    }
+
+    /** Called under write lock **/
+    private void addPoolGroupsForNewUnits(PoolInfoDiff diff,
+                                          PoolSelectionUnit psu) {
+        Collection<StorageUnit> newUnits = diff.getNewUnits();
+        for (StorageUnit unit : newUnits) {
+            String name = unit.getName();
+            StorageUnitInfoExtractor.getPrimaryGroupsFor(name, psu)
+                                    .stream()
+                                    .forEach((g) -> diff.unitsAdded.put(g, name));
+        }
+    }
+
+    /** Called under write lock **/
+    private void addPoolToPoolGroups(Entry<String, String> entry) {
+        Integer pindex = safeIndexOf(entry.getKey(), pools);
+        Integer gindex = safeIndexOf(entry.getValue(), groups);
+        poolGroupToPool.put(gindex, pindex);
+        poolToPoolGroup.put(pindex, gindex);
+    }
+
+    /** Called under write lock **/
+    private void addPoolsAndUnitsToNewPoolGroups(PoolInfoDiff diff,
+                                                 PoolSelectionUnit psu) {
+        Collection<SelectionPoolGroup> newGroups = diff.getNewGroups();
+        for (SelectionPoolGroup group : newGroups) {
+            String name = group.getName();
+            psu.getPoolsByPoolGroup(name)
+               .stream()
+               .map(SelectionPool::getName)
+               .forEach((p) -> diff.poolsAdded.put(p, name));
+            StorageUnitInfoExtractor.getStorageUnitsInGroup(name, psu)
+               .stream()
+               .forEach((u) -> diff.unitsAdded.put(name, u.getName()));
+        }
+    }
+
+    /** Called under write lock **/
+    private void addStorageUnit(StorageUnit unit) {
+        String name = unit.getName();
+        sunits.add(name);
+        constraints.put(sunits.indexOf(name),
+                        new StorageUnitConstraints(unit.getRequiredCopies(),
+                                                   unit.getOnlyOneCopyPer()));
+    }
+
+    /** Called under write lock **/
+    private void addUnitToPoolGroup(Entry<String, String> entry) {
+        Integer gindex = safeIndexOf(entry.getKey(), groups);
+        Integer sindex = safeIndexOf(entry.getValue(), sunits);
+        storageToPoolGroup.put(sindex, gindex);
+        poolGroupToStorage.put(gindex, sindex);
+    }
+
+    /** Called under read lock **/
+    private Set<String> comparePoolGroups(PoolInfoDiff diff,
+                                          PoolSelectionUnit psu) {
+        Set<String> next = psu.getPoolGroups().values()
+                                    .stream()
+                                    .map(SelectionPoolGroup::getName)
+                                    .collect(Collectors.toSet());
+        Set<String> curr = poolGroupToPool.keySet()
+                                    .stream()
+                                    .map(this::getGroup)
+                                    .collect(Collectors.toSet());
+        Sets.difference(next, curr) .stream()
+                                    .map((name) -> psu.getPoolGroups().get(name))
+                                    .forEach(diff.newGroups::add);
+        Sets.difference(curr, next) .stream()
+                                    .forEach(diff.oldGroups::add);
+        return Sets.intersection(next, curr);
+    }
+
+    /** Called under read lock **/
+    private void comparePoolInfo(PoolInfoDiff diff,
+                                 Set<String> commonPools,
+                                 PoolMonitor poolMonitor) {
+        PoolSelectionUnit psu = poolMonitor.getPoolSelectionUnit();
+        CostModule costModule = poolMonitor.getCostModule();
+
+        /*
+         *  First add the info for all new pools to the diff.
+         */
+        diff.getNewPools().stream()
+            .map(SelectionPool::getName)
+            .forEach((p) -> {
+                diff.getModeChanged().put(p, getPoolMode(psu.getPool(p)));
+                diff.getTagsChanged().put(p, getPoolTags(p, costModule));
+                diff.getPoolCost().put(p, getPoolCostInfo(p, costModule));
+                diff.getHsmsChanged().put(p, psu.getPool(p).getHsmInstances());
+                checkReadPrefs(p, diff.getReadPref0(), psu);
+            });
+
+        /*
+         *  Now check for differences with current pools that are still valid.
+         */
+        commonPools.stream()
+                   .forEach((p) -> {
+                       PoolInformation info = poolInfo.get(getPoolIndex(p));
+                       PoolV2Mode newMode = getPoolMode(psu.getPool(p));
+                       PoolV2Mode oldMode = info.getMode();
+                       if (oldMode == null || (newMode != null
+                                       && !oldMode.equals(newMode))) {
+                           diff.getModeChanged().put(p, newMode);
+                       }
+
+                       ImmutableMap<String, String> newTags
+                                       = getPoolTags(p, costModule);
+                       ImmutableMap<String, String> oldTags = info.getTags();
+                       if (oldTags == null || (newTags != null
+                                        && !oldTags.equals(newTags))) {
+                           diff.getTagsChanged().put(p, newTags);
+                       }
+
+                       /*
+                        *  Since we are not altering the actual collections inside
+                        *  the PoolInfoMap, but are simply modifying the PoolInformation
+                        *  object, and since its own update method is synchronized,
+                        *  we can take care of the update here while holding a read lock.
+                        */
+                       info.update(newMode, newTags, getPoolCostInfo(p, costModule));
+
+                       /*
+                        *  HSM info may not be present when the pool was added, so
+                        *  we readd it here.
+                        */
+                       diff.getHsmsChanged().put(p, psu.getPool(p).getHsmInstances());
+
+                       /*
+                        *  Pool could have been relinked.
+                        */
+                       checkReadPrefs(p, diff.getReadPref0(), psu);
+                   });
+
+    }
+
+    /** Called under read lock **/
+    private void checkReadPrefs(String pool, Set<String> readPref0, PoolSelectionUnit psu) {
+        List<SelectionLink> links = psu.getPoolGroupsOfPool(pool).stream()
+                                       .map(g -> psu.getLinksPointingToPoolGroup(g.getName()))
+                                       .flatMap(c -> c.stream())
+                                       .collect(Collectors.toList());
+        if (links.isEmpty()) {
+            return;
+        }
+
+        for (SelectionLink link: links) {
+            if (link.getPreferences().getReadPref() != 0) {
+                return;
+            }
+        }
+
+        readPref0.add(pool);
+    }
+
+    /** Called under read lock **/
+    private Set<String> comparePools(PoolInfoDiff diff, PoolSelectionUnit psu) {
+        Set<String> next = psu.getPools().values().stream()
+                                                  .map(SelectionPool::getName)
+                                                  .collect(Collectors.toSet());
+        Set<String> curr = ImmutableSet.copyOf(pools);
+        Sets.difference(next, curr).stream().map(psu::getPool).forEach(diff.newPools::add);
+        Sets.difference(curr, next).stream().forEach(diff.oldPools::add);
+        return Sets.intersection(curr, next);
+    }
+
+    /** Called under read lock **/
+    private void comparePoolGroupMarkers(PoolInfoDiff diff,
+        Set<String> common,
+        PoolSelectionUnit psu) {
+        for (String group : common) {
+            SelectionPoolGroup selectionPoolGroup = psu.getPoolGroups().get(group);
+            PrimaryGroupMarker marker = markers.get(groups.indexOf(group));
+            if (selectionPoolGroup.isPrimary() != marker.isPrimary()) {
+                diff.getOldGroups().add(group);
+                diff.getNewGroups().add(selectionPoolGroup);
+
+                /*
+                 * Only rescan groups whose marker changed.
+                 */
+                diff.getMarkerChanged().add(group);
+            }
+        }
+    }
+
+    /** Called under read lock **/
+    private void comparePoolsInPoolGroups(PoolInfoDiff diff,
+                                          Set<String> common,
+                                          PoolSelectionUnit psu) {
+        for (String group : common) {
+            Set<String> next = psu.getPoolsByPoolGroup(group)
+                                  .stream()
+                                  .map(SelectionPool::getName)
+                                  .collect(Collectors.toSet());
+            Set<String> curr = poolGroupToPool.get(safeIndexOf(group, groups))
+                                              .stream()
+                                              .map(i->safeGet(i, pools))
+                                              .collect(Collectors.toSet());
+            Sets.difference(next, curr)
+                .stream()
+                .forEach((p) -> diff.poolsAdded.put(p, group));
+            Sets.difference(curr, next)
+                .stream()
+                .filter((p) -> !diff.oldPools.contains(p))
+                .forEach((p) -> diff.poolsRmved.put(p, group));
+        }
+    }
+
+    /** Called under read lock **/
+    private void compareStorageUnitLinksAndConstraints(PoolInfoDiff diff,
+                                                       Set<String> common,
+                                                       PoolSelectionUnit psu) {
+        for (String unit : common) {
+            StorageUnit storageUnit = psu.getStorageUnit(unit);
+            int index = safeIndexOf(unit, sunits);
+            Set<String> next
+                = ImmutableSet.copyOf(StorageUnitInfoExtractor.getPoolGroupsFor(unit, psu,
+                                                                    false));
+            Set<String> curr = storageToPoolGroup.get(index)
+                                                 .stream()
+                                                 .map(i->safeGet(i, groups))
+                                                 .collect(Collectors.toSet());
+            Sets.difference(next, curr)
+                .stream()
+                .forEach((group) -> diff.unitsAdded.put(group, unit));
+            Sets.difference(curr, next)
+                .stream()
+                .filter((group) -> !diff.oldGroups.contains(group))
+                .forEach((group) -> diff.unitsRmved.put(group, unit));
+
+            Integer required = storageUnit.getRequiredCopies();
+            int newRequired = required == null ? -1 : required;
+
+            StorageUnitConstraints constraints = this.constraints.get(index);
+            int oldRequired = !constraints.hasRequirement() ? -1 : constraints.getRequired();
+
+            Set<String> oneCopyPer = ImmutableSet.copyOf(storageUnit.getOnlyOneCopyPer());
+
+            if (newRequired != oldRequired || !oneCopyPer.equals(constraints.getOneCopyPer())) {
+                diff.constraints.put(unit, new StorageUnitConstraints(required, oneCopyPer));
+            }
+        }
+    }
+
+    /** Called under read lock **/
+    private Set<String> compareStorageUnits(PoolInfoDiff diff,
+                                            PoolSelectionUnit psu) {
+        Set<String> next = psu.getSelectionUnits().values()
+                                .stream()
+                                .filter(StorageUnit.class::isInstance)
+                                .map(SelectionUnit::getName)
+                                .collect(Collectors.toSet());
+        Set<String> curr = storageToPoolGroup.keySet()
+                                .stream()
+                                .map(i->safeGet(i, sunits))
+                                .collect(Collectors.toSet());
+        Sets.difference(next, curr)
+                                .stream()
+                                .map(psu::getStorageUnit)
+                                .forEach(diff.newUnits::add);
+        Sets.difference(curr, next).stream().forEach( diff.oldUnits::add);
+        return Sets.intersection(next, curr);
+    }
+
+    private PoolV2Mode getPoolMode(SelectionPool pool) {
+        /*
+         *  Allow a NULL value
+         */
+        return pool.getPoolMode();
+    }
+
+    private ImmutableMap<String, String> getPoolTags(String pool,
+                                                     CostModule costModule) {
+        PoolInfo poolInfo = costModule.getPoolInfo(pool);
+        if (poolInfo == null) {
+            return null;
+        }
+        return poolInfo.getTags();
+    }
+
+    private PoolCostInfo getPoolCostInfo(String pool, CostModule costModule) {
+        /*
+         *  Allow a NULL value
+         */
+        return costModule.getPoolCostInfo(pool);
+    }
+
+    /** called under read lock **/
+    private Optional<Integer> getPrimaryGroup(Integer pool, Collection<Integer> groups)
+            throws IllegalStateException {
+        Collection<Integer> primary = groups.stream()
+                                            .filter(gindex -> markers.get(gindex).isPrimary())
+                                            .collect(Collectors.toList());
+
+        if (primary.size() > 1) {
+                throw new IllegalStateException(String.format(
+                    "Pool map is inconsistent; pool %s belongs to "
+                        + "more than one primary "
+                        + "group: %s.",
+                    safeGet(pool, pools),
+                    primary.stream().map(this::getGroup).collect(Collectors.toList())));
+        }
+
+        LOGGER.trace("number of primary pool groups for pool {}: {}.", pool, primary.size());
+
+        if (primary.size() == 1) {
+            return primary.stream().findFirst();
+        }
+
+        return Optional.empty();
+    }
+
+    private void getUninitializedPools(PoolInfoDiff diff) {
+        pools.stream()
+             .filter((p) -> !isInitialized(p))
+             .forEach(diff.uninitPools::add);
+    }
+
+    /** Called under write lock **/
+    private void removeFromPoolGroup(Entry<String, String> entry) {
+        Integer pindex = safeIndexOf(entry.getKey(), pools);
+        Integer gindex = safeIndexOf(entry.getValue(), groups);
+        poolGroupToPool.remove(gindex, pindex);
+        poolToPoolGroup.remove(pindex, gindex);
+    }
+
+    private void removeStorageUnit(Entry<String, String> entry) {
+        Integer sindex = safeIndexOf(entry.getValue(), sunits);
+        Integer pindex = safeIndexOf(entry.getKey(), groups);
+        storageToPoolGroup.remove(sindex, pindex);
+        poolGroupToStorage.remove(pindex, sindex);
+    }
+
+    /** Called under write lock **/
+    private PoolInformation setPoolInfo(String pool,
+                                        PoolV2Mode mode,
+                                        ImmutableMap<String, String> tags,
+                                        PoolCostInfo cost) {
+        Integer pindex = safeIndexOf(pool, pools);
+        PoolInformation entry = poolInfo.getOrDefault(pindex, new PoolInformation(pool, pindex));
+        entry.update(mode, tags, cost);
+        poolInfo.put(pindex, entry);
+        return entry;
+    }
+
+    /** Called under write lock **/
+    private void updateConstraints(Entry<String, StorageUnitConstraints> entry) {
+        constraints.put(safeIndexOf(entry.getKey(), sunits), entry.getValue());
+    }
+
+    /** Called under write lock **/
+    private void updateHsms(String pool, Set<String> hsms) {
+        Integer index = pools.indexOf(pool);
+        if (hsms.isEmpty()) {
+            poolToHsm.removeAll(index);
+        } else {
+            hsms.stream().forEach(hsm -> poolToHsm.put(index, hsm));
+        }
+    }
+
+    /**
+     *  Called under read lock
+     *
+     *  @param index     of pool group.
+     *  @param extractor configured for the specific tag constraints.
+     *  @param required  specific to this group or storage unit.
+     *  @throws IllegalStateException upon encountering the first set of
+     *                                constraints which cannot be met.
+     */
+    private void verify(Integer index, AbstractLocationExtractor extractor, int required)
+            throws IllegalStateException {
+        Stream<Integer> indices;
+
+        if (index == SYSTEM_PGROUP) {
+            indices = pools.stream().map(p->safeIndexOf(p, pools)).filter(i->i != MISSING_INDEX);
+        } else {
+            indices = poolGroupToPool.get(index).stream();
+        }
+
+        Set<String> members = indices.map(i->safeGet(i, pools)).collect(Collectors.toSet());
+
+        for (int i = 0; i < required; i++) {
+            Collection<String> candidates = extractor.getCandidateLocations(members);
+            if (candidates.isEmpty()) {
+                throw new IllegalStateException("No candidate locations for "
+                                                 + (index == SYSTEM_PGROUP ? "any pool" :
+                                                 safeGet(index, groups)));
+            }
+            String selected = RandomSelectionStrategy.SELECTOR.apply(candidates);
+            members.remove(selected);
+            extractor.addSeenTagsFor(selected);
+        }
+    }
+
+    private boolean viable(Integer pool, boolean writable) {
+        PoolInformation info = poolInfo.get(pool);
+        return info != null && info.isInitialized()
+            && (writable ? info.canRead() && info.canWrite() : info.canRead());
+    }
+}
\ No newline at end of file
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInformation.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInformation.java
new file mode 100644
index 0000000000000000000000000000000000000000..ab540e9f5586446c787552643d0baf594a22e539
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PoolInformation.java
@@ -0,0 +1,190 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.collect.ImmutableMap;
+import diskCacheV111.pools.PoolCostInfo;
+import diskCacheV111.pools.PoolV2Mode;
+import java.util.Date;
+import java.util.Map;
+import org.dcache.qos.data.PoolQoSStatus;
+
+/**
+ *  Encapsulates "live" pool information – pool mode, status, and cost. Also stores pool tags.
+ *  <p/>
+ *  This object is held by the {@link PoolInfoMap}; status, mode, tags and cost are refreshed
+ *  during the Pool Monitor updates.
+ */
+final class PoolInformation {
+    public static final String UNINITIALIZED = "UNINITIALIZED";
+
+    private static final String TOSTRING
+                    = "key\t\t%s\nname\t\t%s\ntags\t\t%s\nmode\t\t%s\n"
+                    + "status\t\t%s\nlast update\t%s\n";
+
+    private final String name;
+    private final Integer key;
+    private PoolQoSStatus status;
+    private PoolV2Mode mode;
+    private boolean excluded;
+    private ImmutableMap<String, String> tags;
+    private PoolCostInfo costInfo;
+    private long lastUpdate;
+
+    PoolInformation(String name, Integer key) {
+        this(name, key, null);
+    }
+
+    PoolInformation(String name, Integer key, PoolV2Mode mode) {
+        this.name = name;
+        this.key = key;
+        lastUpdate = System.currentTimeMillis();
+        excluded = false;
+        this.mode = mode;
+    }
+
+    public synchronized String toString() {
+        if (!isInitialized()) {
+            return  String.format(TOSTRING,
+                                  key, name, "", "", UNINITIALIZED, "");
+        }
+        return String.format(TOSTRING,
+                             key, name, tags, mode,
+                             excluded ? "EXCLUDED" : status,
+                             new Date(lastUpdate));
+    }
+
+    synchronized boolean canRead() {
+        return mode != null
+                         && mode.getMode() != PoolV2Mode.DISABLED
+                         && !mode.isDisabled(PoolV2Mode.DISABLED_DEAD)
+                         && !mode.isDisabled(PoolV2Mode.DISABLED_FETCH)
+                         && !mode.isDisabled(PoolV2Mode.DISABLED_P2P_SERVER);
+    }
+
+    synchronized boolean canWrite() {
+        return mode != null
+                         && mode.getMode() != PoolV2Mode.DISABLED
+                         && !mode.isDisabled(PoolV2Mode.DISABLED_DEAD)
+                         && !mode.isDisabled(PoolV2Mode.DISABLED_P2P_CLIENT);
+    }
+
+    synchronized PoolCostInfo getCostInfo() {
+        return costInfo;
+    }
+
+    synchronized long getLastUpdate() {
+        return lastUpdate;
+    }
+
+    Integer getKey() {
+        return key;
+    }
+
+    synchronized PoolV2Mode getMode() {
+        return mode;
+    }
+
+    String getName() {
+        return name;
+    }
+
+    synchronized PoolQoSStatus getStatus() {
+        return status;
+    }
+
+    synchronized ImmutableMap<String, String> getTags() {
+        return tags;
+    }
+
+    synchronized boolean isExcluded() {
+        return excluded;
+    }
+
+    synchronized boolean isInitialized() {
+        return mode != null && tags != null && costInfo != null;
+    }
+
+    synchronized void setExcluded(boolean excluded) {
+        this.excluded = excluded;
+    }
+
+    synchronized void update(PoolV2Mode mode, Map<String, String> tags, PoolCostInfo costInfo) {
+        updatePoolMode(mode);
+        updateTags(tags);
+        if (costInfo != null) {
+            this.costInfo = costInfo;
+        }
+        lastUpdate = System.currentTimeMillis();
+    }
+
+    private void updatePoolMode(PoolV2Mode mode) {
+        if (mode != null) {
+            this.mode = mode;
+            status = PoolQoSStatus.getStatusFor(mode);
+        }
+    }
+
+    private void updateTags(Map<String, String> tags) {
+        if (tags != null) {
+            this.tags = ImmutableMap.copyOf(tags);
+        }
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PrimaryGroupMarker.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PrimaryGroupMarker.java
new file mode 100644
index 0000000000000000000000000000000000000000..c34bc55473f5826bb9643faeece996cd37947c6b
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/PrimaryGroupMarker.java
@@ -0,0 +1,75 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+/**
+ *  Whether the pool group has been marked 'primary' ('resilient').
+ */
+public final class PrimaryGroupMarker {
+    private boolean primary;
+
+    PrimaryGroupMarker(boolean primary) {
+        this.primary = primary;
+    }
+
+    public boolean isPrimary() {
+        return primary;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/QoSOperation.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/QoSOperation.java
new file mode 100644
index 0000000000000000000000000000000000000000..4862481258546d9e19093171b3f7a3bf873e7644
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/QoSOperation.java
@@ -0,0 +1,84 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import org.dcache.qos.data.PoolQoSStatus;
+
+/**
+ *  Operation types which have a bearing on verification behavior.
+ */
+public enum QoSOperation {
+    FILE,
+    POOL_SCAN_DOWN,
+    POOL_SCAN_ACTIVE;
+
+    public static QoSOperation get(PoolQoSStatus status) {
+        if (status == null) {
+            return FILE;
+        }
+
+        switch(status) {
+            case DOWN:
+                return POOL_SCAN_DOWN;
+            default:
+                return POOL_SCAN_ACTIVE;
+        }
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/StorageUnitConstraints.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/StorageUnitConstraints.java
new file mode 100644
index 0000000000000000000000000000000000000000..3d61e8f642530208eae2952f4fbf6c2da9bd1893
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/data/StorageUnitConstraints.java
@@ -0,0 +1,128 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.data;
+
+import com.google.common.collect.ImmutableSet;
+import java.util.Collection;
+import java.util.Objects;
+import java.util.Set;
+
+/**
+ *  Encapsulates the constraints defined for a storage unit. These include the number of copies
+ *  required, and how they are to be distributed according to pool tags.
+ */
+public final class StorageUnitConstraints {
+    /*
+     *   The number of copies which should be maintained.
+     */
+    private final Integer required;
+
+    /*
+     *  Copies should be distributed across pools in such a way that no two copies have
+     * the same values for a given tag.
+     */
+    private final ImmutableSet<String> oneCopyPer;
+
+    public StorageUnitConstraints(Integer required, Collection<String> oneCopyPer) {
+        this.required = required;
+        if (oneCopyPer == null) {
+            this.oneCopyPer = ImmutableSet.of();
+        } else {
+            this.oneCopyPer = ImmutableSet.copyOf(oneCopyPer);
+        }
+    }
+
+    @Override
+    public boolean equals(Object other) {
+        if (!(other instanceof StorageUnitConstraints)) {
+            return false;
+        }
+
+        StorageUnitConstraints otherConstraints = (StorageUnitConstraints) other;
+
+        return Objects.equals(required, otherConstraints.required)
+                        && this.oneCopyPer.equals(otherConstraints.oneCopyPer);
+    }
+
+    @Override
+    public int hashCode() {
+        return Objects.hash(required, oneCopyPer);
+    }
+
+    public Set<String> getOneCopyPer() {
+        return oneCopyPer;
+    }
+
+    public int getRequired() {
+        if (required == null) {
+            return 0;
+        }
+        return required;
+    }
+
+    public boolean hasRequirement() {
+        return required != null && required != 0;
+    }
+
+    @Override
+    public String toString() {
+        return String.format("(required %s)(oneCopyPer %s)", required, oneCopyPer);
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/CheckpointHandler.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/CheckpointHandler.java
new file mode 100644
index 0000000000000000000000000000000000000000..5cd2f24afe2b75147c7939e6f5818e70be665db1
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/CheckpointHandler.java
@@ -0,0 +1,170 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.handlers;
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileReader;
+import java.io.FileWriter;
+import java.io.IOException;
+import java.io.PrintWriter;
+import java.util.Iterator;
+import java.util.concurrent.atomic.AtomicLong;
+import org.dcache.qos.QoSException;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.services.verifier.data.FileQoSOpCheckpointRecord;
+import org.dcache.qos.services.verifier.data.FileQoSOperation;
+import org.dcache.qos.services.verifier.data.FileQoSOperationMap;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ *  This implementation writes out the toString of the wrapper record to a text file.
+ */
+public final class CheckpointHandler {
+    private static final Logger LOGGER = LoggerFactory.getLogger(CheckpointHandler.class);
+
+    private PoolInfoMap poolInfoMap;
+    private FileQoSOperationMap fileQoSOperationMap;
+
+    /**
+     *  Read back in from the checkpoint file operation records. These are converted
+     *  to {@link FileQoSUpdate} objects and passed to the map for registration.
+     *  <p/>
+     *  The file to be reloaded is renamed, so that any checkpointing begun while
+     *  the reload is in progress does not overwrite the file. In the case of a failed
+     *  reload, the reload file should be manually merged into the current checkpoint
+     *  file before restart.
+     *
+     *  @param checkpointFilePath to read
+     */
+    public void load(String checkpointFilePath) {
+        if (!new File(checkpointFilePath).exists()) {
+            return;
+        }
+
+        File current = new File(checkpointFilePath);
+        File reload = new File(checkpointFilePath + "-reload");
+        current.renameTo(reload);
+
+        try (BufferedReader fr = new BufferedReader(new FileReader(reload))) {
+            while (true) {
+                String line = fr.readLine();
+                if (line == null) {
+                    break;
+                }
+                try {
+                    fileQoSOperationMap.register(new FileQoSOpCheckpointRecord(line).toUpdate());
+                } catch (QoSException e) {
+                    LOGGER.warn("{}; skipping record.", e.getMessage());
+                }
+            }
+            reload.delete();
+        } catch (FileNotFoundException e) {
+            LOGGER.error("Unable to reload checkpoint file: {}", e.getMessage());
+        } catch (IOException e) {
+            LOGGER.error("Unrecoverable error during reload checkpoint file: {}",
+                            e.getMessage());
+        }
+    }
+
+    /**
+     *  Since we use checkpointing as an approximation, the fact that the ConcurrentMap
+     *  (internal to the {@link FileQoSOperationMap) may be dirty and that it is not
+     *  locked should not matter greatly.
+     *
+     *  @param checkpointFilePath where to write.
+     *  @param iterator from a ConcurrentHashMap implementation of the operation map index.
+     *  @return number of records written
+     */
+    public long save(String checkpointFilePath, Iterator<FileQoSOperation> iterator) {
+        File current = new File(checkpointFilePath);
+        File old = new File(checkpointFilePath + "-old");
+        if (current.exists()) {
+            current.renameTo(old);
+        }
+
+        AtomicLong count = new AtomicLong(0);
+        try (PrintWriter fw = new PrintWriter(new FileWriter(checkpointFilePath, false))) {
+            while (iterator.hasNext()) {
+                FileQoSOperation operation = iterator.next();
+                fw.println(new FileQoSOpCheckpointRecord(operation, poolInfoMap).toString());
+                count.incrementAndGet();
+            }
+        } catch (FileNotFoundException e) {
+            LOGGER.error("Unable to save checkpoint file: {}", e.getMessage());
+        } catch (IOException e) {
+            LOGGER.error("Unrecoverable error during save of checkpoint file: {}",
+                            e.getMessage());
+        }
+
+        return count.get();
+    }
+
+    public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+        this.poolInfoMap = poolInfoMap;
+    }
+
+    public void setFileQoSOperationMap(FileQoSOperationMap fileQoSOperationMap) {
+        this.fileQoSOperationMap = fileQoSOperationMap;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/FileQoSOperationHandler.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/FileQoSOperationHandler.java
new file mode 100644
index 0000000000000000000000000000000000000000..2c2b7cab43f5a2267bfb1071fdf56d264694acab
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/FileQoSOperationHandler.java
@@ -0,0 +1,797 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.handlers;
+
+import com.google.common.collect.HashMultimap;
+import com.google.common.collect.Multimap;
+import com.google.common.util.concurrent.RateLimiter;
+import diskCacheV111.util.CacheException;
+import diskCacheV111.util.PnfsId;
+import java.io.Serializable;
+import java.time.Instant;
+import java.time.temporal.ChronoUnit;
+import java.util.Calendar;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.Set;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Future;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import org.dcache.alarms.AlarmMarkerFactory;
+import org.dcache.alarms.PredefinedAlarm;
+import org.dcache.qos.QoSException;
+import org.dcache.qos.data.FileQoSRequirements;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.data.QoSAction;
+import org.dcache.qos.data.QoSAdjustmentStatus;
+import org.dcache.qos.data.QoSMessageType;
+import org.dcache.qos.listeners.QoSActionCompletedListener;
+import org.dcache.qos.listeners.QoSAdjustmentListener;
+import org.dcache.qos.listeners.QoSPoolScanResponseListener;
+import org.dcache.qos.listeners.QoSRequirementsListener;
+import org.dcache.qos.services.verifier.data.FileQoSOperation;
+import org.dcache.qos.services.verifier.data.FileQoSOperationMap;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.dcache.qos.services.verifier.util.QoSVerifierCounters;
+import org.dcache.qos.util.CacheExceptionUtils;
+import org.dcache.qos.util.ExceptionMessage;
+import org.dcache.qos.vehicles.QoSAdjustmentRequest;
+import org.dcache.qos.vehicles.QoSAdjustmentResponse;
+import org.dcache.qos.vehicles.QoSBatchedVerificationRequest;
+import org.dcache.qos.vehicles.QoSVerificationRequest;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.dcache.qos.data.QoSAction.VOID;
+import static org.dcache.qos.data.QoSMessageType.CHECK_CUSTODIAL_ONLINE;
+import static org.dcache.qos.data.QoSMessageType.VALIDATE_ONLY;
+import static org.dcache.qos.services.verifier.handlers.FileQoSStatusVerifier.VERIFY_FAILURE_MESSAGE;
+
+/**
+ *  Main handler responsible for processing verification requests and operations.
+ *  <p/>
+ *  Receives the initial updates+requirements and determines whether to add an operation
+ *  for that file to the operation map.
+ *  <p/>
+ *  Processes operation verification (called by the verification task).
+ *  <p/>
+ *  Updates operations when responses from the adjuster arrive.
+ *  <p/>
+ *  Tracks batch verification requests and cancellations arriving from the scanner.
+ *  <p/>
+ *  Relays notification from the operation map to the engine when an action is aborted or completed.
+ *  <p/>
+ *  Class is not marked final for stubbing/mocking purposes.
+ */
+public class FileQoSOperationHandler {
+  private static final Logger LOGGER = LoggerFactory.getLogger(FileQoSOperationHandler.class);
+  private static final Logger ABORTED_LOGGER = LoggerFactory.getLogger("org.dcache.qos-log");
+
+  private static final String ABORT_LOG_MESSAGE
+      = "Storage unit {}: aborted operation for {}; "
+      + "referring pool {}; pools tried: {}; {}";
+
+  private static final String ABORT_ALARM_MESSAGE
+      = "There are files (storage unit {}) for which an operation "
+      + "has been aborted; please consult the qos "
+      + "logs or 'history errors' for details.";
+
+  private static final String INACCESSIBLE_FILE_MESSAGE
+      = "Pool {} is inaccessible but it contains  "
+      + "one or more QoS 'disk' files with no currently readable locations. "
+      + "Administrator intervention is required; please consult the qos "
+      + "logs or 'history errors' for details.";
+
+  private static final String MISSING_LOCATIONS_MESSAGE
+      = "{} has no locations in the namespace (file is lost). "
+      + "Administrator intervention is required.";
+
+  private static final String INCONSISTENT_LOCATIONS_ALARM
+      = "QoS has detected an inconsistency or lag between "
+      + "the namespace replica locations and the actual locations on disk.";
+
+  private static final String MISCONFIGURED_POOL_GROUP_ALARM
+      = "QoS has detected that pool group {} does not have enough pools to "
+      + "meet the requirements of files linked to it.";
+
+  private static final RateLimiter LIMITER = RateLimiter.create(0.001);
+
+  class ScanRecord {
+    private final AtomicInteger done = new AtomicInteger(0);
+    private final AtomicInteger failures = new AtomicInteger(0);
+    private final AtomicInteger arrived = new AtomicInteger(0);
+
+    private boolean cancelled = false;
+
+    void cancel() {
+      cancelled = true;
+    }
+
+    void updateArrived(int count) {
+      arrived.addAndGet(count);
+    }
+
+    void updateTerminated(boolean failed) {
+      done.incrementAndGet();
+      if (failed) {
+        failures.incrementAndGet();
+      }
+    }
+
+    boolean isCancelled() {
+      return cancelled;
+    }
+
+    boolean isComplete() {
+      return cancelled || arrived.get() == done.get();
+    }
+  }
+
+  class ScanRecordMap {
+    private final Map<String, ScanRecord> scanRecords = new HashMap<>();
+    private final Multimap<String, Future> futures =  HashMultimap.create();
+
+    synchronized void addFuture(String pool, Future future) {
+      futures.put(pool, future);
+    }
+
+    synchronized void cancel(String pool) {
+      ScanRecord record = scanRecords.get(pool);
+      if (record != null) {
+        LOGGER.trace("cancelled scan record for {}.", pool);
+        record.cancel();
+      }
+      LOGGER.trace("cancelling futures for {}.", pool);
+      futures.get(pool).stream().forEach(f -> f.cancel(true));
+      futures.removeAll(pool);
+    }
+
+    synchronized ScanRecord updateArrived(String pool, int count) {
+      LOGGER.trace("updateArrived, pool {}, count {}.", pool, count);
+      ScanRecord record = scanRecords.get(pool);
+
+      if (record == null) {
+        record = new ScanRecord();
+        scanRecords.put(pool, record);
+      }
+
+      if (record.isCancelled()) {
+        LOGGER.trace("updateArrived, scan of {} cancelled.", pool);
+        return record;
+      }
+
+      record.updateArrived(count);
+
+      return record;
+    }
+
+    synchronized void updateCompleted(String pool, boolean failed) {
+      ScanRecord record = scanRecords.get(pool);
+      if (record != null) {
+        record.updateTerminated(failed);
+      }
+    }
+
+    synchronized Optional<ScanRecord> fetchAndRemoveIfCompleted(String pool) {
+      ScanRecord record = scanRecords.get(pool);
+      if (record == null || !record.isComplete()) {
+        return Optional.empty();
+      }
+      LOGGER.trace("fetchAndRemoveIfCompleted, record is complete {}.", pool);
+      scanRecords.remove(pool);
+      futures.removeAll(pool);
+      return Optional.of(record);
+    }
+  }
+
+  private final ScanRecordMap scanRecordMap = new ScanRecordMap();
+
+  private FileQoSOperationMap fileOpMap;
+  private PoolInfoMap poolInfoMap;
+  private FileQoSStatusVerifier statusVerifier;
+  private QoSAdjustmentListener adjustmentListener;
+  private QoSPoolScanResponseListener scanResponseListener;
+  private QoSRequirementsListener requirementsListener;
+  private QoSActionCompletedListener actionCompletedListener;
+
+  private ExecutorService updateExecutor;
+  private ExecutorService bulkExecutor;
+  private ScheduledExecutorService taskExecutor;
+
+  private QoSVerifierCounters counters;
+
+  private long launchDelay = 0L;
+  private TimeUnit launchDelayUnit = TimeUnit.SECONDS;
+
+  public long getLaunchDelay() {
+    return launchDelay;
+  }
+
+  public TimeUnit getLaunchDelayUnit() {
+    return launchDelayUnit;
+  }
+
+  public ScheduledExecutorService getTaskExecutor() {
+    return taskExecutor;
+  }
+
+  /**
+   *  Callback from the adjustment service.
+   */
+  public void handleAdjustmentResponse(QoSAdjustmentResponse response) {
+    counters.incrementReceived(QoSVerifierCounters.ADJ_RESP_MESSAGE);
+    PnfsId pnfsId = response.getPnfsId();
+    QoSAdjustmentStatus status = response.getStatus();
+    Serializable error = response.getError();
+    LOGGER.debug("{}, handleAdjustmentResponse: {}{}.", pnfsId, status,
+        error == null ? "" : " " + error);
+    updateExecutor.submit(() -> {
+      switch (status) {
+        case FAILED:
+          fileOpMap.updateOperation(pnfsId, CacheExceptionUtils.getCacheExceptionFrom(error));
+          break;
+        case CANCELLED:
+        case COMPLETED:
+          fileOpMap.updateOperation(pnfsId, null);
+          break;
+        default:
+      }
+    });
+  }
+
+  /**
+   *  From a pool mode or exclusion change communicated by the scanner.
+   *  Just sets new info on map, and can be done on message thread.
+   */
+  public void handleExcludedStatusChange(String location, boolean excluded) {
+    counters.incrementReceived(QoSVerifierCounters.LOC_EXCL_MESSAGE);
+    poolInfoMap.updatePoolInfo(location, excluded);
+  }
+
+  /**
+   *  Callback from scanner.
+   */
+  public void handleFileOperationsCancelledForPool(String pool) {
+    counters.incrementReceived(QoSVerifierCounters.BVRF_CNCL_MESSAGE);
+    /*
+     *  Cancel any ongoing batch requests.
+     */
+    scanRecordMap.cancel(pool);
+    /*
+     *  Do not use the bulk executor as cancellation could be queued behind running
+     *  bulk updates that it pertains to.
+     */
+    updateExecutor.submit(() -> fileOpMap.cancelFileOpForPool(pool, true));
+  }
+
+  /**
+   *  Incoming cancellation request from a client. Forces removal of operation.
+   */
+  public void handleFileOperationCancelled(PnfsId pnfsId) {
+    counters.incrementReceived(QoSVerifierCounters.VRF_CNCL_MESSAGE);
+    updateExecutor.submit(() -> fileOpMap.cancel(pnfsId, true));
+  }
+
+  /**
+   *  Called in the post-process method of the operation map.
+   */
+  public void handleQoSActionCompleted(PnfsId pnfsId, int opState, QoSAction type, Serializable error) {
+    actionCompletedListener.fileQoSActionCompleted(pnfsId, type, error);
+
+    /*
+     *  Need to call out to adjuster if this is a cancellation
+     */
+    if (opState == FileQoSOperation.CANCELED) {
+      try {
+        adjustmentListener.fileQoSAdjustmentCancelled(pnfsId);
+      } catch (QoSException e) {
+        LOGGER.warn("Failed to notify adjustment service to that {} was cancelled; {}.",
+            pnfsId, e.getMessage());
+      }
+    }
+  }
+
+  /**
+   *  The entry method for a verify operation.
+   *  <p/>
+   *  If the entry is already in the current map, its storage group info is updated.
+   *  <p/>
+   *  All requirements of the file that are necessary for qos processing are then fetched if
+   *  not present.  Preliminary checks run for disqualifying conditions here include
+   *  whether this is a storage unit modification, in which case the task is registered
+   *  if the file has the storage unit in question. Otherwise, verification proceeds with a
+   *  series of checks for other disqualifying conditions. If the pnfsId does qualify,
+   *  an entry is added to the {@link FileQoSOperationMap}.
+   */
+  public void handleUpdate(FileQoSUpdate data, FileQoSRequirements requirements) {
+    LOGGER.debug("handleUpdate {}", data);
+
+    if (requirements == null) {
+      try {
+        requirements = requirementsListener.fileQoSRequirementsRequested(data);
+      } catch (QoSException e) {
+        LOGGER.error("Could not get requirements for {}: {}.", data, e.toString());
+        handleVerificationNop(data, true);
+        return;
+      }
+    }
+
+    if (requirements == null) {
+      /*
+       *  Should only happen when a CLEAR CACHE LOCATION finds no locations.
+       */
+      LOGGER.debug("No requirements for {}.", data);
+      handleVerificationNop(data, false);
+      return;
+    }
+
+    data.setSize(requirements.getAttributes().getSize());
+
+    /*
+     *  Determine if action needs to be taken (counts).
+     */
+    if (!statusVerifier.isActionable(data, requirements)) {
+      handleVerificationNop(data, false);
+      return;
+    }
+
+    LOGGER.debug("handleUpdate, update to be registered: {}", data);
+    if (!fileOpMap.register(data)) {
+      LOGGER.debug("handleUpdate, operation already registered for: {}", data.getPnfsId());
+      handleVerificationNop(data, false);
+    };
+  }
+
+  /**
+   *  Called by the verification task.  Checks the status of the file and takes appropriate
+   *  action.  This includes (a) failing the operation if the error is fatal; (b) voiding
+   *  the operation if nothing else needs to be done; (c) sending an adjustment request
+   *  to the adjustment listener.
+   */
+  public void handleVerification(PnfsId pnfsId) {
+    FileQoSOperation operation = fileOpMap.getOperation(pnfsId);
+    if (operation == null) {
+      LOGGER.warn("handleVerification: file operation for {} does not exist; returning.", pnfsId);
+      return;
+    }
+
+    /*
+     *  Check for cancellation.  This is rechecked just before dispatching an adjustment request.
+     */
+    if (operation.isInTerminalState()) {
+      LOGGER.info("handleVerification: file operation for {} already terminated; returning.",
+          pnfsId);
+      return;
+    }
+
+    FileQoSRequirements requirements;
+    QoSAction action;
+    try {
+      FileQoSUpdate data = new FileQoSUpdate(operation.getPnfsId(), null, VALIDATE_ONLY);
+      requirements = requirementsListener.fileQoSRequirementsRequested(data);
+      action = statusVerifier.verify(requirements, operation);
+    } catch (QoSException e) {
+      String message = CacheExceptionUtils.getCacheExceptionErrorMessage(VERIFY_FAILURE_MESSAGE,
+                                                                         pnfsId,
+                                                                         VOID,
+                                                                    null, e.getCause());
+      /*
+       *  FATAL error, should abort operation.
+       */
+      CacheException exception = new CacheException(CacheException.UNEXPECTED_SYSTEM_EXCEPTION,
+                                                    message, e.getCause());
+      fileOpMap.updateOperation(pnfsId, exception);
+      return;
+    } catch (InterruptedException e) {
+      LOGGER.debug("file operation for {} was interrupted; returning.", pnfsId);
+      return;
+    }
+
+    LOGGER.debug("handleVerification for {}, action is {}.", pnfsId, action);
+
+    switch (action) {
+      case VOID:
+        /**  signals the operation map so that the operation can be removed. **/
+        fileOpMap.voidOperation(pnfsId);
+        break;
+      case NOTIFY_MISSING:
+        /**  signals the operation map so that the operation can be removed. **/
+        handleNoLocationsForFile(operation);
+        break;
+      case NOTIFY_INACCESSIBLE:
+        /**  signals the operation map so that the operation can be removed. **/
+        handleInaccessibleFile(operation);
+        break;
+      case NOTIFY_OUT_OF_SYNC:
+        /**  signals the operation map so that the operation can be removed. **/
+        handleNamespaceSyncError(pnfsId);
+        break;
+      case MISCONFIGURED_POOL_GROUP:
+        /**  signals the operation map so that the operation can be removed. **/
+        handleMisconfiguredGroupError(operation);
+        break;
+      case WAIT_FOR_STAGE:
+        /**  signals the operation map if operation is suspended. **/
+        if (!fileOpMap.canStage(operation)) {
+          break;
+        }
+        /** fall through if available for staging **/
+      case CACHE_REPLICA:
+      case PERSIST_REPLICA:
+      case UNSET_PRECIOUS_REPLICA:
+      case COPY_REPLICA:
+      case FLUSH:
+        /**  updates the operation action and sends out an adjustment notification. **/
+        try {
+          handleAdjustment(requirements, operation, action);
+        } catch (QoSException e) {
+          /*
+           *  FATAL error, should abort operation.
+           */
+          CacheException exception = CacheExceptionUtils.getCacheExceptionFrom(e);
+          fileOpMap.updateOperation(pnfsId, exception);
+        }
+    }
+  }
+
+  /**
+   *  Request originating from the engine in response to a location update or QoS change.
+   */
+  public void handleVerificationRequest(QoSVerificationRequest request) {
+    counters.incrementReceived(QoSVerifierCounters.VRF_REQ_MESSAGE);
+    LOGGER.debug("handleVerificationRequest for {}.", request.getUpdate());
+    updateExecutor.submit(() -> handleUpdate(request.getUpdate(), request.getRequirements()));
+  }
+
+  /**
+   *  Request originating from the scanner in response to a pool status change or forced scan.
+   */
+  public void handleVerificationRequest(QoSBatchedVerificationRequest request) {
+    counters.incrementReceived(QoSVerifierCounters.BVRF_REQ_MESSAGE);
+    LOGGER.debug("handleVerificationRequest for {}, type is {}, group is {}, unit is {}.",
+                  request.getPool(), request.getType(), request.getGroup(), request.getStorageUnit());
+    QoSMessageType type = request.getType();
+    String pool = request.getPool();
+    String group = request.getGroup();
+    String storageUnit = request.getStorageUnit();
+    List<PnfsId> replicas = request.getReplicas();
+    boolean forced = request.isForced();
+    ScanRecord record = scanRecordMap.updateArrived(type == CHECK_CUSTODIAL_ONLINE ?
+                                                    CHECK_CUSTODIAL_ONLINE.name() : pool,
+                                                    replicas.size());
+    if (!record.isCancelled()) {
+      scanRecordMap.addFuture(pool,
+          bulkExecutor.submit(() -> updateAll(replicas, pool, type, group, storageUnit, forced)));
+    }
+  }
+
+  /**
+   *  Callback from the operation map when operation fails fatally.
+   */
+  public void operationAborted(FileQoSOperation operation,
+                               String pool,
+                               Set<String> triedSources,
+                               int maxRetries) {
+    PnfsId pnfsId = operation.getPnfsId();
+    String storageUnit =  poolInfoMap.getUnit(operation.getStorageUnit());
+    int retried = operation.getRetried();
+    Exception e = operation.getException();
+    if (retried >= maxRetries) {
+      e = new Exception(String.format("Maximum number of attempts (%s) has been reached", maxRetries),
+                        e);
+    }
+
+    Calendar ref = Calendar.getInstance();
+    ref.set(Calendar.MINUTE, 0);
+    ref.set(Calendar.SECOND, 0);
+    ref.set(Calendar.MILLISECOND, 0);
+
+    storageUnit = storageUnit == null ? "*" : storageUnit;
+
+    /*
+     *  Alarm notification is keyed to the storage group, so as to avoid
+     *  spamming the server or email forwarding. The alarm key changes every hour.
+     *  This guarantees that a new alarm is registered each hour.
+     *  Send this at warn level, so it is possible to throttle repeated
+     *  messages in the domain log.
+     */
+    LOGGER.warn(AlarmMarkerFactory.getMarker(PredefinedAlarm.FAILED_REPLICATION,
+        storageUnit,
+        "ABORT_REPLICATION-" + ref.getTimeInMillis()),
+        ABORT_ALARM_MESSAGE,
+        storageUnit);
+
+    /*
+     *  Full info on the file is logged to the ".qos" log.
+     */
+    ABORTED_LOGGER.error(ABORT_LOG_MESSAGE,
+        storageUnit,
+        pnfsId,
+        pool == null ? "none" : pool,
+        triedSources,
+        new ExceptionMessage(e));
+  }
+
+  public void setActionCompletedListener(QoSActionCompletedListener actionCompletedListener) {
+    this.actionCompletedListener = actionCompletedListener;
+  }
+
+  public void setAdjustmentListener(QoSAdjustmentListener adjustmentListener) {
+    this.adjustmentListener = adjustmentListener;
+  }
+
+  public void setBulkExecutor(ExecutorService bulkExecutor) {
+    this.bulkExecutor = bulkExecutor;
+  }
+
+  public void setCounters(QoSVerifierCounters counters) {
+    this.counters = counters;
+  }
+
+  public void setFileOpMap(FileQoSOperationMap fileOpMap) {
+    this.fileOpMap = fileOpMap;
+  }
+
+  public void setLaunchDelay(long launchDelay) {
+    this.launchDelay = launchDelay;
+  }
+
+  public void setLaunchDelayUnit(TimeUnit launchDelayUnit) {
+    this.launchDelayUnit = launchDelayUnit;
+  }
+
+  public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+    this.poolInfoMap = poolInfoMap;
+  }
+
+  public void setRequirementsListener(QoSRequirementsListener requirementsListener) {
+    this.requirementsListener = requirementsListener;
+  }
+
+  public void setScanResponseListener(QoSPoolScanResponseListener scanResponseListener) {
+    this.scanResponseListener = scanResponseListener;
+  }
+
+  public void setStatusVerifier(FileQoSStatusVerifier statusVerifier) {
+    this.statusVerifier = statusVerifier;
+  }
+
+  public void setTaskExecutor(ScheduledExecutorService taskExecutor) {
+    this.taskExecutor = taskExecutor;
+  }
+
+  public void setUpdateExecutor(ExecutorService updateExecutor) {
+    this.updateExecutor = updateExecutor;
+  }
+
+  public void updateScanRecord(String pool, boolean failure) {
+    LOGGER.debug("updateScanRecord {}, failure {}.", pool, failure);
+    scanRecordMap.updateCompleted(pool, failure);
+
+    /*
+     *  While the interface allows for batched updates, the
+     *  notification by single increments is less error prone.
+     */
+    if (failure) {
+      scanResponseListener.scanRequestUpdated(pool, 0, 1);
+    } else {
+      scanResponseListener.scanRequestUpdated(pool, 1, 0);
+    }
+
+    Optional<ScanRecord> optional = scanRecordMap.fetchAndRemoveIfCompleted(pool);
+
+    if (optional.isPresent()) {
+      ScanRecord record = optional.get();
+      int failed = record.failures.get();
+      int succeeded = record.done.get() - failed;
+      LOGGER.debug("updateScanRecord {}, succeeded {}, failed {}.", pool, succeeded, failed);
+    }
+  }
+
+  private void handleAdjustment(FileQoSRequirements requirements,
+                                FileQoSOperation operation,
+                                QoSAction action) throws QoSException {
+    QoSAdjustmentRequest request = new QoSAdjustmentRequest();
+    request.setAction(action);
+    request.setPnfsId(requirements.getPnfsId());
+    request.setAttributes(requirements.getAttributes());
+    request.setPoolGroup(requirements.getRequiredPoolGroup());
+
+    Integer source = operation.getSource();
+
+    if (source != null) {
+      request.setSource(poolInfoMap.getPool(source));
+    }
+
+    Integer target = operation.getTarget();
+    if (target != null) {
+      request.setTarget(poolInfoMap.getPool(target));
+      request.setTargetInfo(poolInfoMap.getPoolManagerInfo(target));
+    }
+
+    /*
+     *  Notify subscribers.  This will normally be the adjustment service.
+     *  Source and target have been set on the operation.
+     *  Here we also set the action.
+     */
+    operation.requestAdjustment(request, adjustmentListener);
+  }
+
+  private void handleInaccessibleFile(FileQoSOperation operation) {
+    Integer pindex = operation.getParent();
+    if (pindex == null) {
+      pindex = operation.getSource();
+    }
+
+    if (pindex != null) {
+      String pool = poolInfoMap.getPool(pindex);
+      LOGGER.error(AlarmMarkerFactory.getMarker(PredefinedAlarm.INACCESSIBLE_FILE,
+          pool),
+          INACCESSIBLE_FILE_MESSAGE, pool, pool);
+    }
+
+    PnfsId pnfsId = operation.getPnfsId();
+    String error = String.format("%s currently has no active locations.", pnfsId);
+    CacheException exception
+        = CacheExceptionUtils.getCacheException(CacheException.PANIC, VERIFY_FAILURE_MESSAGE,
+                                                 pnfsId, VOID, error, null);
+
+    fileOpMap.updateOperation(pnfsId, exception);
+  }
+
+  private void handleMisconfiguredGroupError(FileQoSOperation operation) {
+    String poolGroup = poolInfoMap.getGroup(operation.getPoolGroup());
+    sendPoolGroupMisconfiguredAlarm(poolGroup);
+    PnfsId pnfsId = operation.getPnfsId();
+    String error
+        = String.format("Pool group %s cannot satisfy the requirements for %s.", poolGroup, pnfsId);
+    CacheException exception
+        = CacheExceptionUtils.getCacheException(CacheException.PANIC, VERIFY_FAILURE_MESSAGE,
+                                                 pnfsId, VOID, error, null);
+    fileOpMap.updateOperation(pnfsId, exception);
+  }
+
+  private void handleNamespaceSyncError(PnfsId pnfsId) {
+    sendOutOfSyncAlarm();
+    String error
+        = String.format("The namespace is not in sync with the pool repositories for %s.", pnfsId);
+    CacheException exception
+        = CacheExceptionUtils.getCacheException(
+        CacheException.PANIC,
+        VERIFY_FAILURE_MESSAGE,
+        pnfsId, VOID, error, null);
+    fileOpMap.updateOperation(pnfsId, exception);
+  }
+
+  private void handleNoLocationsForFile(FileQoSOperation operation) {
+    PnfsId pnfsId = operation.getPnfsId();
+    LOGGER.error(AlarmMarkerFactory.getMarker(PredefinedAlarm.LOST_RESILIENT_FILE,
+        pnfsId.toString()),
+        MISSING_LOCATIONS_MESSAGE, pnfsId);
+    String error = String.format("%s has no locations.", pnfsId);
+    CacheException exception
+        = CacheExceptionUtils.getCacheException(
+        CacheException.PANIC,
+        VERIFY_FAILURE_MESSAGE,
+        pnfsId, VOID, error, null);
+    fileOpMap.updateOperation(pnfsId, exception);
+  }
+
+  private void handleVerificationNop(FileQoSUpdate data, boolean failed) {
+    switch (data.getMessageType()) {
+      case POOL_STATUS_DOWN:
+      case POOL_STATUS_UP:
+        String pool = data.getMessageType() == CHECK_CUSTODIAL_ONLINE ?
+            CHECK_CUSTODIAL_ONLINE.name() : data.getPool();
+        LOGGER.debug("handleVerificationNop {}, updating scan record for {}", data.getPnfsId(), pool);
+        updateScanRecord(pool, failed);
+        break;
+      case QOS_MODIFIED:
+        actionCompletedListener.fileQoSActionCompleted(data.getPnfsId(), VOID, null);
+        break;
+      default:
+        // nothing to do
+    }
+  }
+
+  private static void sendPoolGroupMisconfiguredAlarm(String poolGroup) {
+    /*
+     *  Create a new alarm every hour by keying the alarm to
+     *  an hourly timestamp.  Otherwise, the alarm counter will
+     *  just be updated for each alarm sent.  The rate limiter
+     *  will not alarm more than once every 1000 seconds (once every
+     *  15 minutes).
+     */
+    if (LIMITER.tryAcquire()) {
+      LOGGER.warn(AlarmMarkerFactory.getMarker(PredefinedAlarm.RESILIENCE_PGROUP_ISSUE,
+                                               Instant.now().truncatedTo(ChronoUnit.HOURS).toString()),
+                  MISCONFIGURED_POOL_GROUP_ALARM, poolGroup);
+    }
+  }
+
+  private static void sendOutOfSyncAlarm() {
+    /*
+     *  Create a new alarm every hour by keying the alarm to
+     *  an hourly timestamp.  Otherwise, the alarm counter will
+     *  just be updated for each alarm sent.  The rate limiter
+     *  will not alarm more than once every 1000 seconds (once every
+     *  15 minutes).
+     */
+    if (LIMITER.tryAcquire()) {
+      LOGGER.warn(AlarmMarkerFactory.getMarker(PredefinedAlarm.RESILIENCE_LOC_SYNC_ISSUE,
+          Instant.now().truncatedTo(ChronoUnit.HOURS).toString()),
+          INCONSISTENT_LOCATIONS_ALARM);
+    }
+  }
+
+  private void updateAll(List<PnfsId> replicas,
+                         String pool,
+                         QoSMessageType type,
+                         String group,
+                         String storageUnit,
+                         boolean forced) {
+    replicas.stream().forEach(r ->
+        handleUpdate(new FileQoSUpdate(r, pool, type, group, storageUnit, forced),null));
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/FileQoSStatusVerifier.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/FileQoSStatusVerifier.java
new file mode 100644
index 0000000000000000000000000000000000000000..d7c7a5dc2be55cd1b0bd88a434f1a4da03272e76
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/FileQoSStatusVerifier.java
@@ -0,0 +1,893 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.handlers;
+
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Sets;
+import diskCacheV111.util.CacheException;
+import diskCacheV111.util.PnfsId;
+import diskCacheV111.vehicles.StorageInfo;
+import java.net.URI;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Optional;
+import java.util.Set;
+import org.dcache.cells.CellStub;
+import org.dcache.qos.data.FileQoSRequirements;
+import org.dcache.qos.data.FileQoSUpdate;
+import org.dcache.qos.data.QoSAction;
+import org.dcache.qos.services.verifier.data.FileQoSLocations;
+import org.dcache.qos.services.verifier.data.FileQoSOperation;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.dcache.qos.services.verifier.util.EvictingLocationExtractor;
+import org.dcache.qos.services.verifier.util.LocationSelectionException;
+import org.dcache.qos.services.verifier.util.LocationSelector;
+import org.dcache.qos.util.RepositoryReplicaVerifier;
+import org.dcache.util.CacheExceptionFactory;
+import org.dcache.vehicles.FileAttributes;
+import org.dcache.vehicles.qos.ReplicaStatusMessage;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static org.dcache.qos.data.QoSAction.COPY_REPLICA;
+import static org.dcache.qos.data.QoSAction.MISCONFIGURED_POOL_GROUP;
+import static org.dcache.qos.data.QoSAction.PERSIST_REPLICA;
+import static org.dcache.qos.data.QoSAction.VOID;
+import static org.dcache.qos.services.verifier.data.PoolInfoMap.SYSTEM_PGROUP;
+
+/**
+ *  This is the parent class for the logic engine which verifies replica requirements.
+ *  <p/>
+ *  The two principal methods check whether an update requires action (#isActionable),
+ *  and whether a standing operation requires (further) action (#verify).
+ *  <p/>
+ *  Specific implementations are required to provide a way for selecting new locations,
+ *  and a way for determining which locations can be cached.
+ */
+public abstract class FileQoSStatusVerifier {
+    public static final String VERIFY_FAILURE_MESSAGE = "Processing for %s failed during verify. %s%s";
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(FileQoSStatusVerifier.class);
+
+    protected CellStub pools;
+    protected PoolInfoMap poolInfoMap;
+
+    public boolean isActionable(FileQoSUpdate update, FileQoSRequirements requirements) {
+        PnfsId pnfsId = requirements.getPnfsId();
+
+        /*
+         *  Get indices from map and ensure that the effective pool group is set on the
+         *  update object before proceeding.
+         */
+        String poolGroup = update.getEffectivePoolGroup();
+        Integer poolGroupIndex;
+        if (poolGroup == null) {
+            int poolIndex = poolInfoMap.getPoolIndex(update.getPool());
+            poolGroupIndex = poolInfoMap.getEffectivePoolGroup(poolIndex);
+            poolGroup = poolInfoMap.getGroup(poolGroupIndex);
+            update.setEffectivePoolGroup(poolGroup);
+        } else {
+            poolGroupIndex = poolInfoMap.getGroupIndex(poolGroup);
+        }
+
+        /*
+         *  If the scan was triggered by a change in storage unit requirements,
+         *  the storage unit of the update object will be non-null.
+         *
+         *  This could be from an altered number of required replicas, or from a change
+         *  in tag partitioning; even if the required number of copies exist, they may need to
+         *  be removed and recopied in the latter case.
+         *
+         *  Under these conditions we force the file operation into the table if its storage
+         *  unit matches the modified one.
+         *
+         *  If the file does not match the non-null unit, we skip it.
+         */
+        String storageUnit = update.getStorageUnit();
+        if (storageUnit != null) {
+            FileAttributes attr = requirements.getAttributes();
+            String fileStorageUnit = attr.getStorageClass() + "@" + attr.getHsm();
+            LOGGER.debug("{}, isActionable, storage unit {}, fileStorageUnit is {}",
+                pnfsId, storageUnit, fileStorageUnit);
+            if (storageUnit.equals(storageUnit)) {
+                return true;
+            }
+            LOGGER.debug("{}, isActionable, storage unit {}, fileStorageUnit is {}, skipping ...",
+                pnfsId, storageUnit, fileStorageUnit);
+            return false;
+        }
+
+        /*
+         *  Ignore preliminary checks for forced scans which do not define a storage unit.
+         *  These are scans triggered periodically or by an admin command, and not by
+         *  change in pool state.
+         */
+        if (update.isForced()) {
+            return true;
+        }
+
+        FileQoSLocations qoSLocations;
+        try {
+            qoSLocations = classifyLocations(requirements, poolGroupIndex);
+            qoSLocations.setRequiredPoolGroup(poolGroup);
+        } catch (InterruptedException e) {
+            LOGGER.warn("isActionable {}, thread was interrupted.", pnfsId);
+            return false;
+        }
+
+        int tt = qoSLocations.getCurrentTapeLocations().size();
+        int tr = requirements.getRequiredTape();
+
+        if (tr > 0 && tr != tt) {
+            LOGGER.debug("{}, isActionable, tape requirement not yet met ({} != {})", pnfsId, tr, tt);
+            return true;
+        }
+
+        /*
+         *  Preliminary determination of viable replicas: does not include non-readable,
+         *  non-sticky. For the purposes of triage, we consider excluded
+         *  as part of the "available" replica count.
+         */
+        int dd = 0;
+        int broken = 0;
+        if (!qoSLocations.getCurrentDiskLocations().isEmpty()) {
+            Set<String> precious = qoSLocations.getPrecious();
+            if (!precious.isEmpty()) {
+                LOGGER.debug("{}, isActionable, tape requirement is met ({} = {}), "
+                    + "but there are still {} precious files...", pnfsId, tr, tt, precious);
+                return true;
+            }
+            dd = qoSLocations.getPersistent().size() + qoSLocations.getExcluded().size();
+            broken = qoSLocations.getBroken().size();
+        }
+
+        int dr = requirements.getRequiredDisk();
+        int count = dr - dd;
+
+        LOGGER.debug("{}, isActionable, needs {} replicas, {} valid, {} broken; difference = {}.",
+                        pnfsId, dr, dd, broken, count);
+
+        if (count == 0) {
+            if (broken == 0) {
+                LOGGER.debug("{}, isActionable, requirements are already met.", pnfsId);
+                return false;
+            }
+        }
+
+        return true;
+    }
+
+    public void setPools(CellStub pools) {
+        this.pools = pools;
+    }
+
+    public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+        this.poolInfoMap = poolInfoMap;
+    }
+
+    public QoSAction verify(FileQoSRequirements requirements, FileQoSOperation operation)
+        throws InterruptedException {
+
+        FileQoSLocations locations = classifyLocations(requirements, operation.getPoolGroup());
+        Optional<QoSAction> optional;
+
+        if (requirements.getRequiredDisk() > 0) {
+            optional = checkForEmptyDiskLocations(requirements, locations, operation);
+            if (optional.isPresent()) {
+                operation.setNeeded(1);
+                return optional.get();
+            }
+
+            optional = checkPoolToNamespaceSync(locations);
+            if (optional.isPresent()) {
+                return optional.get();
+            }
+
+            optional = checkForInaccessibleLocations(requirements, locations, operation);
+            if (optional.isPresent()) {
+                operation.setNeeded(1);
+                return optional.get();
+            }
+        }
+
+        optional = checkForFlush(requirements, locations, operation);
+        if (optional.isPresent()) {
+            return optional.get();
+        }
+
+        if (locations.getCurrentDiskLocations().isEmpty()) {
+            return QoSAction.VOID;
+        }
+
+        optional = checkForLocationsToCache(requirements, locations, operation);
+        if (optional.isPresent()) {
+            return optional.get();
+        }
+
+        optional = checkForLocationsToEvict(requirements, locations, operation);
+        if (optional.isPresent()) {
+            return optional.get();
+        }
+
+        optional = checkForLocationAdjustment(requirements, locations, operation);
+        if (optional.isPresent()) {
+            return optional.get();
+        }
+
+        operation.setNeeded(0);
+        return QoSAction.VOID;
+    }
+
+    protected abstract LocationSelector getLocationSelector();
+
+    protected abstract EvictingLocationExtractor getEvictingLocationExtractor(Set<String> partitionKeys);
+
+    private Optional<QoSAction> checkForEmptyDiskLocations(FileQoSRequirements requirements,
+                                                           FileQoSLocations locations,
+                                                           FileQoSOperation operation) {
+        /*
+         *  Somehow, all the locations for this file have been removed from the namespace.
+         */
+        if (locations.getCurrentDiskLocations().isEmpty()) {
+            LOGGER.debug("checkForEmptyDiskLocations {}, needs {} disk locations, no namespace "
+                + "locations found, checking to see if file can be staged.",
+                requirements.getPnfsId(), requirements.getRequiredDisk());
+            if (shouldTryToStage(requirements, locations)) {
+                operation.setNeeded(1);
+                return Optional.of(QoSAction.WAIT_FOR_STAGE);
+            }
+            return Optional.of(QoSAction.NOTIFY_MISSING);
+        }
+
+        return Optional.empty();
+    }
+
+    private Optional<QoSAction> checkPoolToNamespaceSync(FileQoSLocations locations) {
+        /*
+         *  This should happen very rarely, since qos itself does not set the files to removed,
+         *  but rather caches them (removes the system sticky flag).
+         */
+        Set<String> readable = locations.getReadable();
+        Set<String> exist = locations.getExist();
+        if (readable.size() != exist.size()) {
+            LOGGER.debug("checkPoolToNamespaceSync {}, namespace has {} locations, pools {}; "
+                    + "out of sync.",
+                locations.getPnfsId(), readable.size(), exist.size());
+            return Optional.of(QoSAction.NOTIFY_OUT_OF_SYNC);
+        }
+        return Optional.empty();
+    }
+
+    private Optional<QoSAction> checkForInaccessibleLocations(FileQoSRequirements requirements,
+                                                              FileQoSLocations locations,
+                                                              FileQoSOperation operation) {
+        /*
+         *  While cached copies are excluded from the replica count, we allow them to be included
+         *  as readable sources.
+         */
+        if (locations.getViable().size() == 0) {
+            LOGGER.debug("handleVerification {}, no valid readable locations found, "
+                + "checking to see if file can be staged.", requirements.getPnfsId());
+            if (shouldTryToStage(requirements, locations)) {
+                operation.setNeeded(1);
+                return Optional.of(QoSAction.WAIT_FOR_STAGE);
+            }
+            return Optional.of(QoSAction.NOTIFY_INACCESSIBLE);
+        }
+
+        return Optional.empty();
+    }
+
+    private Optional<QoSAction> checkForFlush(FileQoSRequirements requirements,
+                                              FileQoSLocations locations,
+                                              FileQoSOperation operation) {
+        int missingTapeLocations
+            = requirements.getRequiredTape() - locations.getCurrentTapeLocations().size();
+        LOGGER.debug("{}, checking for flush, missing tape locations {}.", requirements.getPnfsId(),
+                                                                           missingTapeLocations);
+        if (missingTapeLocations > 0) {
+            PnfsId pnfsId = requirements.getPnfsId();
+            Set<String> potentialSources = locations.getViable();
+
+            if (potentialSources.isEmpty()) {
+                /*
+                 *  We already checked this condition.  There is something wrong here.
+                 */
+                throw new RuntimeException("no existing sources for file; this condition " +
+                    "should already have been checked.  This is a bug.");
+            }
+
+            Set<String> potentialTargets = findHsmLocations(operation, requirements, locations);
+            LOGGER.debug("{}, potential flush targets {}.", pnfsId, potentialTargets);
+
+            /*
+             *  This is an error condition, but we still might be able to do
+             *  other work in response to this transition, so we emit a warning
+             *  and continue.
+             */
+            if (potentialTargets.isEmpty()) {
+                LOGGER.warn("{}, should be flushed: {}.", pnfsId,
+                    CacheExceptionFactory.exceptionOf(CacheException.NO_POOL_CONFIGURED,
+                        "No HSM-backed location is available").toString());
+                return Optional.empty();
+            }
+
+            Set<String> precious = locations.getPrecious();
+            int preciousOnHsm = Sets.intersection(precious, potentialTargets).size();
+
+            LOGGER.debug("{}, precious locations {}, {} already on flush targets.",
+                pnfsId, precious, preciousOnHsm);
+
+            if (preciousOnHsm < missingTapeLocations) {
+                Optional<String> toPrecious
+                    = Sets.intersection(Sets.difference(potentialSources, precious),
+                                        potentialTargets)
+                    .stream().findAny();
+                String source = toPrecious.orElse(potentialSources.stream().findAny().orElse(null));
+                String target = toPrecious.orElse(potentialTargets.stream().findAny().orElse(null));
+                operation.setSource(poolInfoMap.getPoolIndex(source));
+                operation.setTarget(poolInfoMap.getPoolIndex(target));
+                operation.setNeeded(1);
+                LOGGER.debug("{}, requesting flush from {} on {}.", pnfsId, source, target);
+                return Optional.of(QoSAction.FLUSH);
+            }
+        }
+
+        return Optional.empty();
+    }
+
+    private Optional<QoSAction> checkForLocationsToCache(FileQoSRequirements requirements,
+                                                         FileQoSLocations locations,
+                                                         FileQoSOperation operation) {
+        /*
+         *  First check to see if there are floating precious files.
+         *  We consider only precious locations which are not on HSM pools.
+         *  Precious files which were on non-hsm pools but which needed to go to tape
+         *  will have been caught by the check for flush which always precedes
+         *  this call.
+         */
+        PnfsId pnfsId = requirements.getPnfsId();
+        Set<String> hsmPools = findHsmLocations(operation, requirements, locations);
+        Set<String> toCache = Sets.difference(locations.getPrecious(), hsmPools);
+
+        if (!toCache.isEmpty()) {
+            String target = toCache.iterator().next();
+            LOGGER.debug("handleVerification, {}, precious replica found on non-HSM pool; "
+                + "updating operation to cache: {}", pnfsId, target);
+            operation.setTarget(poolInfoMap.getPoolIndex(target));
+            operation.setNeeded(1);
+            return Optional.of(QoSAction.UNSET_PRECIOUS_REPLICA);
+        }
+
+        /*
+         *  Check for disk required = 0.  If there are sticky replicas, make the first
+         *  one target and return CACHE_REPLICA.
+         */
+        if (requirements.getRequiredDisk() == 0) {
+            Set<String> persistent = locations.getPersistent();
+            if (persistent.size() > 0) {
+                String target = persistent.iterator().next();
+                LOGGER.debug("handleVerification, {}, no persistent replicas required; "
+                    + "updating operation with first sticky target to cache: {}", pnfsId, target);
+                operation.setTarget(poolInfoMap.getPoolIndex(target));
+                operation.setNeeded(1);
+                return Optional.of(QoSAction.CACHE_REPLICA);
+            }
+
+            LOGGER.debug("handleVerification, {}, no persistent replicas required, "
+                    + "nothing to cache; responses {}",
+                pnfsId, locations.getReplicaStatus());
+            operation.setNeeded(0);
+            return Optional.of(QoSAction.VOID);
+        }
+
+        return Optional.empty();
+    }
+
+    private Optional<QoSAction> checkForLocationsToEvict(FileQoSRequirements requirements,
+                                                         FileQoSLocations locations,
+                                                         FileQoSOperation operation) {
+        Optional<QoSAction> action = checkForChangeToPoolGroup(locations, operation);
+        if (action.isPresent()) {
+            return action;
+        }
+
+        return checkForChangeToPoolTags(requirements, locations, operation);
+    }
+
+    private Optional<QoSAction> checkForLocationAdjustment(FileQoSRequirements requirements,
+                                                           FileQoSLocations locations,
+                                                           FileQoSOperation operation) {
+        PnfsId pnfsId = requirements.getPnfsId();
+
+        Set<String> occupied = locations.getOccupied();      // replicas in any state
+        Set<String> persistent = locations.getPersistent();  // replicas with system sticky bit
+        Set<String> cached = locations.getCached();          // replicas without system sticky bit
+
+        Collection<ReplicaStatusMessage> verified = locations.getReplicaStatus();
+        Set<String> partitionKeys = requirements.getPartitionKeys();
+
+        /*
+         *  number of member pools manually excluded by admins
+         */
+        int excluded = locations.getExcluded().size();
+        int required = requirements.getRequiredDisk();
+        int missing = required - persistent.size();
+
+        /*
+         *  First compute the missing replicas on the basis of just the readable
+         *  replicas.  If this is positive, recompute by adding in all the
+         *  excluded locations.  If these satisfy the requirement, void
+         *  the operation.  Do no allow caching in this case, since this
+         *  would imply decreasing already deficient locations.
+         */
+        if (missing > 0) {
+            missing -= excluded;
+            if (missing < 0) {
+                missing = 0;
+            }
+        }
+
+        operation.setNeeded(Math.abs(missing));
+
+        LOGGER.debug("{}, checkForLocationAdjustment; required {}, excluded {}, missing {}.",
+                            pnfsId, required, excluded, missing);
+
+        String source;
+        String target = null;
+        LocationSelector locationSelector = getLocationSelector();
+
+        try {
+            /*
+             *  Note that if the operation source or target is preset,
+             *  and the location is valid, the selection is skipped.
+             */
+            if (missing < 0) {
+                Integer index = operation.getTarget();
+                if (index == null || !poolInfoMap.isPoolViable(index, true)
+                    || !RepositoryReplicaVerifier.isRemovable(poolInfoMap.getPool(index), verified)) {
+                    Set<String> removable
+                        = RepositoryReplicaVerifier.areRemovable(persistent, verified);
+                    target = locationSelector.selectTargetToCache(requirements,
+                                                                  persistent,
+                                                                  removable,
+                                                                  partitionKeys);
+                }
+
+                operation.setTarget(poolInfoMap.getPoolIndex(target));
+                LOGGER.debug("target to remove: {}", target);
+
+                return Optional.of(QoSAction.CACHE_REPLICA);
+            } else if (missing > 0) {
+                Integer viableSource = operation.getSource();
+
+                if (viableSource != null && !poolInfoMap.isPoolViable(viableSource,false)) {
+                    viableSource = null;
+                }
+
+                Integer targetIndex = operation.getTarget();
+                Integer gindex = operation.getPoolGroup();
+                if (targetIndex == null) {
+                    /*
+                     *  See if we can avoid a copy by promoting an existing
+                     *  non-sticky replica to sticky.
+                     *
+                     *  If the source pool is actually a non-sticky replica,
+                     *  choose that first.
+                     */
+                    if (viableSource != null) {
+                        source = poolInfoMap.getPool(viableSource);
+                        if (cached.contains(source)) {
+                            operation.setTarget(viableSource);
+                            LOGGER.debug("promoting source to sticky: {}", source);
+                            return Optional.of(PERSIST_REPLICA);
+                        }
+                    }
+
+                    /*
+                     *  The pool group may have changed.  Make sure all the
+                     *  cached copies are actually still in the pool group.
+                     */
+                    cached = Sets.intersection(cached, locations.getMembers());
+
+                    target = locationSelector.selectTargetToPersist(requirements,
+                                                                    persistent,
+                                                                    cached,
+                                                                    partitionKeys);
+
+                    if (target != null) {
+                        operation.setTarget(poolInfoMap.getPoolIndex(target));
+                        LOGGER.debug("target to promote to sticky: {}", target);
+                        return Optional.of(PERSIST_REPLICA);
+                    }
+
+                    target = locationSelector.selectCopyTarget(operation,
+                                                               poolInfoMap.getGroup(gindex),
+                                                               occupied,
+                                                               partitionKeys);
+                } else if (!poolInfoMap.isPoolViable(targetIndex, true)) {
+                    target = locationSelector.selectCopyTarget(operation,
+                                                               poolInfoMap.getGroup(gindex),
+                                                               occupied,
+                                                               partitionKeys);
+                } else {
+                    target = poolInfoMap.getPool(targetIndex);
+                }
+
+                LOGGER.debug("target to copy: {}", target);
+
+                /*
+                 *  viable may contain both readable and waiting ('from') replicas.
+                 *  To avoid failure/retry, choose only the readable.
+                 */
+                Set<String> strictlyReadable
+                    = RepositoryReplicaVerifier.areReadable(locations.getViable(), verified);
+                if (viableSource == null) {
+                    source = locationSelector.selectCopySource(operation, strictlyReadable);
+                } else {
+                    source = poolInfoMap.getPool(viableSource);
+                }
+
+                LOGGER.debug("source: {}", source);
+                operation.setSource(poolInfoMap.getPoolIndex(source));
+                operation.setTarget(poolInfoMap.getPoolIndex(target));
+                return Optional.of(COPY_REPLICA);
+            } else {
+                LOGGER.debug("Nothing to do, VOID operation for {}", pnfsId);
+                return Optional.of(VOID);
+            }
+        } catch (LocationSelectionException e) {
+            LOGGER.debug("{} Failed location selection because pool group {} "
+                + "could not meet requirements: {}",
+                pnfsId, operation.getPoolGroup(), e.getMessage());
+            return Optional.of(MISCONFIGURED_POOL_GROUP);
+        }
+    }
+
+    private Optional<QoSAction> checkForChangeToPoolGroup(FileQoSLocations locations,
+                                                          FileQoSOperation operation) {
+        PnfsId pnfsId = locations.getPnfsId();
+        Integer pgroup = operation.getPoolGroup();
+        if (pgroup == null) {
+            return Optional.empty();
+        }
+
+        Set<String> members
+            =  poolInfoMap.getMemberLocations(pgroup, locations.getCurrentDiskLocations());
+        locations.setMembers(members);
+
+        LOGGER.debug("handleVerification {}, valid group member locations {}", pnfsId, members);
+
+        /*
+         *  If all the locations are pools no longer belonging to the group,
+         *  the operation should be voided.  This usually indicates that
+         *  the pools have been moved out of the group (primary) or that
+         *  the pools have been entirely removed from the system.
+         *
+         *  Note that having checked for empty locations above means there
+         *  are still replicas of this file in the system.  But if this
+         *  pool group is primary, and not SYSTEM (all pools), then the
+         *  situation is probably indicative of an attempt to drain the
+         *  pools of the group.  It is best here not to take any action
+         *  on the other replicas.
+         */
+        if (members.isEmpty()) {
+            operation.setNeeded(0);
+            return Optional.of(QoSAction.VOID);
+        }
+
+        /*
+         *  Before we attempt any evictions, verify that requirements are met by the pool group.
+         */
+        if (pgroup != SYSTEM_PGROUP) {
+            try {
+                poolInfoMap.verifyConstraints(pgroup);
+            } catch (IllegalStateException e) {
+                operation.setNeeded(0);
+                return Optional.of(MISCONFIGURED_POOL_GROUP);
+            }
+
+            Set<String> persistent = locations.getPersistent();
+            if (shouldEvictALocation(pgroup, operation, persistent)) {
+                LOGGER.debug("handleVerification, a replica should be evicted from {} "
+                    + "because of pool group status change.", persistent);
+                operation.setNeeded(1);
+                return Optional.of(QoSAction.CACHE_REPLICA);
+            }
+        }
+
+        return Optional.empty();
+    }
+
+    private Optional<QoSAction> checkForChangeToPoolTags(FileQoSRequirements requirements,
+                                                         FileQoSLocations locations,
+                                                         FileQoSOperation operation) {
+        PnfsId pnfsId = requirements.getPnfsId();
+        Set<String> persistent = locations.getPersistent();
+
+        /*
+         *  Tagging of the pools may have changed and/or the requirements on
+         *  the storage class may have changed.  If this is the case,
+         *  the files may need to be redistributed.  This begins by choosing
+         *  a location to evict.  When all evictions are done, the new copies
+         *  are made from the remaining replica.  Again, this operation is
+         *  only done on persistent (sticky) replicas.
+         */
+        if (shouldEvictALocation(operation,
+                                 persistent,
+                                 locations.getReplicaStatus(),
+                                 requirements.getPartitionKeys())) {
+            LOGGER.debug("handleVerification, a replica should be evicted from {}", persistent);
+            operation.setNeeded(1);
+            return Optional.of(QoSAction.CACHE_REPLICA);
+        }
+
+        LOGGER.debug("handleVerification after eviction check, {}, valid replicas {}",
+            pnfsId, persistent);
+        return Optional.empty();
+    }
+
+    private FileQoSLocations classifyLocations(FileQoSRequirements requirements, Integer pgroup)
+        throws InterruptedException {
+        PnfsId pnfsId = requirements.getPnfsId();
+        FileQoSLocations qoSLocations = new FileQoSLocations(pnfsId);
+
+        StorageInfo storageInfo = requirements.getAttributes().getStorageInfo();
+        List<URI> uriList = storageInfo.locations();
+
+        Collection<String> tapeLocs = new HashSet();
+        if (uriList == null) {
+            if (storageInfo.isStored()) {
+                tapeLocs.add("legacy-placeholder-location.");
+            }
+        } else {
+            uriList.stream().map(URI::toString).forEach(tapeLocs::add);
+        }
+        qoSLocations.setCurrentTapeLocations(tapeLocs);
+
+        Collection<String> locations = requirements.getAttributes().getLocations();
+        qoSLocations.setCurrentDiskLocations(locations);
+
+        LOGGER.debug("classifyLocations {}, namespace locations {}", pnfsId, locations);
+
+        if (locations.isEmpty()) {
+            return qoSLocations;
+        }
+
+        /*
+         * Verify all the locations. The pools are sent a message which returns
+         * whether the copy exists, is waiting, readable, removable, and has
+         * a sticky bit owned by system.
+         */
+        Collection<ReplicaStatusMessage> status
+            = RepositoryReplicaVerifier.verifyLocations(pnfsId, locations, pools);
+        qoSLocations.setReplicaStatus(status);
+
+        LOGGER.debug("classifyLocations {}, verified replicas: {}", pnfsId, status);
+
+        /*
+         *  Determine that the readable locations from the namespace actually exist.
+         *  This is crucial for the counts.
+         */
+        Set<String> readable = poolInfoMap.getReadableLocations(locations);
+        qoSLocations.setReadable(readable);
+
+        Set<String> exist = RepositoryReplicaVerifier.exist(readable, status);
+        qoSLocations.setExist(exist);
+
+        LOGGER.debug("classifyLocations {}, readable replicas {}, verified replicas {}",
+            pnfsId, readable, exist);
+
+        Set<String> broken = RepositoryReplicaVerifier.getBroken(status);
+        qoSLocations.setBroken(broken);
+
+        Set<String> viable = Sets.difference(exist, broken);
+        qoSLocations.setViable(viable);
+
+        /*
+         *  Find the persistent (sticky) locations.
+         */
+        Set<String> persistent = RepositoryReplicaVerifier.areSticky(viable, status);
+        qoSLocations.setPersistent(persistent);
+
+        Set<String> members = poolInfoMap.getMemberLocations(pgroup, locations);
+        qoSLocations.setMembers(members);
+
+        LOGGER.debug("classifyLocations {}, namespace locations which are members pool group {}: {}",
+            pnfsId, pgroup, members);
+
+        /*
+         *  Find the locations in the namespace that are actually occupied.
+         *  This is an optimization so that we can choose a new pool from the
+         *  group without failing and retrying the migration with a new target.
+         *
+         *  In effect, this means eliminating the phantom locations from
+         *  the namespace.  We do this by adding back into the verified
+         *  locations the offline replica locations.
+         */
+        qoSLocations.setOccupied(Sets.union(exist, Sets.difference(members, readable)));
+
+        /*
+         *  Find the cached (non-sticky) locations.
+         *  Partition the sticky locations between usable and excluded.
+         */
+        qoSLocations.setCached(Sets.difference(viable, persistent));
+        Set<String> excluded
+            = RepositoryReplicaVerifier.areSticky(poolInfoMap.getExcludedLocationNames(members),
+            status);
+        qoSLocations.setPersistent(Sets.difference(persistent, excluded));
+        qoSLocations.setExcluded(excluded);
+
+        LOGGER.debug("classifyLocations {}: member replicas with a sticky replica "
+            + "but which have been manually excluded: {}.", pnfsId, excluded);
+
+        /*
+         *  Compute the viable locations which are precious.
+         */
+        Set<String> precious = RepositoryReplicaVerifier.arePrecious(viable, status);
+        qoSLocations.setPrecious(precious);
+
+        LOGGER.debug("classifyLocations {}: viable replicas which are precious: {}.",
+            pnfsId, precious);
+
+        return qoSLocations;
+    }
+
+    /*
+     *  Find all pools that are backed by an HSM which would be eligible as a flush
+     *  target for this file.
+     */
+    private Set<String> findHsmLocations(FileQoSOperation operation,
+                                         FileQoSRequirements requirements,
+                                         FileQoSLocations locations) {
+        Set<String> hsmLocations = locations.getHsm();
+        if (hsmLocations != null) {
+            return hsmLocations;
+        }
+
+        Set<String> hsms = ImmutableSet.of(requirements.getAttributes().getHsm());
+        Integer unit = operation.getStorageUnit();
+
+        LOGGER.debug("{}, checking for potential HSM locations (storage unit {}, hsms {}).",
+            operation.getPnfsId(), unit, hsms);
+
+        hsmLocations = poolInfoMap.getHsmPoolsForStorageUnit(unit, hsms);
+        locations.setHsm(hsmLocations);
+
+        return hsmLocations;
+    }
+
+    /*
+     *  The current file operation is under the aegis of a particular pool group,
+     *  which is either a primary group, or SYSTEM (all).  If it is not the latter,
+     *  and there are persistent (sticky) replicas on pools in other pool groups,
+     *  we want to move them into the primary group.
+     *
+     *  This can happen, for instance, if a pool group to which the initial write
+     *  of the file was linked was not originally marked as primary, but was
+     *  subsequently updated to be primary.
+     *
+     *  Note that the method will not remove the last persistent replica.
+     */
+    private boolean shouldEvictALocation(int pgroup,
+                                         FileQoSOperation operation,
+                                         Collection<String> persistent) {
+        if (persistent.size() < 2) {
+            return false;
+        }
+
+        for (String location : persistent) {
+            Integer index = poolInfoMap.getPoolIndex(location);
+            if (pgroup != poolInfoMap.getEffectivePoolGroup(index)) {
+                operation.setTarget(index);
+                return true;
+            }
+        }
+
+        return false;
+    }
+
+    /*
+     *  Checks for necessary eviction due to pool tag changes or constraint change.
+     *  This call will automatically set the offending location as the target for a
+     *  caching operation.
+     *
+     *  Note that the extractor algorithm will not cache the last replica, because a singleton
+     *  will always satisfy any equivalence relation. But we short-circuit this check anyway.
+     */
+    private boolean shouldEvictALocation(FileQoSOperation operation,
+                                         Collection<String> persistent,
+                                         Collection<ReplicaStatusMessage> verified,
+                                         Set<String> partitionKeys) {
+        if (persistent.size() < 2) {
+            return false;
+        }
+
+        EvictingLocationExtractor extractor = getEvictingLocationExtractor(partitionKeys);
+        Optional<String> toEvict = extractor.findALocationToEvict(persistent, verified);
+
+        if (toEvict.isPresent()) {
+            operation.setTarget(poolInfoMap.getPoolIndex(toEvict.get()));
+            return true;
+        }
+
+        return false;
+    }
+
+    /*
+     *  Called when there are no accessible replicas for the file.
+     *
+     *  If the file is required to be on disk and it is also on tape, we attempt to stage.
+     *  Staging is fire-and-forget. Since the replica is required to be on disk, the
+     *  verification after the staging will make sure that it also has the correct
+     *  number of replicas.
+     */
+    private static boolean shouldTryToStage(FileQoSRequirements requirements,
+                                            FileQoSLocations locations) {
+        if (requirements.getRequiredDisk() > 0 && !locations.getCurrentTapeLocations().isEmpty()) {
+            LOGGER.debug("shouldTryToStage {}, file is on tape and is also required to be on disk.",
+                requirements.getPnfsId());
+            return true;
+        }
+        LOGGER.debug("shouldTryToStage {}, file not on tape", requirements.getPnfsId());
+        return false;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/PoolGroupAndTagsQoSVerifier.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/PoolGroupAndTagsQoSVerifier.java
new file mode 100644
index 0000000000000000000000000000000000000000..1ce35be2dfe97186782f943060c35d994f906c3c
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/PoolGroupAndTagsQoSVerifier.java
@@ -0,0 +1,89 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.handlers;
+
+import java.util.Set;
+import org.dcache.qos.services.verifier.util.EvictingLocationExtractor;
+import org.dcache.qos.services.verifier.util.LocationSelector;
+import org.dcache.qos.services.verifier.util.PoolInfoLocationSelector;
+import org.dcache.qos.services.verifier.util.PoolTagBasedLocationExtractor;
+
+/**
+ *  Implementation which uses pool tags and pool group to determine eviction, and pool tags
+ *  for selection partitioning.  The location selector accesses the pool info which is
+ *  processed from the pool monitor/pool selection unit.
+ */
+public final class PoolGroupAndTagsQoSVerifier extends FileQoSStatusVerifier {
+  private PoolInfoLocationSelector locationSelector;
+
+  public void setLocationSelector(PoolInfoLocationSelector locationSelector) {
+    this.locationSelector = locationSelector;
+  }
+
+  @Override
+  protected LocationSelector getLocationSelector() {
+    return locationSelector;
+  }
+
+  @Override
+  protected EvictingLocationExtractor getEvictingLocationExtractor(Set<String> partitionKeys) {
+    return new PoolTagBasedLocationExtractor(partitionKeys, poolInfoMap);
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/PoolInfoChangeHandler.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/PoolInfoChangeHandler.java
new file mode 100644
index 0000000000000000000000000000000000000000..e0c0c21d8af1490bd42fc6b7d9d01ee9c5a5550e
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/handlers/PoolInfoChangeHandler.java
@@ -0,0 +1,122 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.handlers;
+
+import java.util.concurrent.ExecutorService;
+import org.dcache.poolmanager.PoolMonitor;
+import org.dcache.qos.services.verifier.data.FileQoSOperationMap;
+import org.dcache.qos.services.verifier.data.PoolInfoDiff;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.dcache.qos.services.verifier.util.VerifierMapInitializer;
+import org.dcache.qos.util.PoolMonitorChangeHandler;
+
+/**
+ *  Manages changes in pool monitor data for the {@link PoolInfoMap}.
+ */
+public final class PoolInfoChangeHandler extends PoolMonitorChangeHandler<PoolInfoDiff, VerifierMapInitializer> {
+    private PoolInfoMap poolInfoMap;
+    private FileQoSOperationMap fileOperationMap;
+
+    public PoolInfoDiff reloadAndScan(PoolMonitor poolMonitor) {
+        LOGGER.trace("Comparing current pool info to new psu.");
+        PoolInfoDiff diff = poolInfoMap.compare(poolMonitor);
+
+        if (diff.isEmpty()) {
+            LOGGER.trace("reloadAndScan, nothing to do.");
+            lastRefresh = System.currentTimeMillis();
+            return diff;
+        }
+
+        LOGGER.trace("Cancelling pool operations for removed pools {}.", diff.getOldPools());
+        diff.getOldPools().stream().forEach(this::cancelCurrentFileOpForPool);
+
+        LOGGER.trace("Cancelling pool operations for pools removed from groups {}.",
+                      diff.getPoolsRemovedFromPoolGroup());
+        diff.getPoolsRemovedFromPoolGroup().keySet().stream()
+            .forEach(this::cancelCurrentFileOpForPool);
+
+        LOGGER.trace("Applying diff to pool info map.");
+        poolInfoMap.apply(diff);
+        lastRefresh = System.currentTimeMillis();
+
+        LOGGER.trace("DIFF:\n{}", diff);
+        return diff;
+    }
+
+    public void setMapInitializer(VerifierMapInitializer initializer) {
+        this.initializer = initializer;
+    }
+
+    public void setFileOperationMap(FileQoSOperationMap fileOperationMap) {
+        this.fileOperationMap = fileOperationMap;
+    }
+
+    public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+        this.poolInfoMap = poolInfoMap;
+    }
+
+    public void setUpdateService(ExecutorService service) {
+        updateService = service;
+    }
+
+    private void cancelCurrentFileOpForPool(String pool) {
+        fileOperationMap.cancelFileOpForPool(pool, false);
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/AbstractLocationExtractor.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/AbstractLocationExtractor.java
new file mode 100644
index 0000000000000000000000000000000000000000..41baa12de84ed9830d1ae4fb74f28296a08c6e51
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/AbstractLocationExtractor.java
@@ -0,0 +1,162 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import com.google.common.collect.HashMultimap;
+import com.google.common.collect.Multimap;
+import java.util.Collection;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+/**
+ *  Implementation of the {@link ConstraintDiscriminator} which returns a list containing
+ *  the locations with zero weight.  The weights are computed in terms of the sum of the
+ *  size of the value partitions to which they belong.  For instance, if location1 has
+ *  tag1 with value A and tag2 with value X, and A is shared by 3 other locations
+ *  and X by 2, then location1 has a weight of 5.
+ *  <p/>
+ *  The use case envisaged here is as follows:  the component has a set of available
+ *  locations from which it must choose one or more. First, it will add the tags of all
+ *  current locations to the seenTags map. It will then run getCandidateLocations()
+ *  on the list one or more times, each time picking a location from the returned list
+ *  using some selection algorithm, removing this location from the available list and
+ *  adding its tags to the seenTags map, and finally passing the modified available list
+ *  in to any further iteration.</p>
+ */
+public abstract class AbstractLocationExtractor extends ConstraintDiscriminator {
+    protected final Multimap<String, String> seenTags = HashMultimap.create();
+
+    protected AbstractLocationExtractor(Collection<String> onlyOneCopyPer) {
+        super(onlyOneCopyPer);
+    }
+
+    /**
+     *  Add tag names and values for the location/pool to the map of seen tags.
+     *
+     *  @param location which has been selected.
+     */
+    public void addSeenTagsFor(String location) {
+        Map<String, String> tags = getKeyValuesFor(location);
+
+        if (tags == null || tags.isEmpty()) {
+            return;
+        }
+
+        for (String tagName : partitionKeys) {
+            String tagValue = tags.get(tagName);
+
+            if (tagValue == null) {
+                continue;
+            }
+
+            seenTags.put(tagName, tagValue);
+        }
+    }
+
+    @Override
+    public Collection<String> getCandidateLocations(Collection<String> locations) {
+        return locations.stream().filter((l) -> checkPartitionConstraints(l) == 0)
+                        .collect(Collectors.toList());
+    }
+
+    public void reset() {
+        seenTags.clear();
+    }
+
+    /**
+     *  @param location to examine
+     *  @return the number of tags whose values match values already
+     *          stored in the seenTags map –– that is, of locations/pools
+     *          which either already exist or have been selected.
+     */
+    private int checkPartitionConstraints(String location) {
+        Map<String, String> tags = getKeyValuesFor(location);
+
+        /*
+         *  An "undefined" situation.
+         *  For maximum flexibility, we allow the location to be selected.
+         */
+        if (tags == null || tags.isEmpty()) {
+            return 0;
+        }
+
+        int violations = 0;
+
+        for (String tagName : partitionKeys) {
+            String tagValue = tags.get(tagName);
+
+            /*
+             *  Again, this is an "undefined" situation, so
+             *  we provisionally qualify the location.
+             */
+            if (tagValue == null) {
+                continue;
+            }
+
+            Collection<String> values = seenTags.get(tagName);
+
+            if (values != null && values.contains(tagValue)) {
+                ++violations;
+            }
+        }
+
+        return violations;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/ConstraintDiscriminator.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/ConstraintDiscriminator.java
new file mode 100644
index 0000000000000000000000000000000000000000..38bdd352d2d9983129121409bf745f163582f90c
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/ConstraintDiscriminator.java
@@ -0,0 +1,99 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import com.google.common.collect.ImmutableSet;
+import java.util.Collection;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ *  Base class for the constraint discriminator interface.
+ *  <p/>
+ *  Implementations return a list, possibly ordered, of locations which qualify,
+ *  depending upon the semantics of the constraint checking done.
+ */
+public abstract class ConstraintDiscriminator {
+    protected final Set<String> partitionKeys;
+
+    /**
+     *  @param onlyOneCopyPer collection of keys (tag names) on whose values the
+     *                        matching and/or exclusion should take place.
+     */
+    protected ConstraintDiscriminator(Collection<String> onlyOneCopyPer) {
+        if (onlyOneCopyPer == null) {
+            partitionKeys = ImmutableSet.of();
+        } else {
+            partitionKeys = ImmutableSet.copyOf(onlyOneCopyPer);
+        }
+    }
+
+    /**
+     *  @param locations current set of locations
+     *  @return  a collection of locations which meet the constraint requirements
+     *           based on the presence of pool tag values matching the names of the partition keys.
+     */
+    public abstract Collection<String> getCandidateLocations(Collection<String> locations);
+
+    /**
+     *  Could be fetched from the pool, the PoolManager, or locally, for example.
+     */
+    protected abstract Map<String, String> getKeyValuesFor(String location);
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/EvictingLocationExtractor.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/EvictingLocationExtractor.java
new file mode 100644
index 0000000000000000000000000000000000000000..c644231dc4d34212934282ce89479afe11ccd1ac
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/EvictingLocationExtractor.java
@@ -0,0 +1,75 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import java.util.Collection;
+import java.util.Optional;
+
+public interface EvictingLocationExtractor {
+  /**
+   *  Based on the underlying discriminator logic, finds a location which is eligible
+   *  for eviction from among the provided locations.
+   *
+   *  @param locations from which to choose
+   *  @param verified  locations which have been verified.
+   *  @return an eligible location if there is one.
+   */
+  Optional<String> findALocationToEvict(Collection<String> locations, Collection verified);
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/LocationSelectionException.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/LocationSelectionException.java
new file mode 100644
index 0000000000000000000000000000000000000000..cff720ffc8af8af4877e69baebc34f2c2a874cb7
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/LocationSelectionException.java
@@ -0,0 +1,71 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+/**
+ *  Indicates a failure to select source or targets for copy and remove operations.
+ */
+public final class LocationSelectionException extends Exception {
+    private static final long serialVersionUID = 8432044084610575263L;
+
+    public LocationSelectionException(String format) {
+        super(format);
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/LocationSelector.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/LocationSelector.java
new file mode 100644
index 0000000000000000000000000000000000000000..6496f33b4c14e698c1868e141128327777522aae
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/LocationSelector.java
@@ -0,0 +1,124 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import java.util.Collection;
+import java.util.Set;
+import org.dcache.qos.data.FileQoSRequirements;
+import org.dcache.qos.services.verifier.data.FileQoSOperation;
+
+public interface LocationSelector {
+  /**
+   *  Select an eligible source for a copy operation.
+   *
+   *  @param operation for which to select the source.
+   *  @param locations all current replicas of the file.
+   *  @return an eligible source.
+   *  @throws LocationSelectionException
+   */
+  String selectCopySource(FileQoSOperation operation, Set<String> locations)
+      throws LocationSelectionException;
+
+  /**
+   *  Select an eligible target location for the copy operation.
+   *
+   *  @param operation for which to select the target.
+   *  @param poolGroup if required, from which to select the target.
+   *  @param locations all current replicas of the file.
+   *  @param tags for partitioning the locations.
+   *  @return an eligible target,
+   *  @throws LocationSelectionException
+   */
+  String selectCopyTarget(FileQoSOperation operation,
+                          String poolGroup,
+                          Collection<String> locations,
+                          Collection<String> tags)
+      throws LocationSelectionException;
+
+  /**
+   *  Select an eligible target to promote from cached to system sticky.
+   *
+   *  @param requirements for the target.
+   *  @param sticky current sticky replicas.
+   *  @param notSticky current non-sticky replicas.
+   *  @param tags for partitioning locations.
+   *  @return an eligible target.
+   */
+  String selectTargetToPersist(FileQoSRequirements requirements,
+                               Collection<String> sticky,
+                               Collection<String> notSticky,
+                               Collection<String> tags);
+
+  /**
+   *  Select an eligible target to demote from sticky to cached.
+   *
+   *  @param requirements for the target.
+   *  @param sticky current sticky replicas.
+   *  @param locations all current replicas of the file.
+   *  @param tags for partitioning locations.
+   *  @return an eligible target.
+   *  @throws LocationSelectionException
+   */
+  String selectTargetToCache(FileQoSRequirements requirements,
+                             Collection<String> sticky,
+                             Collection<String> locations,
+                             Collection<String> tags)
+      throws LocationSelectionException;
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/PoolInfoLocationSelector.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/PoolInfoLocationSelector.java
new file mode 100644
index 0000000000000000000000000000000000000000..21ead537aa7211dfcc4e7f5b8db35d54b4c7e062
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/PoolInfoLocationSelector.java
@@ -0,0 +1,303 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import com.google.common.annotations.VisibleForTesting;
+import com.google.common.collect.Sets;
+import diskCacheV111.vehicles.PoolManagerPoolInformation;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+import java.util.Set;
+import java.util.stream.Collectors;
+import org.dcache.pool.migration.PoolSelectionStrategy;
+import org.dcache.qos.data.FileQoSRequirements;
+import org.dcache.qos.services.verifier.data.FileQoSOperation;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ *  Manages the selection of locations from the underlying pool info map information.
+ *  Encapsulates the logic involved in extracting sets of valid readable or writable pools
+ *  in connection with the verification operation.
+ */
+public final class PoolInfoLocationSelector implements LocationSelector {
+    private static final Logger LOGGER = LoggerFactory.getLogger(PoolInfoLocationSelector.class);
+
+    private PoolInfoMap poolInfoMap;
+    private PoolSelectionStrategy poolSelectionStrategy;
+
+    public String selectCopySource(FileQoSOperation operation,
+                                   Set<String> locations)
+                    throws LocationSelectionException {
+        LOGGER.debug("selecting copy source for {} from {}.", operation.getPnfsId(), locations);
+        if (locations.size() == 1) {
+            if (!operation.getTried().isEmpty()) {
+                throw new LocationSelectionException(String.format("Cannot find "
+                                + "a new source because only one exists:  %s.",
+                                locations));
+            }
+            return locations.iterator().next();
+        }
+        return selectSource(locations, operation.getTried());
+    }
+
+    public String selectCopyTarget(FileQoSOperation operation,
+                                   String poolGroup,
+                                   Collection<String> locations,
+                                   Collection<String> tags)
+                    throws LocationSelectionException {
+        LOGGER.debug("selecting copy target for {} from {}; pool group {}, tags {}.",
+            operation.getPnfsId(), locations, poolGroup, tags);
+        Integer gindex = poolGroup == null ? null : poolInfoMap.getGroupIndex(poolGroup);
+        return selectCopyTarget(gindex, locations, operation.getTried(), tags);
+    }
+
+    public String selectTargetToPersist(FileQoSRequirements requirements,
+                                        Collection<String> sticky,
+                                        Collection<String> notSticky,
+                                        Collection<String> tags) {
+        if (notSticky.isEmpty()) {
+            return null;
+        }
+
+        LOGGER.debug("selecting target for {} from possible non-sticky locations",
+            requirements.getPnfsId());
+        return selectTargetToPersist(sticky, notSticky, tags);
+    }
+
+    public String selectTargetToCache(FileQoSRequirements requirements,
+                                      Collection<String> sticky,
+                                      Collection<String> locations,
+                                      Collection<String> tags)
+                    throws LocationSelectionException {
+        LOGGER.debug("selecting target to cache for {} from {}; tags {}.",
+            requirements.getPnfsId(),
+                     locations,
+                     tags);
+        if (sticky.size() == 1) {
+            String message = String.format("cacheable replica was selected, but "
+                                            + "the principal pool %s is the "
+                                            + "only location; this is a bug.",
+                            locations.iterator().next());
+            throw new LocationSelectionException(message);
+        }
+        return selectTargetToCache(locations, tags);
+    }
+
+    public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+        this.poolInfoMap = poolInfoMap;
+    }
+
+    public void setPoolSelectionStrategy(PoolSelectionStrategy poolSelectionStrategy) {
+        this.poolSelectionStrategy = poolSelectionStrategy;
+    }
+
+    private Set<String> getEligibleCopyTargets(Integer gindex,
+                                               Collection<String> locations,
+                                               Set<Integer> tried) {
+        Collection<Integer> pools = poolInfoMap.getPoolsOfGroup(gindex);
+        Set<Integer> writableMembers = poolInfoMap.getValidLocations(pools,true);
+        Set<Integer> lindices = poolInfoMap.getPoolIndices(locations);
+        Set<Integer> valid = Sets.difference(writableMembers, lindices);
+        valid = Sets.difference(valid, tried);
+        return poolInfoMap.getPools(valid);
+    }
+
+    private Set<String> getEligibleCacheableTargets(Collection<String> locations) {
+        Collection<Integer> indices = poolInfoMap.getPoolIndices(locations);
+        indices = poolInfoMap.getValidLocations(indices, true);
+        return poolInfoMap.getPools(indices);
+    }
+
+    @VisibleForTesting
+    String selectTargetToPersist(Collection<String> sticky,
+                                 Collection<String> notSticky,
+                                 Collection<String> oneCopyPer) {
+        Set<Integer> pools = poolInfoMap.getPoolIndices(notSticky);
+        Set<Integer> p2p = poolInfoMap.getValidLocations(pools,false);
+        Set<String> possible = poolInfoMap.getPools(p2p);
+        possible = eliminateNonDeliverableLocations(possible);
+
+        /*
+         * Filter by tag constraints.
+         */
+        AbstractLocationExtractor extractor = poolInfoMap.getLocationExtractor(oneCopyPer);
+        sticky.stream().forEach(extractor::addSeenTagsFor);
+        return extractor.getCandidateLocations(possible).stream()
+                                                        .findFirst()
+                                                        .orElse(null);
+    }
+
+    /*
+     *  Filters first the writable pools in the pool group which do not yet have a replica
+     *  of this file, then applies any tag-induced partitioning on the basis of the tags
+     *  of replicas that already exist. From that list, it then chooses the pool using the
+     *  configured poolSelectionStrategy.
+     */
+     @VisibleForTesting
+     String selectCopyTarget(Integer gindex,
+                             Collection<String> locations,
+                             Set<Integer> tried,
+                             Collection<String> oneCopyPer)
+                     throws LocationSelectionException {
+        /*
+         *  Writable locations in the pool group without a copy of this file,
+         *  or locations which exist which are not sticky.
+         */
+        Set<String> possible = getEligibleCopyTargets(gindex, locations, tried);
+
+        /*
+         *  Filter by tag constraints.
+         */
+        AbstractLocationExtractor extractor = poolInfoMap.getLocationExtractor(oneCopyPer);
+        locations.stream().forEach(extractor::addSeenTagsFor);
+        Collection<String> candidates = extractor.getCandidateLocations(possible);
+
+        if (candidates.isEmpty()) {
+            throw new LocationSelectionException(String.format("Cannot satisfy "
+                            + "copy request because there are no (further) "
+                            + "possible locations; candidates %s", candidates));
+        }
+
+        /*
+         *  Get pool cost for the candidates, then select the one using
+         *  the inject poolSelectionStrategy.
+         */
+        List<PoolManagerPoolInformation> info = new ArrayList<>();
+        for (String c : candidates) {
+            /*
+             *  throws InterruptedException
+             */
+            info.add(poolInfoMap.getPoolManagerInfo(poolInfoMap.getPoolIndex(c)));
+        }
+
+        PoolManagerPoolInformation target = poolSelectionStrategy.select(info);
+
+        LOGGER.debug("Pool selection poolSelectionStrategy "
+                        + "selected {} as copy target.", target);
+
+        if (target == null) {
+            throw new LocationSelectionException(String.format("Cannot satisfy "
+                            + "copy request because the selection "
+                            + "algorithm returned no viable locations; "
+                            + "locations: %s; possible %s", locations, candidates));
+        }
+
+        return target.getName();
+    }
+
+    /*
+     *  Filters first the writable pools in the pool group which contain a replica of this file,
+     *  then applies any tag-induced partitioning on the basis of the tags of replicas that
+     *  already exist to select a maximally constrained pool. If more than one pool has the same
+     *  weight, one of them is chosen randomly.
+     */
+    @VisibleForTesting
+    String selectTargetToCache(Collection<String> locations, Collection<String> oneCopyPer)
+                    throws LocationSelectionException {
+        Set<String> possible = getEligibleCacheableTargets(locations);
+        ConstraintDiscriminator extractor = new PoolTagBasedLocationExtractor(oneCopyPer,
+                                                                              poolInfoMap);
+        Collection<String> maximallyConstrained = extractor.getCandidateLocations(possible);
+        String target = RandomSelectionStrategy.SELECTOR.apply(maximallyConstrained);
+
+        if (target == null) {
+            throw new LocationSelectionException(String.format("Cannot satisfy "
+                            + "cache request because the selection algorithm "
+                            + "returned no viable locations: locations: %s; "
+                            + "possible: %s", locations, possible));
+        }
+
+        return target;
+    }
+
+    /*
+     *  Chooses a source randomly from among the readable locations which have not yet been tried.
+     */
+    @VisibleForTesting
+    String selectSource(Set<String> readable, Collection<Integer> tried)
+                    throws LocationSelectionException {
+        Set<String> excluded = poolInfoMap.getPools(tried);
+        Set<String> possible = Sets.difference(readable, excluded);
+        if (possible.isEmpty()) {
+            throw new LocationSelectionException(String.format("Cannot find  "
+                            + "a readable source because there "
+                            + "are no other viable locations; "
+                            + "readable: %s; tried: %s", readable, excluded));
+        }
+
+        return RandomSelectionStrategy.SELECTOR.apply(possible);
+    }
+
+    /*
+     *  Replicas may end up on pools (for instance, via staging) that are not accessible to
+     *  external reads.
+     *
+     *  We need to ensure that we don't set the sticky bit on cache locations
+     *  that are not readable to external clients.   The 'p2p' enabled requirement
+     *  (PoolV2Mode) for QoS-writable files is not sufficient (since this has to do
+     *  with the disable command in the PoolSelectionUnit, and not link preferences).
+     */
+    private Set<String> eliminateNonDeliverableLocations(Set<String> cached) {
+        return cached.stream().filter(p -> !poolInfoMap.isReadPref0(p)).collect(Collectors.toSet());
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/PoolTagBasedLocationExtractor.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/PoolTagBasedLocationExtractor.java
new file mode 100644
index 0000000000000000000000000000000000000000..a0790ae035f0884cfcda9a9e80fee0a509331090
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/PoolTagBasedLocationExtractor.java
@@ -0,0 +1,194 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import com.google.common.collect.ArrayListMultimap;
+import com.google.common.collect.Multimap;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.Set;
+import java.util.stream.Collectors;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.dcache.qos.util.RepositoryReplicaVerifier;
+
+/**
+ *  Implementation of the {@link ConstraintDiscriminator}, but specifically for evicting/caching
+ *  locations based on pool tags.<
+ *  <p/>
+ *  The algorithm is similar to the one described in {@link AbstractLocationExtractor}.
+ */
+public final class PoolTagBasedLocationExtractor extends ConstraintDiscriminator
+                                                 implements EvictingLocationExtractor {
+    class WeightedLocation {
+        final String location;
+        Integer weight;
+
+        public WeightedLocation(String location, Integer weight) {
+            this.location = location;
+            this.weight = weight;
+        }
+
+        void incrementBy(int count) {
+            weight += count;
+        }
+    }
+
+    private final Multimap<String, String> tagValuesByLocation = ArrayListMultimap.create();
+    private final Map<String, WeightedLocation> weights = new HashMap<>();
+    private final PoolInfoMap info;
+
+    private int maximal = 0;
+
+    public PoolTagBasedLocationExtractor(Collection<String> onlyOneCopyPer,
+                                   PoolInfoMap info) {
+        super(onlyOneCopyPer);
+        this.info = info;
+    }
+
+    @Override
+    public List<String> getCandidateLocations(Collection<String> locations) {
+        return extractMaximal(calculateWeights(locations));
+    }
+
+    public int getLastComputedMaximum() {
+        return maximal;
+    }
+
+    @Override
+    protected Map<String, String> getKeyValuesFor(String location) {
+        return info.getTags(info.getPoolIndex(location));
+    }
+
+    private Map<String, WeightedLocation>
+                calculateWeights(Collection<String> locations) {
+        locations.stream()
+                 .forEach((l) -> weights.put(l,
+                                             new WeightedLocation(l, 0)));
+
+        for (String tag: partitionKeys) {
+            for (String location: locations) {
+                Map<String, String> tags = getKeyValuesFor(location);
+
+                if (tags.isEmpty()) {
+                    continue;
+                }
+
+                String value = tags.get(tag);
+                if (value != null) {
+                    tagValuesByLocation.put(value, location);
+                }
+            }
+
+            for (String value: tagValuesByLocation.keySet() ) {
+                Collection<String> locs = tagValuesByLocation.get(value);
+                int count = locs.size();
+                for (String location: locs) {
+                    weights.get(location).incrementBy(count);
+                }
+            }
+
+            tagValuesByLocation.clear();
+        }
+
+        return weights;
+    }
+
+    public Optional<String> findALocationToEvict(Collection<String> locations, Collection verified) {
+        Set<String> seen = new HashSet <>();
+        for (String location: locations) {
+            Map<String, String> tags = getKeyValuesFor(location);
+            for (String tag: partitionKeys) {
+                if (tags.containsKey(tag)) {
+                    String nameValue = tag + tags.get(tag);
+                    if (seen.contains(nameValue)
+                                    && RepositoryReplicaVerifier.isRemovable(location, verified)) {
+                        return Optional.of(location);
+                    }
+                    seen.add(nameValue);
+                }
+            }
+        }
+        return Optional.empty();
+    }
+
+    private List<String> extractMaximal(Map<String, WeightedLocation> weights) {
+        final int max = getMaximal(weights.values());
+        List<String> maximal = weights.values().stream()
+                                               .filter((w) -> w.weight == max)
+                                               .map((w) -> w.location)
+                                               .collect(Collectors.toList());
+        weights.clear();
+        return maximal;
+    }
+
+    private int getMaximal(Collection<WeightedLocation> weightedLocations) {
+        maximal = 0;
+        for (WeightedLocation location : weightedLocations) {
+            if (location.weight > maximal) {
+                maximal = location.weight;
+            }
+        }
+        return maximal;
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/QoSVerificationTask.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/QoSVerificationTask.java
new file mode 100644
index 0000000000000000000000000000000000000000..5a1639db4d3470097dab44d57490a38dee4d561f
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/QoSVerificationTask.java
@@ -0,0 +1,109 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import diskCacheV111.util.PnfsId;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import org.dcache.pool.classic.Cancellable;
+import org.dcache.qos.services.verifier.handlers.FileQoSOperationHandler;
+import org.dcache.qos.util.ErrorAwareTask;
+
+/**
+ *  Runs the verification handling.
+ */
+public final class QoSVerificationTask extends ErrorAwareTask implements Cancellable {
+    private final PnfsId                  pnfsId;
+    private final FileQoSOperationHandler handler;
+    private final int                     retry;
+
+    private Future                        future;
+
+    public QoSVerificationTask(PnfsId pnfsId, int retry, FileQoSOperationHandler handler) {
+        this.pnfsId = pnfsId;
+        this.retry = retry;
+        this.handler = handler;
+    }
+
+    @Override
+    public Void call() {
+        handler.handleVerification(pnfsId);
+        return null;
+    }
+
+    @Override
+    public void cancel(String explanation) {
+        if (future != null) {
+            future.cancel(true);
+        }
+    }
+
+    public void submit() {
+        long delay = handler.getLaunchDelay();
+        TimeUnit unit = handler.getLaunchDelayUnit();
+
+        if (delay == 0 && retry > 0) {
+            delay = 5;
+            unit = TimeUnit.SECONDS;
+        }
+
+        future = handler.getTaskExecutor().schedule(createFireAndForgetTask(), delay, unit);
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/QoSVerifierCounters.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/QoSVerifierCounters.java
new file mode 100644
index 0000000000000000000000000000000000000000..f80722a979b6fadb034613c2c620d764e9c1c95c
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/QoSVerifierCounters.java
@@ -0,0 +1,316 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicLong;
+import org.dcache.qos.data.QoSAction;
+import org.dcache.qos.util.QoSCounter;
+import org.dcache.qos.util.QoSCounterGroup;
+import org.dcache.qos.util.QoSCounters;
+
+public final class QoSVerifierCounters extends QoSCounters {
+  public static final String ADJ_RESP_MESSAGE = "ADJUST RESPONSE";
+  public static final String LOC_EXCL_MESSAGE = "LOCATION EXCLUDED";
+  public static final String VRF_REQ_MESSAGE = "VERIFY REQUEST";
+  public static final String BVRF_REQ_MESSAGE = "BATCH VERIFY REQUEST";
+  public static final String VRF_CNCL_MESSAGE = "CANCEL REQUEST";
+  public static final String BVRF_CNCL_MESSAGE = "BATCH CANCEL REQUEST";
+
+  private static final String MESSAGES = "MESSAGES";
+  private static final String OPS = "OPS";
+  private static final String POOLS = "POOLS";
+  private static final String ALL = "ALL";
+  private static final String VOIDED = "VOIDED";
+
+  private static final String LASTCHK   = "Last checkpoint at %s\n";
+  private static final String LASTCHKD  = "Last checkpoint took %s seconds\n";
+  private static final String LASTCHKCT = "Last checkpoint saved %s records\n\n";
+  private static final String FORMAT_MESSAGES   = "%-30s %15s\n";
+  private static final String FORMAT_OPS        = "%-30s %15s %9s %12s\n";
+  private static final String FORMAT_DETAILS    = "%-28s | %12s %12s\n";
+  private static final String FORMAT_STATS      = "%-15s %28s | %15s %9s %9s %12s | %15s\n";
+  private static final String[] MESSAGES_HEADER = {"MESSAGES", "RECEIVED"};
+  private static final String[] OPS_HEADER      = {"OPS", "COMPLETED", "OPS/SEC", "FAILED" };
+  private static final String[] DETAILS_HEADER  = {"POOL", "COMPLETED", "FAILED" };
+  private static final String[] STATS_HEADER    = {"EPOCH", "CHECKPOINT", "OPS", "HZ",
+      "CHNG", "FAILED", "CHCKPTD"};
+
+  class QoSVerifyOpsCounter extends QoSCounter {
+    final AtomicLong current = new AtomicLong(0L);
+    long last = 0L;
+
+    public QoSVerifyOpsCounter(String name) {
+      super(name);
+    }
+  }
+
+  class QoSVerifyCounterGroup extends QoSCounterGroup<QoSCounter> {
+    protected QoSVerifyCounterGroup(String name) {
+      super(name);
+    }
+
+    @Override
+    public void toFormattedString(StringBuilder builder) {
+      getKeys().stream()
+          .forEach(k-> {
+            QoSCounter c = getCounter(k);
+            builder.append(String.format(FORMAT_MESSAGES, k, c.getTotal()));
+          });
+    }
+
+    @Override
+    protected QoSCounter createCounter(String key) {
+      return new QoSCounter(key);
+    }
+  }
+
+  class QoSVerifyRateCounterGroup extends QoSCounterGroup<QoSVerifyOpsCounter> {
+    protected QoSVerifyRateCounterGroup(String name) {
+      super(name);
+    }
+
+    @Override
+    public void toFormattedString(StringBuilder builder) {
+      getKeys().stream()
+          .forEach(k-> {
+            QoSVerifyOpsCounter c = getCounter(k);
+            builder.append(String.format(FORMAT_OPS, k, c.getTotal(),
+                getRatePerSecond(c.current.get()), c.getFailed()));
+          });
+    }
+
+    @Override
+    protected QoSVerifyOpsCounter createCounter(String key) {
+      return new QoSVerifyOpsCounter(key);
+    }
+  }
+
+  class QoSVerifyDetailsCounterGroup extends QoSCounterGroup<QoSCounter> {
+    protected QoSVerifyDetailsCounterGroup(String name) {
+      super(name);
+    }
+
+    @Override
+    public void toFormattedString(StringBuilder builder) {
+      getKeys().stream()
+          .forEach(k-> {
+            QoSCounter c = getCounter(k);
+            builder.append(String.format(FORMAT_DETAILS, k, c.getTotal(), c.getFailed()));
+          });
+    }
+
+    @Override
+    protected QoSCounter createCounter(String key) {
+      return new QoSCounter(key);
+    }
+  }
+
+  private long lastCheckpoint         = started.getTime();
+  private long lastCheckpointDuration = 0L;
+  private long lastCheckpointCount    = 0L;
+
+  @Override
+  public void initialize() {
+    groupMap = new HashMap<>();
+
+    QoSVerifyCounterGroup group = new QoSVerifyCounterGroup(MESSAGES);
+    group.addCounter(ADJ_RESP_MESSAGE);
+    group.addCounter(LOC_EXCL_MESSAGE);
+    group.addCounter(VRF_REQ_MESSAGE);
+    group.addCounter(VRF_CNCL_MESSAGE);
+    group.addCounter(BVRF_REQ_MESSAGE);
+    group.addCounter(BVRF_CNCL_MESSAGE);
+    groupMap.put(MESSAGES, group);
+
+    QoSVerifyRateCounterGroup rateGroup = new QoSVerifyRateCounterGroup(OPS);
+    rateGroup.addCounter(ALL);
+    rateGroup.addCounter(VOIDED);
+    groupMap.put(OPS, rateGroup);
+
+    QoSVerifyDetailsCounterGroup detailsGroup = new QoSVerifyDetailsCounterGroup(POOLS);
+    groupMap.put(POOLS, detailsGroup);
+  }
+
+  @Override
+  public void appendCounts(StringBuilder builder) {
+    builder.append(String.format(FORMAT_MESSAGES, MESSAGES_HEADER));
+    QoSCounterGroup group = groupMap.get(MESSAGES);
+    group.toFormattedString(builder);
+    builder.append("\n");
+    appendCheckpointInfo(builder);
+    builder.append(String.format(FORMAT_OPS, OPS_HEADER));
+    group = groupMap.get(OPS);
+    group.toFormattedString(builder);
+  }
+
+  @Override
+  public void appendDetails(StringBuilder builder) {
+    builder.append(String.format(FORMAT_DETAILS, DETAILS_HEADER));
+    QoSCounterGroup group = groupMap.get(POOLS);
+    group.toFormattedString(builder);
+  }
+
+  public void increment(String source, String target, QoSAction type) {
+    QoSVerifyOpsCounter counter = (QoSVerifyOpsCounter)groupMap.get(OPS).getCounter(ALL);
+    counter.incrementTotal();
+    counter.current.incrementAndGet();
+
+    if (type == QoSAction.VOID) {
+      counter = (QoSVerifyOpsCounter)groupMap.get(OPS).getCounter(VOIDED);
+      counter.incrementTotal();
+      counter.current.incrementAndGet();
+    }
+
+    if (source != null) {
+      checkPoolCounters(source);
+      groupMap.get(POOLS).getCounter(source).incrementTotal();
+    }
+
+    if (target != null) {
+      checkPoolCounters(target);
+      groupMap.get(POOLS).getCounter(target).incrementTotal();
+    }
+  }
+
+  public void incrementFailed(String pool) {
+    QoSVerifyOpsCounter counter = (QoSVerifyOpsCounter)groupMap.get(OPS).getCounter(ALL);
+    counter.incrementTotal();
+    counter.incrementFailed();
+    counter.current.incrementAndGet();
+
+    checkPoolCounters(pool);
+    groupMap.get(POOLS).getCounter(pool).incrementFailed();
+  }
+
+  public void incrementReceived(String type) {
+    QoSCounter counter = groupMap.get(MESSAGES).getCounter(type);
+    if (counter != null) {
+      counter.incrementTotal();
+    }
+  }
+
+  public void recordCheckpoint(long ended, long duration, long count) {
+    synchronized (statisticsBuffer) {
+      statisticsBuffer.add(getFormattedStatistics());
+    }
+    lastCheckpoint = ended;
+    lastCheckpointDuration = duration;
+    lastCheckpointCount = count;
+    resetLatestCounts();
+  }
+
+  @Override
+  protected String getStatisticsFormat() {
+    return FORMAT_STATS;
+  }
+
+  @Override
+  protected String[] getStatisticsHeader() {
+    return STATS_HEADER;
+  }
+
+  private void appendCheckpointInfo(StringBuilder builder) {
+    builder.append(String.format(LASTCHK, new Date(lastCheckpoint)));
+    builder.append(String.format(LASTCHKD, TimeUnit.MILLISECONDS.toSeconds(lastCheckpointDuration)));
+    builder.append(String.format(LASTCHKCT, lastCheckpointCount));
+  }
+
+  private void checkPoolCounters(String pool) {
+    QoSVerifyDetailsCounterGroup group = (QoSVerifyDetailsCounterGroup)groupMap.get(POOLS);
+    if (!group.hasCounter(pool)) {
+      group.addCounter(pool);
+    }
+  }
+
+  private String getFormattedStatistics() {
+    long epoch = lastCheckpoint;
+    Date chckpt = new Date(lastCheckpoint);
+    QoSVerifyOpsCounter counter = (QoSVerifyOpsCounter)groupMap.get(OPS).getCounter(ALL);
+    long ops = counter.getTotal();
+    long failed = counter.getFailed();
+    long current = counter.current.get();
+    long last = counter.last;
+    double hz = getRatePerSecond(current);
+    String delta = getRateChangeSinceLast(current, last);
+    return String.format(FORMAT_STATS, epoch, chckpt, ops, hz, delta, failed, lastCheckpointCount);
+  }
+
+  private long getRatePerSecond(long value) {
+    long elapsed = System.currentTimeMillis() - lastCheckpoint;
+    elapsed = TimeUnit.MILLISECONDS.toSeconds(elapsed);
+    if (elapsed == 0) {
+      return 0L;
+    }
+
+    return value/elapsed;
+  }
+
+  private void resetLatestCounts() {
+    QoSVerifyOpsCounter counter = (QoSVerifyOpsCounter)groupMap.get(OPS).getCounter(ALL);
+    counter.last = counter.current.get();
+    counter.current.set(0L);
+    counter = (QoSVerifyOpsCounter)groupMap.get(OPS).getCounter(VOIDED);
+    counter.last = counter.current.get();
+    counter.current.set(0L);
+  }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/RandomSelectionStrategy.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/RandomSelectionStrategy.java
new file mode 100644
index 0000000000000000000000000000000000000000..61fd5cf2219ea14fdf711236f5107a119e250430
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/RandomSelectionStrategy.java
@@ -0,0 +1,86 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import com.google.common.collect.Iterables;
+import java.security.SecureRandom;
+import java.util.Collection;
+import java.util.function.Function;
+
+/**
+ *  A simple utility for selection of a string. Chooses randomly from the elements
+ *  in the collection.  Note that this does not side-effect the collection itself.
+ */
+public final class RandomSelectionStrategy implements Function<Collection<String>, String> {
+    public static final RandomSelectionStrategy SELECTOR = new RandomSelectionStrategy();
+    private static final SecureRandom RANDOM = new SecureRandom();
+
+    private RandomSelectionStrategy() {
+    }
+
+    @Override
+    public String apply(Collection<String> collection) {
+        if (collection.isEmpty()) {
+            return null;
+        }
+
+        return Iterables.get(collection, RANDOM.nextInt(collection.size()));
+    }
+}
diff --git a/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/VerifierMapInitializer.java b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/VerifierMapInitializer.java
new file mode 100644
index 0000000000000000000000000000000000000000..a3e6e1caaac411e92bb9f8dfc025b441caa4bf6b
--- /dev/null
+++ b/modules/dcache-qos/src/main/java/org/dcache/qos/services/verifier/util/VerifierMapInitializer.java
@@ -0,0 +1,150 @@
+/*
+COPYRIGHT STATUS:
+Dec 1st 2001, Fermi National Accelerator Laboratory (FNAL) documents and
+software are sponsored by the U.S. Department of Energy under Contract No.
+DE-AC02-76CH03000. Therefore, the U.S. Government retains a  world-wide
+non-exclusive, royalty-free license to publish or reproduce these documents
+and software for U.S. Government purposes.  All documents and software
+available from this server are protected under the U.S. and Foreign
+Copyright Laws, and FNAL reserves all rights.
+
+Distribution of the software available from this server is free of
+charge subject to the user following the terms of the Fermitools
+Software Legal Information.
+
+Redistribution and/or modification of the software shall be accompanied
+by the Fermitools Software Legal Information  (including the copyright
+notice).
+
+The user is asked to feed back problems, benefits, and/or suggestions
+about the software to the Fermilab Software Providers.
+
+Neither the name of Fermilab, the  URA, nor the names of the contributors
+may be used to endorse or promote products derived from this software
+without specific prior written permission.
+
+DISCLAIMER OF LIABILITY (BSD):
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED  WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED  WARRANTIES OF MERCHANTABILITY AND FITNESS
+FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL FERMILAB,
+OR THE URA, OR THE U.S. DEPARTMENT of ENERGY, OR CONTRIBUTORS BE LIABLE
+FOR  ANY  DIRECT, INDIRECT,  INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
+OF SUBSTITUTE  GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY  OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT  OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE  POSSIBILITY OF SUCH DAMAGE.
+
+Liabilities of the Government:
+
+This software is provided by URA, independent from its Prime Contract
+with the U.S. Department of Energy. URA is acting independently from
+the Government and in its own private capacity and is not acting on
+behalf of the U.S. Government, nor as its contractor nor its agent.
+Correspondingly, it is understood and agreed that the U.S. Government
+has no connection to this software and in no manner whatsoever shall
+be liable for nor assume any responsibility or obligation for any claim,
+cost, or damages arising out of or resulting from the use of the software
+available from this server.
+
+Export Control:
+
+All documents and software available from this server are subject to U.S.
+export control laws.  Anyone downloading information from this server is
+obligated to secure any necessary Government licenses before exporting
+documents or software obtained from this server.
+ */
+package org.dcache.qos.services.verifier.util;
+
+import java.util.concurrent.TimeUnit;
+import org.dcache.qos.services.verifier.data.FileQoSOperationMap;
+import org.dcache.qos.services.verifier.data.PoolInfoMap;
+import org.dcache.qos.services.verifier.handlers.PoolInfoChangeHandler;
+import org.dcache.qos.util.MapInitializer;
+
+/**
+ *  Initialization sequence waits for the pool monitor, runs the diff and applies it to the
+ *  pool info map, enables delivery of messages, initializes the operation map, and starts
+ *  the watchdog; finally it reloads checkpointed operations.
+ */
+public final class VerifierMapInitializer extends MapInitializer {
+    private PoolInfoMap                 poolInfoMap;
+    private FileQoSOperationMap         fileOperationMap;
+    private PoolInfoChangeHandler       poolInfoChangeHandler;
+
+    public synchronized void shutDown() {
+        if (fileOperationMap.isRunning()) {
+            LOGGER.info("Shutting down file operation map.");
+            fileOperationMap.shutdown();
+        }
+
+        super.shutDown();
+    }
+
+    public void run() {
+        if (isInitialized()) {
+            return;
+        }
+
+        poolInfoChangeHandler.setRefreshService(initService);
+        poolInfoChangeHandler.setEnabled(true);
+
+        if (!waitForPoolMonitor()) {
+            return;
+        }
+
+        /*
+         *  Synchronous sequence of initialization procedures;
+         *  order must be maintained.
+         */
+        LOGGER.info("Received pool monitor; loading pool information.");
+        poolInfoMap.apply(poolInfoMap.compare(poolMonitor));
+
+        LOGGER.info("Pool maps initialized.");
+        messageGuard.enable();
+
+        LOGGER.info("Messages are now activated; starting file operation consumer.");
+        fileOperationMap.initialize();
+
+        LOGGER.info("File operation consumer is running; activating admin commands.");
+        setInitialized();
+
+        LOGGER.info("Starting the periodic pool monitor refresh check.");
+        poolInfoChangeHandler.startWatchdog();
+
+        /*
+         *  Do this after initialization.
+         *  It may take a while so we don't want to block the admin access.
+         */
+        LOGGER.info("Admin access enabled; reloading checkpoint file.");
+        fileOperationMap.reload();
+
+        LOGGER.info("Checkpoint file finished reloading.");
+    }
+
+    public void setFileOperationMap(FileQoSOperationMap fileOperationMap) {
+        this.fileOperationMap = fileOperationMap;
+    }
+
+    public void setPoolInfoMap(PoolInfoMap poolInfoMap) {
+        this.poolInfoMap = poolInfoMap;
+    }
+
+    public void setChangeHandler(
+                    PoolInfoChangeHandler changeHandler) {
+        this.poolInfoChangeHandler = changeHandler;
+    }
+
+    @Override
+    protected long getRefreshTimeout() {
+        return poolInfoChangeHandler.getRefreshTimeout();
+    }
+
+    @Override
+    protected TimeUnit getRefreshTimeoutUnit() {
+        return poolInfoChangeHandler.getRefreshTimeoutUnit();
+    }
+}
